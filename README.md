# ğŸš˜ ììœ¨ì£¼í–‰ ì„¼ì„œì˜ ì•ˆí…Œë‚˜ ì„±ëŠ¥ ì˜ˆì¸¡ AI ê²½ì§„ëŒ€íšŒ ğŸš˜

<img src="https://user-images.githubusercontent.com/55012723/210489354-d39644e2-f938-4b35-97aa-8b4338a73a5c.jpg"  width="500" height="500"/>

Regressionì„ í†µí•œ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”í•´ë³´ì!

<br/><br/>

## Team

**Name** : ì•ˆì¥ìµœ

**Members** : ê³ ë ¤ëŒ€í•™êµ ì‚°ì—…ê²½ì˜ê³µí•™ë¶€ ì•ˆì˜ì§€, ì¥ìˆ˜í˜, ìµœëŒ€ì›

<br/><br/>

## Project Descriptions

**Link** : [ììœ¨ì£¼í–‰ ì„¼ì„œì˜ ì•ˆí…Œë‚˜ ì„±ëŠ¥ ì˜ˆì¸¡ AI ê²½ì§„ëŒ€íšŒ (DACON)](https://dacon.io/competitions/official/235927/overview/description)


**[ëª©í‘œ]**  
ê³µì • ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ Radar ì„¼ì„œì˜ ì•ˆí…Œë‚˜ ì„±ëŠ¥ ì˜ˆì¸¡ì„ ìœ„í•œ AI ëª¨ë¸ ê°œë°œ  <br/>

ê³µì • ë°ì´í„°ì™€ ì œí’ˆ ì„±ëŠ¥ê°„ ìƒê´€ ë¶„ì„ì„ í†µí•´ ì œí’ˆì˜ ë¶ˆëŸ‰ì„ ì˜ˆì¸¡/ë¶„ì„


**[ë°°ê²½]**  
RadarëŠ” ììœ¨ì£¼í–‰ ì°¨ì— ìˆì–´ ì°¨ëŸ‰ê³¼ì˜ ê±°ë¦¬, ìƒëŒ€ ì†ë„, ë°©í–¥ ë“±ì„ ì¸¡ì •í•´ì£¼ëŠ” í•„ìˆ˜ì ì¸ ì„¼ì„œ ë¶€í’ˆ <br/>
LGì—ì„œëŠ” ì œí’ˆì˜ ì„±ëŠ¥ í‰ê°€ ê³µì •ì—ì„œ ì–‘í’ˆê³¼ ë¶ˆëŸ‰ì„ ì„ ë³„ ì¤‘. <br/>
AI ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ê³µì • ë°ì´í„°ì™€ ì œí’ˆ ì„±ëŠ¥ê°„ ìƒê´€ ë¶„ì„ì„ í†µí•´ ì œí’ˆì˜ ë¶ˆëŸ‰ì„ ì˜ˆì¸¡/ë¶„ì„í•˜ê³ , <br/>
ìˆ˜ìœ¨ì„ ê·¹ëŒ€í™”í•˜ì—¬ ë¶ˆëŸ‰ìœ¼ë¡œ ì¸í•œ ì œí’ˆ íê¸° ë¹„ìš©ì„ ê°ì¶•ì‹œí‚¤ëŠ” ê²ƒì´ ëª©í‘œ.


**[ë°ì´í„°]**

-Train Data : 39607ê°œ (ìˆ˜ì¹˜í˜• ì •í˜• ë°ì´í„°)

-Test Data : 39608ê°œ

-X ë³€ìˆ˜ : 56ê°œ (ê³µì • ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ ë¼ë²¨ë§)
 > 
    - PCB ì²´ê²° ì‹œ ë‹¨ê³„ë³„ ëˆ„ë¦„ëŸ‰(1~4)
    - ë°©ì—´(TIM) ì¬ë£Œ ë©´ì (1~3)
    - ë°©ì—´(TIM) ì¬ë£Œ ë¬´ê²Œ(1~3)
    - ì»¤ë„¥í„° ìœ„ì¹˜ ê¸°ì¤€ ì¢Œí‘œ â†’ ì¥ë¹„ì˜ ì›ì ìœ¼ë¡œë¶€í„° ê±°ë¦¬ ê°’
    - ê° ì•ˆí…Œë‚˜ íŒ¨ë“œ ìœ„ì¹˜(ë†’ì´) ì°¨ì´
    - ì•ˆí…Œë‚˜ íŒ¨ë“œ ìœ„ì¹˜
    - 1st ìŠ¤í¬ë¥˜ ì‚½ì… ê¹Šì´(1~4)
    - ì»¤ë„¥í„° í•€ ì¹˜ìˆ˜(1~6)
    - 2nd ìŠ¤í¬ë¥˜ ì‚½ì… ê¹Šì´(1~4) 
    - ìŠ¤í¬ë¥˜ ì²´ê²° ì‹œ ë¶„ë‹¹ íšŒì „ìˆ˜ (1~4)
    - í•˜ìš°ì§• PCB ì•ˆì°©ë¶€ ì¹˜ìˆ˜(1~3)
    - ë ˆì´ë” ì¹˜ìˆ˜ (ì•ˆí…Œë‚˜ 1~4ë²ˆ ë¶€ìœ„)
    - ì•ˆí…Œë‚˜ ë¶€ë¶„ ë ˆì´ë” ê¸°ìš¸ê¸°
    - ì‹¤ë€íŠ¸ ë³¸ë“œ ì†Œìš”ëŸ‰
    - Cal íˆ¬ì… ì „ ëŒ€ê¸° ì‹œê°„(Calibration ê³µì • -> RF ì„±ëŠ¥ í¸ì°¨ ì—†ë„ë¡ ì¡°ì •í•´ì£¼ëŠ” ê³¼ì •)
    - RF 1~7 ë¶€ë¶„ì˜ SMT ë‚© ëŸ‰

-Y ë³€ìˆ˜ : 14ê°œ
 > <img width="300" alt="image" src="https://user-images.githubusercontent.com/55012723/210501843-15250981-b4c3-4567-9889-4f31bfcfb540.png">



**[ì£¼ìµœ]**  
LG AI Research 


**[í‰ê°€ ì‚°ì‹]**  
Normalized RMSE (NRMSE)

```python

def lg_nrmse(gt, preds):
    # ê° Y Featureë³„ NRMSE ì´í•©
    # Y_01 ~ Y_08 ê¹Œì§€ 20% ê°€ì¤‘ì¹˜ ë¶€ì—¬
    all_nrmse = []
    for idx in range(1,15): # ignore 'ID'
        rmse = metrics.mean_squared_error(gt[:,idx], preds[:,idx], squared=False)
        nrmse = rmse/np.mean(np.abs(gt[:,idx]))
        all_nrmse.append(nrmse)
    score = 1.2 * np.sum(all_nrmse[:8]) + 1.0 * np.sum(all_nrmse[8:14])
    return score
    
```

<br/><br/>

## ğŸ‘£ Score
Public : 1.94045(122th) <br/>
Private : 1.96222(126th)

<br/><br/>

## ğŸŒ Environment

Google Colab
OS: macOS Ventura 13.0 <br/>
CPU: Intel(R) Xeon(R) CPU @ 2.20GHz 

<br/><br/>

## ğŸ”¥ Competition Strategies

**1. Feature Enginnering **  
- Adding Average SMT column
- Deleting Validation columns

<br/>

**2. Data Transform**  
Non-destructive transformations (not to add or lose the information)
- Flip  
- Transpose  
- RandomRotate  
- ShiftScaleRotate  

<br/>

**3. Training Methods**
- EarlyStopping  
  > To prevent overfitting  
  > If validation loss does not improve after given patience(=2), training is earlystopped  
- Fine-tuning with pre-trained model  
  > pretrained model : [RRDB_PSNR_x4.pth](https://github.com/xinntao/ESRGAN/tree/master/models)(the PSNR-oriented model withÂ high PSNR performance)  
  > Retraining entire model : Judging that the similarity between DF2K dataset(pretrained model) and our training datset is small  

<br/>

**4. Loss Function**
- L1 loss + L2 loss (2:1)
  > L2 loss : PSNR is based on MSE  
  > L1 loss: For better convergence [https://arxiv.org/pdf/1707.02921v1.pdf](https://arxiv.org/pdf/1707.02921v1.pdf)

<br/>

**5. Learning Scheduler, Optimizer**
- StepLR  
  > step_size = 3, gamma = 0.5  
  > Decays the learning rate of each parameter in half once per 3 epochs 
- Adam  

<br/>

**6. Post Processing**
- Geometric Self-Ensemble [https://arxiv.org/pdf/1707.02921v1.pdf](https://arxiv.org/pdf/1707.02921v1.pdf)
  > <img width="751" alt="KakaoTalk_Photo_2023-01-04-11-58-49" src="https://user-images.githubusercontent.com/55012723/210476203-015eac00-d0e0-4d10-8eb5-a772a9910097.png">


<br/><br/> 

## Main configuration & Hyperparameters
'''
1. Manuel_seed : 42  

2. Model :  
   > num_feat : 64 , Channel number of intermediate features.  
   > growth_channel: 32 , Channels for each growth(dense connection).  
   > num_block: 23 , number of RRDB blocks.  

3. Dataloader :  
   > train_batch_size : 4  
   > test_batch_size: 1  
   > num_workers: 4   

4. Train :  
   > epochs: 7  
   > optim_g: {type: Adam, lr: 1e-4, betas: [0.9, 0.99]}  

'''

<br/><br/>

## Code Descriptions
1. DACON_AISR_TRIAL
- EDSR, SRGAN, SWINIR


2. DACON_AISR_BEST
- RRDB, RRDB+(Self-ensemble)

