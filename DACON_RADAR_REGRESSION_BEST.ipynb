{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Drive Amount"
      ],
      "metadata": {
        "id": "ysqe4l4HS_40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL9BoEaHVnG6",
        "outputId": "e13f904c-184e-4554-81ca-abf4c0979f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hMuG573J8mb"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra-u6XYBZvvX",
        "outputId": "903f2264-393c-4f84-f807-a5b3f1c7af7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 168 kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.2.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQLY1hFjJ_S_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "\n",
        "import optuna\n",
        "from optuna import Trial, visualization\n",
        "from optuna.samplers import TPESampler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seed Fix"
      ],
      "metadata": {
        "id": "j4S5Fu0oT8yQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg0eam2vsJ83"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed) #실수 범위 내 숫자들을 모두 seed로 활용 가능\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed) # 음이 아닌 정수만 seed 값\n",
        "seed_everything(42) # Seed 고정 >> 모델 학습 결과 reproduction 하기 위해"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "vU-w9HJeUA5z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcpdpVHkVraR",
        "outputId": "21e02b24-2ef3-422a-ae64-ff87cf040bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Shareddrives/LG_DACON/데이터\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/drive/Shareddrives/LG_DACON/데이터')\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woFgPaqsVySw",
        "outputId": "c6d94a17-6439-44af-f9f9-2c6fe63fef33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39607, 71)\n",
            "            ID    X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08  \\\n",
            "0  TRAIN_00001  70.544  103.320  67.47     1  101.892  74.983  29.45   62.38   \n",
            "1  TRAIN_00002  69.524  103.321  65.17     1  101.944  72.943  28.73   61.23   \n",
            "2  TRAIN_00003  72.583  103.320  64.07     1  103.153  72.943  28.81  105.77   \n",
            "3  TRAIN_00004  71.563  103.320  67.57     1  101.971  77.022  28.92  115.21   \n",
            "4  TRAIN_00005  69.524  103.320  63.57     1  101.981  70.904  29.68  103.38   \n",
            "\n",
            "     X_09  ...    Y_05    Y_06   Y_07    Y_08    Y_09    Y_10    Y_11    Y_12  \\\n",
            "0  245.71  ...  29.632  16.083  4.276 -25.381 -25.529 -22.769  23.792 -25.470   \n",
            "1  233.61  ...  33.179  16.736  3.229 -26.619 -26.523 -22.574  24.691 -26.253   \n",
            "2  272.20  ...  31.801  17.080  2.839 -26.238 -26.216 -22.169  24.649 -26.285   \n",
            "3  255.36  ...  34.503  17.143  3.144 -25.426 -25.079 -21.765  24.913 -25.254   \n",
            "4  241.46  ...  32.602  17.569  3.138 -25.376 -25.242 -21.072  25.299 -25.072   \n",
            "\n",
            "     Y_13    Y_14  \n",
            "0 -25.409 -25.304  \n",
            "1 -26.497 -26.438  \n",
            "2 -26.215 -26.370  \n",
            "3 -25.021 -25.345  \n",
            "4 -25.195 -24.974  \n",
            "\n",
            "[5 rows x 71 columns]\n"
          ]
        }
      ],
      "source": [
        "train_df  = pd.read_csv('train.csv')\n",
        "print(train_df.shape)\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaKAvziMVyWh"
      },
      "outputs": [],
      "source": [
        "train_x = train_df.filter(regex='X') # Input : X Featrue\n",
        "train_y = train_df.filter(regex='Y') # Output : Y Feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YWPLl3Ajvqq"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-LZb-pnj1LC"
      },
      "source": [
        "## Adding Average SMT Column & Deleting Validation Columns "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYTzU5wtL-pA",
        "outputId": "07453824-b718-4540-947a-ddacce8cf395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# 평균_SMT납량\n",
        "train_x[\"평균_SMT납량\"] = (train_x[\"X_50\"] + train_x[\"X_51\"] + train_x[\"X_52\"] + train_x[\"X_53\"] + train_x[\"X_54\"] + train_x[\"X_55\"] + train_x[\"X_56\"]) / 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJW00GkpVyZP"
      },
      "outputs": [],
      "source": [
        "deleted_train_x = train_x.drop(['X_04','X_23', 'X_47', 'X_48'], axis=1) # n차 검증 x 칼럼 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXGKCNi0jd9h",
        "outputId": "6b1a8c69-5788-476b-fccd-b23611af3278"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Y_01', 'Y_02', 'Y_03', 'Y_04', 'Y_05', 'Y_06', 'Y_07', 'Y_08', 'Y_09',\n",
              "       'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_y.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RMyWJlrzBmR"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTODVb1BVycQ"
      },
      "outputs": [],
      "source": [
        "# 회귀분석을 위한 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(deleted_train_x, train_y, test_size=0.2, random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOQeNDf2Mu7Z",
        "outputId": "b7e7e6b3-3a66-4ac0-b280-d33da6e93cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31685, 53)\n",
            "(7922, 53)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW5aknI6KKoD"
      },
      "source": [
        "## Clustering By Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D62jwwMhKOmH"
      },
      "outputs": [],
      "source": [
        "# 공정 1~4로 나누기\n",
        "p1_train=X_train.iloc[:,:10] #X 1 ~ 11\n",
        "p2_train=X_train.iloc[:,10:38] #X 12~40\n",
        "p3_train=X_train.iloc[:,38:45] #X 41~49\n",
        "p4_train=X_train.iloc[:,45:52] #X 50~56\n",
        "\n",
        "p1_val=X_test.iloc[:,:10] #X 1 ~ 11\n",
        "p2_val=X_test.iloc[:,10:38] #X 12~40\n",
        "p3_val=X_test.iloc[:,38:45] #X 41~49\n",
        "p4_val=X_test.iloc[:,45:52] #X 50~56"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs945yswKOtj",
        "outputId": "4d94efa5-e047-4725-aa7f-5d3351b9b646"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# 공정1 클러스터링 ----> 2\n",
        "clust_model_1 = KMeans(n_clusters = 2,random_state = 42) \n",
        "clust_model_1.fit(p1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0H6tqaGKOwc"
      },
      "outputs": [],
      "source": [
        "pred_1_train = clust_model_1.predict(p1_train) # 각 예측군집 \n",
        "pred_1_val = clust_model_1.predict(p1_val) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKnBqN2eKO2R",
        "outputId": "c7e29f10-6a7d-428f-e598-eae83a39f4fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# 공정2 클러스터링 ----> 3\n",
        "clust_model_2 = KMeans(n_clusters = 3,random_state = 42) \n",
        "clust_model_2.fit(p2_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjM_ZJz_Q2A7"
      },
      "outputs": [],
      "source": [
        "pred_2_train = clust_model_2.predict(p2_train) # 각 예측군집 \n",
        "pred_2_val = clust_model_2.predict(p2_val) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBgsRpQRRDXT",
        "outputId": "47e5d69a-89c4-434d-ef4a-d894fa715501"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# 공정3 클러스터링 ---> 3\n",
        "clust_model_3 = KMeans(n_clusters = 3,random_state = 42) \n",
        "clust_model_3.fit(p3_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2a_AWUdRDfi"
      },
      "outputs": [],
      "source": [
        "pred_3_train = clust_model_3.predict(p3_train) # 각 예측군집 \n",
        "pred_3_val = clust_model_3.predict(p3_val) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtQQpsgjRDr_",
        "outputId": "75ec0b1c-d999-4444-d6aa-8016cbcefa3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# 공정4 클러스터링 ---> 2\n",
        "clust_model_4 = KMeans(n_clusters = 2,random_state = 42) \n",
        "clust_model_4.fit(p4_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7a3W2loR_w8"
      },
      "outputs": [],
      "source": [
        "pred_4_train = clust_model_4.predict(p4_train) # 각 예측군집 \n",
        "pred_4_val = clust_model_4.predict(p4_val) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA16teslSrcq"
      },
      "outputs": [],
      "source": [
        "# 원핫인코딩\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "\n",
        "pred_1_train = pred_1_train.reshape(-1,1)\n",
        "pred_2_train = pred_2_train.reshape(-1,1)\n",
        "pred_3_train = pred_3_train.reshape(-1,1)\n",
        "pred_4_train = pred_4_train.reshape(-1,1)\n",
        "\n",
        "pred_1_val = pred_1_val.reshape(-1,1)\n",
        "pred_2_val = pred_2_val.reshape(-1,1)\n",
        "pred_3_val = pred_3_val.reshape(-1,1)\n",
        "pred_4_val = pred_4_val.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGbXAQSrTVVb"
      },
      "outputs": [],
      "source": [
        "train_cluster_1 = np.array(ohe.fit_transform(pred_1_train)) # 공정1\n",
        "train_cluster_2 = np.array(ohe.fit_transform(pred_2_train)) # 공정2\n",
        "train_cluster_3 = np.array(ohe.fit_transform(pred_3_train)) # 공정3\n",
        "train_cluster_4 = np.array(ohe.fit_transform(pred_4_train)) # 공정4\n",
        "\n",
        "val_cluster_1 = np.array(ohe.fit_transform(pred_1_val)) # 공정1\n",
        "val_cluster_2 = np.array(ohe.fit_transform(pred_2_val)) # 공정2\n",
        "val_cluster_3 = np.array(ohe.fit_transform(pred_3_val)) # 공정3\n",
        "val_cluster_4 = np.array(ohe.fit_transform(pred_4_val)) # 공정4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUW-tHs9UL4T"
      },
      "outputs": [],
      "source": [
        "X_train = np.concatenate([X_train, train_cluster_1,train_cluster_2,train_cluster_3,train_cluster_4], axis=1)\n",
        "X_test = np.concatenate([X_test, val_cluster_1,val_cluster_2,val_cluster_3,val_cluster_4], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvDMezVvVXu4"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc3xfK8ScPoG",
        "outputId": "4683c9be-2043-4115-854b-7d0a72456807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31685, 63)\n",
            "(31685, 14)\n",
            "(7922, 63)\n",
            "(7922, 14)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15qjIjpGWHFU"
      },
      "source": [
        "# Modeling (each variable)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "_UsUfj8jUVo1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un2OOn5_pZWY"
      },
      "outputs": [],
      "source": [
        "#simplest stacking \n",
        "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "        \n",
        "    # we define clones of the original models to fit the data in\n",
        "    def fit(self, X, y):\n",
        "        self.models_ = [clone(x) for x in self.models]\n",
        "        \n",
        "        # Train cloned base models\n",
        "        for model in self.models_:\n",
        "            model.fit(X, y)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    #Now we do the predictions for cloned models and average them\n",
        "    def predict(self, X):\n",
        "        predictions = np.column_stack([\n",
        "            model.predict(X) for model in self.models_\n",
        "        ])\n",
        "        return np.mean(predictions, axis=1)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKUdjPhtpZdW"
      },
      "outputs": [],
      "source": [
        "# less simple stacking\n",
        "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
        "    def __init__(self, base_models, meta_model, n_folds=5):\n",
        "        self.base_models = base_models\n",
        "        self.meta_model = meta_model\n",
        "        self.n_folds = n_folds\n",
        "   \n",
        "    # We again fit the data on clones of the original models\n",
        "    def fit(self, X, y):\n",
        "        self.base_models_ = [list() for x in self.base_models]\n",
        "        self.meta_model_ = clone(self.meta_model)\n",
        "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
        "        \n",
        "        # Train cloned base models then create out-of-fold predictions\n",
        "        # that are needed to train the cloned meta-model\n",
        "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
        "        for i, model in enumerate(self.base_models):\n",
        "            for train_index, holdout_index in kfold.split(X, y):\n",
        "                instance = clone(model)\n",
        "                self.base_models_[i].append(instance)\n",
        "                instance.fit(X[train_index], y[train_index])\n",
        "                y_pred = instance.predict(X[holdout_index])\n",
        "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
        "                \n",
        "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
        "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
        "        return self\n",
        "   \n",
        "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
        "    #meta-features for the final prediction which is done by the meta-model\n",
        "    def predict(self, X):\n",
        "        meta_features = np.column_stack([\n",
        "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
        "            for base_models in self.base_models_ ])\n",
        "        return self.meta_model_.predict(meta_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYSffSsuWEjt"
      },
      "outputs": [],
      "source": [
        "#Validation function\n",
        "n_folds = 5\n",
        "\n",
        "def rmse_cv(model, x_train, y_train):\n",
        "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(x_train)\n",
        "    rmse= np.sqrt(-cross_val_score(model, x_train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ai_sPmMfRjq"
      },
      "outputs": [],
      "source": [
        "def rmse(y, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def modeling(model_dict, X_train, y_train):\n",
        "  for model_name, model in model_dict.items():\n",
        "    print(f'\\n{model_name} Start!')\n",
        "    score = rmsle_cv(model, X_train, y_train) # cross validation \n",
        "    print(\"\\nscore: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
        "    print(f'{model_name} End!\\n')"
      ],
      "metadata": {
        "id": "2-Colso4XQP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDrGfWjgekEE"
      },
      "outputs": [],
      "source": [
        "ridge = make_pipeline(RobustScaler(), BayesianRidge())\n",
        "lasso = make_pipeline(RobustScaler(), Lasso()) # sensitive to outlier\n",
        "ENet = make_pipeline(RobustScaler(), ElasticNet())\n",
        "Gboost = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=42))\n",
        "model_xgb = make_pipeline(StandardScaler(), XGBRegressor(random_state=42))\n",
        "model_lgb = make_pipeline(StandardScaler(), LGBMRegressor(random_state=42))\n",
        "model_cat = make_pipeline(StandardScaler(), CatBoostRegressor(random_state=42,verbose=False))\n",
        "averaged_models = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))\n",
        "stacked_averaged_models = make_pipeline(StandardScaler(), StackingAveragedModels(base_models = (Gboost, ENet, ridge),\n",
        "                                                 meta_model = lasso)) # y1기준 전부 부스팅 계열(Gboost, model_xgb, model_lgb, model_cat)로 넣으면 시간 너무 오래걸림 + 성능: 0.3475 ---> kaggle에서 활용한 조합으로 시도(KRR만 ridge으로) : 0.3554"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6c9rbr6phjS"
      },
      "outputs": [],
      "source": [
        "model_dict =  { 'ridge': ridge, 'lasso': lasso, 'ENet': ENet, 'Gboost': Gboost, 'xgb': model_xgb, 'lgb': model_lgb\n",
        "                , 'model_cat': model_cat, 'averaged_models': averaged_models, }#'stacked_averaged_models': stacked_averaged_models }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-validation Check"
      ],
      "metadata": {
        "id": "PvMYesUdX6bj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C31a1zSOZFF5"
      },
      "source": [
        "### y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N-1eYhvrNmG"
      },
      "outputs": [],
      "source": [
        "y1_train = y_train[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyPqMrtxaPeK",
        "outputId": "7856f6dc-4992-441c-aa4b-169260843ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.3496 (0.0022)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.3554 (0.0022)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.3554 (0.0022)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.3469 (0.0023)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[08:36:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:36:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.3467 (0.0024)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.3470 (0.0021)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.3473 (0.0019)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[08:39:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:40:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:40:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:41:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[08:42:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.3458 (0.0021)\n",
            "\n",
            "averaged_models End!\n",
            "\n",
            "\n",
            "stacked_averaged_models Start!\n",
            "\n",
            "score: 0.3554 (0.0022)\n",
            "\n",
            "stacked_averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y1_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFvI41LtfyXV"
      },
      "source": [
        "### y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ06A4oifO35"
      },
      "outputs": [],
      "source": [
        "y2_train = y_train[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkFU-vvHnpIY",
        "outputId": "370e259d-320f-43e4-dfab-9fe244f0c6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.3794 (0.0008)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.3859 (0.0015)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.3859 (0.0015)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.3778 (0.0008)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[09:02:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:02:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:02:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:03:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:03:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.3777 (0.0008)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.3780 (0.0012)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.3785 (0.0011)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[09:04:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:05:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:05:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:06:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:06:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.3768 (0.0009)\n",
            "\n",
            "averaged_models End!\n",
            "\n",
            "\n",
            "stacked_averaged_models Start!\n",
            "\n",
            "score: 0.3859 (0.0015)\n",
            "\n",
            "stacked_averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y2_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD6XQeantq_q"
      },
      "source": [
        "### y3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHp0E2MUnpL5"
      },
      "outputs": [],
      "source": [
        "y3_train = y_train[:, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OSN3D9QnpPQ",
        "outputId": "b13ef35c-f646-4a3a-be70-7a4e39ec66aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.3560 (0.0014)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.3609 (0.0014)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.3609 (0.0014)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.3543 (0.0012)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[09:20:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:20:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:20:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:20:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:20:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.3542 (0.0013)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.3545 (0.0015)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.3550 (0.0013)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[09:21:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:22:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:23:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:24:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:24:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.3533 (0.0013)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y3_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rRjBaP-ttti"
      },
      "source": [
        "### y4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M0ucbz6npUh"
      },
      "outputs": [],
      "source": [
        "y4_train = y_train[:, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1EJVmAosjtg",
        "outputId": "2ec3efd5-82cf-44d0-f2c7-eb8b395239c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 2.6451 (0.0998)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 2.6914 (0.0991)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 2.6873 (0.0993)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 2.6208 (0.0997)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[09:27:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:27:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:27:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:27:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:27:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 2.6216 (0.1015)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 2.6043 (0.1023)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 2.5922 (0.0981)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[09:28:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:29:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:30:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:30:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:31:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 2.5977 (0.1015)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y4_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toyoolGjtwJC"
      },
      "source": [
        "### y5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cASWTm0ysjwo"
      },
      "outputs": [],
      "source": [
        "y5_train = y_train[:, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT8CGAdFsjzo",
        "outputId": "6b0aab3a-373a-4163-88e6-2de16202b077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 2.5173 (0.0305)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 2.5465 (0.0343)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 2.5465 (0.0343)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 2.5068 (0.0309)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[09:32:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:33:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:33:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:33:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:33:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 2.5068 (0.0309)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 2.4988 (0.0330)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 2.4975 (0.0296)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[09:34:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:35:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:35:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:36:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:36:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 2.4930 (0.0312)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y5_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AySv19FAtxxj"
      },
      "source": [
        "### y6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iVITOPgsj2Y"
      },
      "outputs": [],
      "source": [
        "y6_train = y_train[:, 5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcij07fosj5Q",
        "outputId": "f4cd4022-b964-491b-e41a-860cd96bcffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 1.9055 (0.2039)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 1.9145 (0.2091)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 1.9145 (0.2091)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 1.8943 (0.1767)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[09:38:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:38:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:38:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:38:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:38:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 1.8787 (0.1757)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 1.7830 (0.1441)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 1.8020 (0.1369)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[09:40:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:40:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:41:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:41:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:42:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 1.8095 (0.1596)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y6_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpTHoyr5tzrD"
      },
      "source": [
        "### y7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGmeR-E6sj8o"
      },
      "outputs": [],
      "source": [
        "y7_train = y_train[:, 6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN2TPIaCskAA",
        "outputId": "9efc4832-400c-481f-9c76-dc66c953d982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.4140 (0.0035)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.4197 (0.0040)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.4197 (0.0040)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.4124 (0.0036)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[09:44:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:44:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:44:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:44:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:44:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.4120 (0.0034)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.4110 (0.0031)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.4101 (0.0032)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[09:45:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:46:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:46:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:47:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:47:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.4098 (0.0033)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y7_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmAzJ0f1t1Yz"
      },
      "source": [
        "### y8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE6-S5fPskDK"
      },
      "outputs": [],
      "source": [
        "y8_train = y_train[:, 7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHq5jKkrskGA",
        "outputId": "7c721590-1137-42f5-9b11-3675681a7a46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.6416 (0.0044)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.6596 (0.0036)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.6596 (0.0036)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.6316 (0.0038)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[09:49:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:49:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:49:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:49:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:49:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6320 (0.0037)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.6290 (0.0042)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.6278 (0.0041)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[09:51:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:51:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:52:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:53:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:53:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6275 (0.0040)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y8_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yA5mxAYt2yT"
      },
      "source": [
        "### y9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATReSjWAskJC"
      },
      "outputs": [],
      "source": [
        "y9_train = y_train[:, 8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdaKjh0XskMA",
        "outputId": "fb7a01cb-eab0-4910-bf2d-64e806fa9664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.6360 (0.0052)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.6522 (0.0043)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.6522 (0.0043)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.6264 (0.0050)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[09:55:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:55:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:55:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:55:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:55:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6269 (0.0050)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.6235 (0.0046)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.6223 (0.0049)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[09:57:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:57:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:58:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:58:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[09:59:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6222 (0.0049)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y9_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sI6_18gt4yE"
      },
      "source": [
        "### y10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XZuSCEMszjD"
      },
      "outputs": [],
      "source": [
        "y10_train = y_train[:, 9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk20gzNOskPI",
        "outputId": "32b5dbd3-fe56-4dce-8ce8-a53765410ed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.8964 (0.0174)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.9251 (0.0158)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.9251 (0.0158)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.8758 (0.0157)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[10:46:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:46:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:46:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:46:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:46:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.8765 (0.0156)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.8644 (0.0104)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.8607 (0.0120)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[10:48:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:48:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:49:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:49:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:50:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.8643 (0.0137)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y10_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwBsih5kt6e0"
      },
      "source": [
        "### y11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VC4z8HPskSN"
      },
      "outputs": [],
      "source": [
        "y11_train = y_train[:, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyIUE45KskVY",
        "outputId": "5c772975-0915-4433-e6ef-aef3c765602c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.8245 (0.0081)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.8307 (0.0082)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.8307 (0.0082)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.8176 (0.0080)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[10:52:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:52:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:52:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:52:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:52:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.8174 (0.0080)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.8137 (0.0080)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.8114 (0.0077)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[10:53:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:54:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:54:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:55:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:56:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.8118 (0.0079)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y11_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mEqLEnTt8db"
      },
      "source": [
        "### y12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tnw8b1iaskYe"
      },
      "outputs": [],
      "source": [
        "y12_train = y_train[:, 11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIkQfvSmskbY",
        "outputId": "38678837-b0cb-4c74-ebcd-f9cbf22cfca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.6385 (0.0056)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.6550 (0.0046)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.6550 (0.0046)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.6287 (0.0051)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[10:57:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:57:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:58:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:58:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[10:58:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6292 (0.0054)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.6268 (0.0051)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.6247 (0.0056)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[10:59:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:00:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:00:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:01:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:01:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6248 (0.0053)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y12_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOuUnptFt942"
      },
      "source": [
        "### y13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnqskJxbskew"
      },
      "outputs": [],
      "source": [
        "y13_train = y_train[:, 12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s5sLPtVtfl6",
        "outputId": "508ae65c-e729-45dd-b1d2-04253219033f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.6373 (0.0045)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.6541 (0.0032)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.6541 (0.0032)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.6273 (0.0046)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[11:03:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:03:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:03:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:03:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:03:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6277 (0.0046)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.6245 (0.0044)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.6233 (0.0052)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[11:05:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:05:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:06:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:06:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:07:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6232 (0.0046)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y13_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzuMqFZlt_im"
      },
      "source": [
        "### y14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmTXxbViskkt"
      },
      "outputs": [],
      "source": [
        "y14_train = y_train[:, 13]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Mbrm9sltUp5",
        "outputId": "d7a7f998-1380-40c2-bf70-3630a378cec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ridge Start!\n",
            "\n",
            "score: 0.6389 (0.0047)\n",
            "\n",
            "ridge End!\n",
            "\n",
            "\n",
            "lasso Start!\n",
            "\n",
            "score: 0.6552 (0.0036)\n",
            "\n",
            "lasso End!\n",
            "\n",
            "\n",
            "ENet Start!\n",
            "\n",
            "score: 0.6552 (0.0036)\n",
            "\n",
            "ENet End!\n",
            "\n",
            "\n",
            "Gboost Start!\n",
            "\n",
            "score: 0.6290 (0.0046)\n",
            "\n",
            "Gboost End!\n",
            "\n",
            "\n",
            "xgb Start!\n",
            "[11:09:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:09:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:09:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:09:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:09:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6293 (0.0046)\n",
            "\n",
            "xgb End!\n",
            "\n",
            "\n",
            "lgb Start!\n",
            "\n",
            "score: 0.6261 (0.0050)\n",
            "\n",
            "lgb End!\n",
            "\n",
            "\n",
            "model_cat Start!\n",
            "\n",
            "score: 0.6246 (0.0048)\n",
            "\n",
            "model_cat End!\n",
            "\n",
            "\n",
            "averaged_models Start!\n",
            "[11:10:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:11:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:11:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:12:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[11:12:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "\n",
            "score: 0.6247 (0.0047)\n",
            "\n",
            "averaged_models End!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "modeling(model_dict, X_train, y14_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8_UKWOSQnlf"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9SmD082QvLA"
      },
      "outputs": [],
      "source": [
        "# cross validation 기준으로 선정\n",
        "y1_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))\n",
        "y2_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))\n",
        "y3_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))\n",
        "y4_model = make_pipeline(StandardScaler(), CatBoostRegressor(verbose=False))\n",
        "y5_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))\n",
        "y6_model = make_pipeline(StandardScaler(), LGBMRegressor())\n",
        "y7_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))\n",
        "y8_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))\n",
        "y9_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))\n",
        "y10_model = make_pipeline(StandardScaler(), CatBoostRegressor(verbose=False))\n",
        "y11_model = make_pipeline(StandardScaler(), CatBoostRegressor(verbose=False))\n",
        "y12_model = make_pipeline(StandardScaler(), CatBoostRegressor(verbose=False))\n",
        "y13_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))\n",
        "y14_model = make_pipeline(StandardScaler(), CatBoostRegressor(verbose=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYjtYec_NnMd"
      },
      "source": [
        "## Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hGANldy3is5"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler() #평균 0, 표준편차 1\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_scaled.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvgcbiWkF6lO",
        "outputId": "83ffa228-dfe5-477d-b937-b140f3642a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31685, 63) (31685, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSCHERI2rvJa"
      },
      "source": [
        "# Hyperparameter Tuning(Optuna)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Data -> Drill , Valid Data (8:2)"
      ],
      "metadata": {
        "id": "3senlA7Qe39Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-LwKBc9Dhzo"
      },
      "outputs": [],
      "source": [
        "X_drill_scaled, X_val_scaled, y_drill, y_val = train_test_split(X_train_scaled,y_train,test_size=0.2,random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnUhC0DkM4AO",
        "outputId": "2376ae0a-768b-4b76-9fc6-a2504a7f8d32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((31685, 63), (25348, 63), (6337, 63), (7922, 63))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "X_train_scaled.shape, X_drill_scaled.shape, X_val_scaled.shape, X_test_scaled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###y1\n",
        "\n",
        "AveragingModels(models = (Gboost, model_xgb, model_lgb, model_cat)))"
      ],
      "metadata": {
        "id": "FHg7qoorc0R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
        "        'n_estimators': 10000,\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
        "        'random_state': 42,\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_xgb = XGBRegressor(**param)\n",
        "    model_xgb = model_xgb.fit(X_drill_scaled, y_drill[:,0], eval_set=[(X_val_scaled,y_val[:,0])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,0], model_xgb.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "UFqK8lG1Jkjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_xgb.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "id": "KPCeVkO8OixC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_trial_1 = optuna_xgb.best_trial\n",
        "xgb_best_params_1 = xgb_best_trial_1.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(xgb_best_trial_1.value, xgb_best_params_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6evkfNVPIL2",
        "outputId": "35f96283-2c95-40b5-9496-7051e682250c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.3508510812878692,\n",
            "params {'lambda': 3.230484834681071, 'alpha': 0.007539544503372105, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 7, 'min_child_weight': 209}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_params_1 = {'lambda': 3.230484834681071,\n",
        " 'alpha': 0.007539544503372105,\n",
        " 'colsample_bytree': 1.0,\n",
        " 'subsample': 0.5,\n",
        " 'learning_rate': 0.016,\n",
        " 'max_depth': 7,\n",
        " 'min_child_weight': 209}"
      ],
      "metadata": {
        "id": "-Ir2VUfXQFJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1_model_1 = XGBRegressor(**xgb_best_params_1)"
      ],
      "metadata": {
        "id": "4ubPU13AQPhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'random_state': 42,\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "        \n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_drill_scaled, y_drill[:,0], eval_set=[(X_val_scaled,y_val[:,0])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,0], model_lgbm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "Q_Lt8k6jJdo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_lgbm.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Detd5XuBJmvv",
        "outputId": "ef188f93-acd8-48b2-eac0-bd30ff7899bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 03:19:40,624]\u001b[0m A new study created in memory with name: no-name-e2bfb3db-f0ec-45e8-b649-a8341d750519\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:19:49,879]\u001b[0m Trial 0 finished with value: 0.35167239476305406 and parameters: {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:20:15,193]\u001b[0m Trial 1 finished with value: 0.3613997347048612 and parameters: {'max_depth': 5, 'learning_rate': 2.2310108018679158e-08, 'n_estimators': 2612, 'min_child_samples': 62, 'subsample': 0.765297684068612}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:20:21,860]\u001b[0m Trial 2 finished with value: 0.35247846022916934 and parameters: {'max_depth': 3, 'learning_rate': 0.006598711072054081, 'n_estimators': 2514, 'min_child_samples': 25, 'subsample': 0.4725148048142631}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:20:38,495]\u001b[0m Trial 3 finished with value: 0.3613846432255223 and parameters: {'max_depth': 5, 'learning_rate': 6.690421166498788e-07, 'n_estimators': 1622, 'min_child_samples': 46, 'subsample': 0.5223381155442193}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:20:51,820]\u001b[0m Trial 4 finished with value: 0.3613996540757301 and parameters: {'max_depth': 10, 'learning_rate': 6.870101665590006e-08, 'n_estimators': 947, 'min_child_samples': 40, 'subsample': 0.607503080954597}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:21:13,076]\u001b[0m Trial 5 finished with value: 0.3613968919736209 and parameters: {'max_depth': 13, 'learning_rate': 1.577766363058244e-07, 'n_estimators': 1591, 'min_child_samples': 61, 'subsample': 0.4173923345744613}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:21:16,890]\u001b[0m Trial 6 finished with value: 0.36140015845039486 and parameters: {'max_depth': 10, 'learning_rate': 1.0547383621352015e-07, 'n_estimators': 288, 'min_child_samples': 96, 'subsample': 0.9689996293810518}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:21:22,008]\u001b[0m Trial 7 finished with value: 0.3613968980396662 and parameters: {'max_depth': 13, 'learning_rate': 6.724850206557239e-07, 'n_estimators': 383, 'min_child_samples': 70, 'subsample': 0.5987069208932017}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:21:23,681]\u001b[0m Trial 8 finished with value: 0.3613779650306994 and parameters: {'max_depth': 4, 'learning_rate': 9.355380606452177e-06, 'n_estimators': 199, 'min_child_samples': 92, 'subsample': 0.5070361211081488}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:21:45,116]\u001b[0m Trial 9 finished with value: 0.3613830700621274 and parameters: {'max_depth': 11, 'learning_rate': 7.417652034871823e-07, 'n_estimators': 1608, 'min_child_samples': 57, 'subsample': 0.47382827709841974}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:21:56,884]\u001b[0m Trial 10 finished with value: 0.3518604271409263 and parameters: {'max_depth': 7, 'learning_rate': 0.003955232336089218, 'n_estimators': 2119, 'min_child_samples': 6, 'subsample': 0.405672369598035}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:22:04,288]\u001b[0m Trial 11 finished with value: 0.3516766766692927 and parameters: {'max_depth': 7, 'learning_rate': 0.007953409633698581, 'n_estimators': 2167, 'min_child_samples': 13, 'subsample': 0.4013720109047739}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:22:31,614]\u001b[0m Trial 12 finished with value: 0.3544296073842784 and parameters: {'max_depth': 7, 'learning_rate': 0.0004511388495675214, 'n_estimators': 2070, 'min_child_samples': 9, 'subsample': 0.4060696340155517}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:23:10,887]\u001b[0m Trial 13 finished with value: 0.3571612718634214 and parameters: {'max_depth': 7, 'learning_rate': 0.0001378296140671229, 'n_estimators': 2991, 'min_child_samples': 80, 'subsample': 0.7228898200777368}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:23:37,862]\u001b[0m Trial 14 finished with value: 0.35352775773187795 and parameters: {'max_depth': 8, 'learning_rate': 0.0005559231881814425, 'n_estimators': 2115, 'min_child_samples': 31, 'subsample': 0.5500437593750167}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:23:53,827]\u001b[0m Trial 15 finished with value: 0.36091782222799146 and parameters: {'max_depth': 15, 'learning_rate': 3.213476103996379e-05, 'n_estimators': 1094, 'min_child_samples': 21, 'subsample': 0.4595849978287922}. Best is trial 0 with value: 0.35167239476305406.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:24:17,788]\u001b[0m Trial 16 finished with value: 0.35163505205450113 and parameters: {'max_depth': 6, 'learning_rate': 0.001601446145845733, 'n_estimators': 2469, 'min_child_samples': 76, 'subsample': 0.7368481236544839}. Best is trial 16 with value: 0.35163505205450113.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:24:38,835]\u001b[0m Trial 17 finished with value: 0.3518384629316675 and parameters: {'max_depth': 5, 'learning_rate': 0.0017342958744185123, 'n_estimators': 2900, 'min_child_samples': 79, 'subsample': 0.7391188697913744}. Best is trial 16 with value: 0.35163505205450113.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:25:11,790]\u001b[0m Trial 18 finished with value: 0.36015860162717295 and parameters: {'max_depth': 9, 'learning_rate': 3.797935773199829e-05, 'n_estimators': 2495, 'min_child_samples': 77, 'subsample': 0.860752772266864}. Best is trial 16 with value: 0.35163505205450113.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:25:22,521]\u001b[0m Trial 19 finished with value: 0.35441895754765174 and parameters: {'max_depth': 3, 'learning_rate': 0.0011139995175226236, 'n_estimators': 1848, 'min_child_samples': 88, 'subsample': 0.6884417887303066}. Best is trial 16 with value: 0.35163505205450113.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:25:35,105]\u001b[0m Trial 20 finished with value: 0.3596338698139572 and parameters: {'max_depth': 6, 'learning_rate': 0.0001379020609068817, 'n_estimators': 988, 'min_child_samples': 69, 'subsample': 0.8307857150098001}. Best is trial 16 with value: 0.35163505205450113.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:25:41,680]\u001b[0m Trial 21 finished with value: 0.35167460397243455 and parameters: {'max_depth': 8, 'learning_rate': 0.009089386482629344, 'n_estimators': 2338, 'min_child_samples': 47, 'subsample': 0.6583175600200113}. Best is trial 16 with value: 0.35163505205450113.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:26:04,520]\u001b[0m Trial 22 finished with value: 0.35166078351889946 and parameters: {'max_depth': 9, 'learning_rate': 0.001950758272067906, 'n_estimators': 2350, 'min_child_samples': 47, 'subsample': 0.6844653505480081}. Best is trial 16 with value: 0.35163505205450113.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:26:37,248]\u001b[0m Trial 23 finished with value: 0.3514496892935193 and parameters: {'max_depth': 9, 'learning_rate': 0.0012978001727601285, 'n_estimators': 2753, 'min_child_samples': 36, 'subsample': 0.581034190835316}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:27:15,678]\u001b[0m Trial 24 finished with value: 0.3559539769692994 and parameters: {'max_depth': 12, 'learning_rate': 0.00020790587330952006, 'n_estimators': 2802, 'min_child_samples': 36, 'subsample': 0.5808402103789303}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:27:44,059]\u001b[0m Trial 25 finished with value: 0.35170841272831405 and parameters: {'max_depth': 9, 'learning_rate': 0.0015362046730094025, 'n_estimators': 2725, 'min_child_samples': 51, 'subsample': 0.6455447104868853}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:28:16,084]\u001b[0m Trial 26 finished with value: 0.3611914157364237 and parameters: {'max_depth': 10, 'learning_rate': 6.177692251141983e-06, 'n_estimators': 2398, 'min_child_samples': 41, 'subsample': 0.803122223177908}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:28:42,637]\u001b[0m Trial 27 finished with value: 0.3600307146875381 and parameters: {'max_depth': 11, 'learning_rate': 5.388436641467111e-05, 'n_estimators': 1935, 'min_child_samples': 33, 'subsample': 0.8871870063843876}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:29:18,475]\u001b[0m Trial 28 finished with value: 0.3538072793099004 and parameters: {'max_depth': 8, 'learning_rate': 0.00039611712169162653, 'n_estimators': 2742, 'min_child_samples': 26, 'subsample': 0.684564366223569}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:29:32,848]\u001b[0m Trial 29 finished with value: 0.35158966517665174 and parameters: {'max_depth': 6, 'learning_rate': 0.0028356365300060415, 'n_estimators': 1376, 'min_child_samples': 53, 'subsample': 0.5585697070707765}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:29:45,052]\u001b[0m Trial 30 finished with value: 0.3515116909880377 and parameters: {'max_depth': 6, 'learning_rate': 0.003591036147856601, 'n_estimators': 1305, 'min_child_samples': 69, 'subsample': 0.5668823667685721}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:29:57,830]\u001b[0m Trial 31 finished with value: 0.35168044586085584 and parameters: {'max_depth': 6, 'learning_rate': 0.0028064180446193856, 'n_estimators': 1219, 'min_child_samples': 68, 'subsample': 0.5627765356171772}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:30:12,864]\u001b[0m Trial 32 finished with value: 0.3537372959855743 and parameters: {'max_depth': 6, 'learning_rate': 0.0008801253631989622, 'n_estimators': 1302, 'min_child_samples': 56, 'subsample': 0.5301315296739731}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:30:18,296]\u001b[0m Trial 33 finished with value: 0.3524330742387139 and parameters: {'max_depth': 4, 'learning_rate': 0.004898746157127096, 'n_estimators': 764, 'min_child_samples': 74, 'subsample': 0.6115079902424931}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:30:28,969]\u001b[0m Trial 34 finished with value: 0.3523861701226479 and parameters: {'max_depth': 4, 'learning_rate': 0.0033685917407598725, 'n_estimators': 1361, 'min_child_samples': 87, 'subsample': 0.4868322797499679}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:30:48,024]\u001b[0m Trial 35 finished with value: 0.35680362505596297 and parameters: {'max_depth': 5, 'learning_rate': 0.00025011705540924577, 'n_estimators': 1865, 'min_child_samples': 62, 'subsample': 0.5622342632346815}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:30:55,595]\u001b[0m Trial 36 finished with value: 0.35620005172957364 and parameters: {'max_depth': 6, 'learning_rate': 0.0008984476417064609, 'n_estimators': 598, 'min_child_samples': 65, 'subsample': 0.4421381553933041}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:31:09,899]\u001b[0m Trial 37 finished with value: 0.36140035609991444 and parameters: {'max_depth': 5, 'learning_rate': 1.1358331873744956e-08, 'n_estimators': 1428, 'min_child_samples': 54, 'subsample': 0.619893644268371}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:31:20,104]\u001b[0m Trial 38 finished with value: 0.36135395917369806 and parameters: {'max_depth': 3, 'learning_rate': 2.596572102319858e-06, 'n_estimators': 1752, 'min_child_samples': 42, 'subsample': 0.5013955119883226}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:31:39,544]\u001b[0m Trial 39 finished with value: 0.3597317051432638 and parameters: {'max_depth': 8, 'learning_rate': 8.835667118997866e-05, 'n_estimators': 1491, 'min_child_samples': 83, 'subsample': 0.5411933597432991}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:31:48,418]\u001b[0m Trial 40 finished with value: 0.3517176047634001 and parameters: {'max_depth': 6, 'learning_rate': 0.0046547039411756865, 'n_estimators': 2548, 'min_child_samples': 99, 'subsample': 0.6440227715618979}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:32:08,432]\u001b[0m Trial 41 finished with value: 0.3516441100336367 and parameters: {'max_depth': 9, 'learning_rate': 0.0022530604834939565, 'n_estimators': 2659, 'min_child_samples': 48, 'subsample': 0.7711595258852653}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:32:25,499]\u001b[0m Trial 42 finished with value: 0.3516685697301284 and parameters: {'max_depth': 10, 'learning_rate': 0.002475002056604826, 'n_estimators': 2620, 'min_child_samples': 50, 'subsample': 0.7662692599307526}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:32:41,136]\u001b[0m Trial 43 finished with value: 0.3550706818632743 and parameters: {'max_depth': 11, 'learning_rate': 0.0006381353969225344, 'n_estimators': 1199, 'min_child_samples': 74, 'subsample': 0.5772109999110137}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:32:47,362]\u001b[0m Trial 44 finished with value: 0.35168394914193973 and parameters: {'max_depth': 8, 'learning_rate': 0.008775049853014786, 'n_estimators': 1684, 'min_child_samples': 58, 'subsample': 0.7808162553445742}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:33:13,425]\u001b[0m Trial 45 finished with value: 0.35454879074746 and parameters: {'max_depth': 5, 'learning_rate': 0.00035281480511511874, 'n_estimators': 2640, 'min_child_samples': 38, 'subsample': 0.72189344222939}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:33:45,147]\u001b[0m Trial 46 finished with value: 0.35185352839100326 and parameters: {'max_depth': 7, 'learning_rate': 0.0014173976144422704, 'n_estimators': 2977, 'min_child_samples': 44, 'subsample': 0.9289745377009221}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:33:54,586]\u001b[0m Trial 47 finished with value: 0.35167462149914114 and parameters: {'max_depth': 7, 'learning_rate': 0.0050803148775085015, 'n_estimators': 856, 'min_child_samples': 60, 'subsample': 0.5889211199806186}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:34:12,667]\u001b[0m Trial 48 finished with value: 0.3515722663067212 and parameters: {'max_depth': 14, 'learning_rate': 0.002644210213177141, 'n_estimators': 1579, 'min_child_samples': 65, 'subsample': 0.9984285020100014}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 03:34:33,040]\u001b[0m Trial 49 finished with value: 0.3538611834480167 and parameters: {'max_depth': 15, 'learning_rate': 0.0006960714022469942, 'n_estimators': 1554, 'min_child_samples': 64, 'subsample': 0.9787787527963858}. Best is trial 23 with value: 0.3514496892935193.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_trial_1 = optuna_lgbm.best_trial\n",
        "lgbm_best_params_1 = lgbm_best_trial_1.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_best_trial_1.value, lgbm_best_params_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96gQj7itKnVR",
        "outputId": "2b81b018-f781-4ab2-cf51-3b706924dcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.3514496892935193,\n",
            "params {'max_depth': 9, 'learning_rate': 0.0012978001727601285, 'n_estimators': 2753, 'min_child_samples': 36, 'subsample': 0.581034190835316}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params_1 = {'max_depth': 9,\n",
        " 'learning_rate': 0.0012978001727601285,\n",
        " 'n_estimators': 2753,\n",
        " 'min_child_samples': 36,\n",
        " 'subsample': 0.581034190835316}"
      ],
      "metadata": {
        "id": "ZV9_py2fLTaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1_model_2 = LGBMRegressor(**lgbm_best_params_1 )"
      ],
      "metadata": {
        "id": "eKF4twwoLUO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###y2"
      ],
      "metadata": {
        "id": "IbsAUXOULa94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
        "        'n_estimators': 10000,\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
        "        'random_state': 42,\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_xgb = XGBRegressor(**param)\n",
        "    model_xgb = model_xgb.fit(X_drill_scaled, y_drill[:,1], eval_set=[(X_val_scaled,y_val[:,1])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,1], model_xgb.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "T0swS4E2LcaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_xgb.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLP-Th1wLfTr",
        "outputId": "1cf6d1a1-2373-4495-9911-830776e94ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:10,738]\u001b[0m A new study created in memory with name: no-name-d5c2aa37-f5b9-4a1c-9147-b65de3b1f742\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:14,611]\u001b[0m Trial 0 finished with value: 0.3737046171086356 and parameters: {'lambda': 0.03148911647956861, 'alpha': 6.351221010640703, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 183}. Best is trial 0 with value: 0.3737046171086356.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:18,681]\u001b[0m Trial 1 finished with value: 0.3738034140000285 and parameters: {'lambda': 0.004809461967501573, 'alpha': 0.0018205657658407262, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 7, 'min_child_weight': 82}. Best is trial 0 with value: 0.3737046171086356.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:22,984]\u001b[0m Trial 2 finished with value: 0.37370413145347875 and parameters: {'lambda': 2.0651425578959257, 'alpha': 0.026730883107816707, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 11, 'min_child_weight': 229}. Best is trial 2 with value: 0.37370413145347875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:32,163]\u001b[0m Trial 3 finished with value: 0.3742906767852997 and parameters: {'lambda': 0.17583640270008521, 'alpha': 1.2130221181165162, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 34}. Best is trial 2 with value: 0.37370413145347875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:37,936]\u001b[0m Trial 4 finished with value: 0.3735934655222667 and parameters: {'lambda': 0.008160948743089917, 'alpha': 0.05110120656497164, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 11, 'min_child_weight': 296}. Best is trial 4 with value: 0.3735934655222667.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:40,945]\u001b[0m Trial 5 finished with value: 0.3738981897714912 and parameters: {'lambda': 0.009294394155644996, 'alpha': 0.4881375191603672, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 5, 'min_child_weight': 198}. Best is trial 4 with value: 0.3735934655222667.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:47,963]\u001b[0m Trial 6 finished with value: 0.37383348904504204 and parameters: {'lambda': 1.857328833311487, 'alpha': 0.16626592254031872, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'min_child_weight': 98}. Best is trial 4 with value: 0.3735934655222667.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:51,384]\u001b[0m Trial 7 finished with value: 0.37352432862533735 and parameters: {'lambda': 0.9682012086882473, 'alpha': 0.39676339357448603, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 7, 'min_child_weight': 290}. Best is trial 7 with value: 0.37352432862533735.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:29:57,801]\u001b[0m Trial 8 finished with value: 0.3734570502682233 and parameters: {'lambda': 7.152863022216533, 'alpha': 2.5824850844906155, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 211}. Best is trial 8 with value: 0.3734570502682233.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:29:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:04,643]\u001b[0m Trial 9 finished with value: 0.3739270123184489 and parameters: {'lambda': 1.5246518242848615, 'alpha': 3.6309591863459096, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 82}. Best is trial 8 with value: 0.3734570502682233.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:11,900]\u001b[0m Trial 10 finished with value: 0.37366506490780665 and parameters: {'lambda': 8.279350403364669, 'alpha': 0.012047666811939929, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 141}. Best is trial 8 with value: 0.3734570502682233.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:16,058]\u001b[0m Trial 11 finished with value: 0.37356109188327974 and parameters: {'lambda': 0.31356971313563703, 'alpha': 0.8731689376242987, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.012, 'max_depth': 7, 'min_child_weight': 299}. Best is trial 8 with value: 0.3734570502682233.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:19,646]\u001b[0m Trial 12 finished with value: 0.37368974570257235 and parameters: {'lambda': 9.228445195261523, 'alpha': 0.3007016232607134, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 17, 'min_child_weight': 248}. Best is trial 8 with value: 0.3734570502682233.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:25,327]\u001b[0m Trial 13 finished with value: 0.3735675382328357 and parameters: {'lambda': 0.5729891581071089, 'alpha': 1.8108430517659544, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.012, 'max_depth': 13, 'min_child_weight': 250}. Best is trial 8 with value: 0.3734570502682233.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:30,624]\u001b[0m Trial 14 finished with value: 0.3736880416973876 and parameters: {'lambda': 1.0337440791489405, 'alpha': 8.36440616184807, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 7, 'min_child_weight': 156}. Best is trial 8 with value: 0.3734570502682233.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:34,132]\u001b[0m Trial 15 finished with value: 0.37322906072830697 and parameters: {'lambda': 0.06573761850403101, 'alpha': 0.11337032848184257, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 271}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:37,790]\u001b[0m Trial 16 finished with value: 0.3734896920221688 and parameters: {'lambda': 0.05661893817797476, 'alpha': 0.0045943610934533665, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 216}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:41,478]\u001b[0m Trial 17 finished with value: 0.3732416179918255 and parameters: {'lambda': 0.0017881959703957278, 'alpha': 0.049814110332196175, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 257}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:44,943]\u001b[0m Trial 18 finished with value: 0.3734939484393215 and parameters: {'lambda': 0.0010069081000511379, 'alpha': 0.08347743131278815, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 261}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:49,639]\u001b[0m Trial 19 finished with value: 0.37370415213254377 and parameters: {'lambda': 0.0012290910919916743, 'alpha': 0.024144974993921754, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 17, 'min_child_weight': 265}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:52,152]\u001b[0m Trial 20 finished with value: 0.3738640733713859 and parameters: {'lambda': 0.021809108599450646, 'alpha': 0.005015799436471375, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 5, 'min_child_weight': 164}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:55,356]\u001b[0m Trial 21 finished with value: 0.3740483725935545 and parameters: {'lambda': 0.10135100550414516, 'alpha': 0.08523699760352155, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 9, 'min_child_weight': 218}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:30:58,313]\u001b[0m Trial 22 finished with value: 0.37346305213148695 and parameters: {'lambda': 0.003356055081840762, 'alpha': 0.18609547429487389, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 274}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:30:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:04,314]\u001b[0m Trial 23 finished with value: 0.3732833835751275 and parameters: {'lambda': 0.019053672783088452, 'alpha': 0.03461934427944359, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 240}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:08,418]\u001b[0m Trial 24 finished with value: 0.3734208772922334 and parameters: {'lambda': 0.019958815925204713, 'alpha': 0.03358431030802113, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 13, 'min_child_weight': 242}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:11,805]\u001b[0m Trial 25 finished with value: 0.3736097598950623 and parameters: {'lambda': 0.0023522586579121066, 'alpha': 0.015398260963337015, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 268}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:18,978]\u001b[0m Trial 26 finished with value: 0.37328784907566254 and parameters: {'lambda': 0.05177755573218333, 'alpha': 0.007715224057403519, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 183}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:23,510]\u001b[0m Trial 27 finished with value: 0.37368081179952245 and parameters: {'lambda': 0.010961703778037088, 'alpha': 0.1629915696105257, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 125}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:30,047]\u001b[0m Trial 28 finished with value: 0.3740816079547559 and parameters: {'lambda': 0.15798875231434903, 'alpha': 0.05388521445597273, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 9, 'min_child_weight': 10}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:33,462]\u001b[0m Trial 29 finished with value: 0.3734962613549017 and parameters: {'lambda': 0.03628294690625192, 'alpha': 0.0015025306473817207, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 190}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:36,844]\u001b[0m Trial 30 finished with value: 0.37377000011380074 and parameters: {'lambda': 0.017546264076352746, 'alpha': 0.04643898417413263, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.02, 'max_depth': 15, 'min_child_weight': 235}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:43,520]\u001b[0m Trial 31 finished with value: 0.37328010837704756 and parameters: {'lambda': 0.055167891299689444, 'alpha': 0.008047826980718223, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 181}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:50,488]\u001b[0m Trial 32 finished with value: 0.37326427748023977 and parameters: {'lambda': 0.07027170547345622, 'alpha': 0.0036062653034814457, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 286}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:31:56,402]\u001b[0m Trial 33 finished with value: 0.3735746474839236 and parameters: {'lambda': 0.06706821188888336, 'alpha': 0.0026232993055529744, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 281}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:31:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:32:03,893]\u001b[0m Trial 34 finished with value: 0.37326209227815726 and parameters: {'lambda': 0.28023713978041315, 'alpha': 0.001098883757700098, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 280}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:32:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:32:08,015]\u001b[0m Trial 35 finished with value: 0.3736520995328648 and parameters: {'lambda': 0.25273932026371626, 'alpha': 0.001006126023816344, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.014, 'max_depth': 13, 'min_child_weight': 281}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:32:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:32:11,791]\u001b[0m Trial 36 finished with value: 0.37348263379442453 and parameters: {'lambda': 0.495426243375285, 'alpha': 0.0026261140397388903, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.018, 'max_depth': 13, 'min_child_weight': 258}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:32:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:32:16,897]\u001b[0m Trial 37 finished with value: 0.37355661009865504 and parameters: {'lambda': 0.12783250510002406, 'alpha': 0.002280805054761494, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 13, 'min_child_weight': 300}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:32:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:32:23,648]\u001b[0m Trial 38 finished with value: 0.3735921978258347 and parameters: {'lambda': 0.005392887842794181, 'alpha': 0.0010114488143772088, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 5, 'min_child_weight': 281}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:32:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:32:28,046]\u001b[0m Trial 39 finished with value: 0.373412036813312 and parameters: {'lambda': 4.031670225514203, 'alpha': 0.004541053042074165, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 11, 'min_child_weight': 223}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:32:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:32:44,329]\u001b[0m Trial 40 finished with value: 0.3738659813003553 and parameters: {'lambda': 0.27110278397957155, 'alpha': 0.8101100990963048, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 50}. Best is trial 15 with value: 0.37322906072830697.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:32:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:32:52,577]\u001b[0m Trial 41 finished with value: 0.37321053947565463 and parameters: {'lambda': 0.0832332486265797, 'alpha': 0.008887832197292075, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 284}. Best is trial 41 with value: 0.37321053947565463.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:32:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:33:00,933]\u001b[0m Trial 42 finished with value: 0.3731421640572953 and parameters: {'lambda': 0.08826961957711191, 'alpha': 0.01455833806770514, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 288}. Best is trial 42 with value: 0.3731421640572953.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:33:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:33:08,735]\u001b[0m Trial 43 finished with value: 0.3732999862889623 and parameters: {'lambda': 0.1993180910059349, 'alpha': 0.016852219487764476, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 259}. Best is trial 42 with value: 0.3731421640572953.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:33:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:33:16,071]\u001b[0m Trial 44 finished with value: 0.3733207860957513 and parameters: {'lambda': 0.49501800695129355, 'alpha': 0.008915619513436604, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 202}. Best is trial 42 with value: 0.3731421640572953.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:33:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:33:22,235]\u001b[0m Trial 45 finished with value: 0.3735638161789097 and parameters: {'lambda': 0.032581993985287445, 'alpha': 0.13411960696067696, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 296}. Best is trial 42 with value: 0.3731421640572953.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:33:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:33:26,518]\u001b[0m Trial 46 finished with value: 0.3736331439650658 and parameters: {'lambda': 0.08764275184714451, 'alpha': 0.021298661501979194, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 17, 'min_child_weight': 230}. Best is trial 42 with value: 0.3731421640572953.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:33:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:33:31,282]\u001b[0m Trial 47 finished with value: 0.3731988789645186 and parameters: {'lambda': 0.11472964048999039, 'alpha': 0.251328348985497, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 17, 'min_child_weight': 272}. Best is trial 42 with value: 0.3731421640572953.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:33:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:33:36,028]\u001b[0m Trial 48 finished with value: 0.37351671637126593 and parameters: {'lambda': 0.011161969686914597, 'alpha': 0.07135874445399977, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 17, 'min_child_weight': 250}. Best is trial 42 with value: 0.3731421640572953.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:33:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:33:40,762]\u001b[0m Trial 49 finished with value: 0.3732778986858168 and parameters: {'lambda': 0.12781483347055447, 'alpha': 0.28385686661336734, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 17, 'min_child_weight': 273}. Best is trial 42 with value: 0.3731421640572953.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_trial_2 = optuna_xgb.best_trial\n",
        "xgb_best_params_2 = xgb_best_trial_2.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(xgb_best_trial_2.value, xgb_best_params_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4nzLCNrLnFM",
        "outputId": "36f77a10-1555-4d62-b998-9456b6e351f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.3731421640572953,\n",
            "params {'lambda': 0.08826961957711191, 'alpha': 0.01455833806770514, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 288}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_params_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf14dCatLvs_",
        "outputId": "70590f42-5fea-4870-a70f-1867ff642621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lambda': 0.08826961957711191,\n",
              " 'alpha': 0.01455833806770514,\n",
              " 'colsample_bytree': 0.8,\n",
              " 'subsample': 0.8,\n",
              " 'learning_rate': 0.008,\n",
              " 'max_depth': 17,\n",
              " 'min_child_weight': 288}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2_model_1 = XGBRegressor(**xgb_best_params_2)"
      ],
      "metadata": {
        "id": "1xA4tK_3LwYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'random_state': 42,\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "        \n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_drill_scaled, y_drill[:,1], eval_set=[(X_val_scaled,y_val[:,1])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,1], model_lgbm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "DS19KGF-L7pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_lgbm.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVz8bqxbMBET",
        "outputId": "7b380570-e0e1-4506-ef41-043b56bd7b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:35:20,331]\u001b[0m A new study created in memory with name: no-name-407ba9ca-60f5-4148-a27b-00c991599b4d\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:35:28,441]\u001b[0m Trial 0 finished with value: 0.37420151700870447 and parameters: {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:35:53,842]\u001b[0m Trial 1 finished with value: 0.38275743030697074 and parameters: {'max_depth': 5, 'learning_rate': 2.2310108018679158e-08, 'n_estimators': 2612, 'min_child_samples': 62, 'subsample': 0.765297684068612}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:36:01,235]\u001b[0m Trial 2 finished with value: 0.3746326814459143 and parameters: {'max_depth': 3, 'learning_rate': 0.006598711072054081, 'n_estimators': 2514, 'min_child_samples': 25, 'subsample': 0.4725148048142631}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:36:17,188]\u001b[0m Trial 3 finished with value: 0.38274502077196765 and parameters: {'max_depth': 5, 'learning_rate': 6.690421166498788e-07, 'n_estimators': 1622, 'min_child_samples': 46, 'subsample': 0.5223381155442193}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:36:29,790]\u001b[0m Trial 4 finished with value: 0.3827573284784194 and parameters: {'max_depth': 10, 'learning_rate': 6.870101665590006e-08, 'n_estimators': 947, 'min_child_samples': 40, 'subsample': 0.607503080954597}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:36:50,633]\u001b[0m Trial 5 finished with value: 0.3827550191916336 and parameters: {'max_depth': 13, 'learning_rate': 1.577766363058244e-07, 'n_estimators': 1591, 'min_child_samples': 61, 'subsample': 0.4173923345744613}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:36:54,426]\u001b[0m Trial 6 finished with value: 0.382757745070772 and parameters: {'max_depth': 10, 'learning_rate': 1.0547383621352015e-07, 'n_estimators': 288, 'min_child_samples': 96, 'subsample': 0.9689996293810518}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:36:59,439]\u001b[0m Trial 7 finished with value: 0.38275494532908305 and parameters: {'max_depth': 13, 'learning_rate': 6.724850206557239e-07, 'n_estimators': 383, 'min_child_samples': 70, 'subsample': 0.5987069208932017}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:37:01,067]\u001b[0m Trial 8 finished with value: 0.382737445740969 and parameters: {'max_depth': 4, 'learning_rate': 9.355380606452177e-06, 'n_estimators': 199, 'min_child_samples': 92, 'subsample': 0.5070361211081488}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:37:22,027]\u001b[0m Trial 9 finished with value: 0.382743352002765 and parameters: {'max_depth': 11, 'learning_rate': 7.417652034871823e-07, 'n_estimators': 1608, 'min_child_samples': 57, 'subsample': 0.47382827709841974}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:37:33,321]\u001b[0m Trial 10 finished with value: 0.37422052122408545 and parameters: {'max_depth': 7, 'learning_rate': 0.003955232336089218, 'n_estimators': 2119, 'min_child_samples': 6, 'subsample': 0.405672369598035}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:37:39,554]\u001b[0m Trial 11 finished with value: 0.37435600216110926 and parameters: {'max_depth': 7, 'learning_rate': 0.007953409633698581, 'n_estimators': 2167, 'min_child_samples': 13, 'subsample': 0.4013720109047739}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:38:07,000]\u001b[0m Trial 12 finished with value: 0.37662025353177264 and parameters: {'max_depth': 7, 'learning_rate': 0.0004511388495675214, 'n_estimators': 2070, 'min_child_samples': 9, 'subsample': 0.4062952147191863}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:38:43,675]\u001b[0m Trial 13 finished with value: 0.376037847149958 and parameters: {'max_depth': 7, 'learning_rate': 0.00037539053857553006, 'n_estimators': 2990, 'min_child_samples': 80, 'subsample': 0.7228898200777368}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:39:10,738]\u001b[0m Trial 14 finished with value: 0.3759309160210844 and parameters: {'max_depth': 8, 'learning_rate': 0.0005559231881814425, 'n_estimators': 2115, 'min_child_samples': 31, 'subsample': 0.5500437593750167}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:39:25,671]\u001b[0m Trial 15 finished with value: 0.382086625397698 and parameters: {'max_depth': 15, 'learning_rate': 4.9891950471885754e-05, 'n_estimators': 1094, 'min_child_samples': 23, 'subsample': 0.4613200801565298}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:39:42,908]\u001b[0m Trial 16 finished with value: 0.3743148664853466 and parameters: {'max_depth': 6, 'learning_rate': 0.001983842523248026, 'n_estimators': 2469, 'min_child_samples': 76, 'subsample': 0.4403660616338505}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:40:08,253]\u001b[0m Trial 17 finished with value: 0.381648042958953 and parameters: {'max_depth': 9, 'learning_rate': 4.8601229212599175e-05, 'n_estimators': 1902, 'min_child_samples': 43, 'subsample': 0.7049150949211169}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:40:24,432]\u001b[0m Trial 18 finished with value: 0.3816257230635656 and parameters: {'max_depth': 9, 'learning_rate': 8.079185621006249e-05, 'n_estimators': 1162, 'min_child_samples': 50, 'subsample': 0.848318087347811}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:40:40,159]\u001b[0m Trial 19 finished with value: 0.37491123900416784 and parameters: {'max_depth': 3, 'learning_rate': 0.0018760249817966635, 'n_estimators': 2911, 'min_child_samples': 32, 'subsample': 0.5520069211471134}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:40:58,407]\u001b[0m Trial 20 finished with value: 0.3825565482179792 and parameters: {'max_depth': 5, 'learning_rate': 9.032360273921872e-06, 'n_estimators': 1867, 'min_child_samples': 86, 'subsample': 0.43882360636947054}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:41:13,502]\u001b[0m Trial 21 finished with value: 0.3742770589867332 and parameters: {'max_depth': 6, 'learning_rate': 0.002275267507229588, 'n_estimators': 2418, 'min_child_samples': 74, 'subsample': 0.4447116844408013}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:41:26,146]\u001b[0m Trial 22 finished with value: 0.3742538402343489 and parameters: {'max_depth': 6, 'learning_rate': 0.002978012537565063, 'n_estimators': 2350, 'min_child_samples': 69, 'subsample': 0.4954273064643754}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:41:32,051]\u001b[0m Trial 23 finished with value: 0.37421218445857857 and parameters: {'max_depth': 8, 'learning_rate': 0.007798433911930324, 'n_estimators': 2743, 'min_child_samples': 67, 'subsample': 0.5003378679250625}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:41:37,493]\u001b[0m Trial 24 finished with value: 0.374231051833237 and parameters: {'max_depth': 11, 'learning_rate': 0.009815557522885744, 'n_estimators': 2718, 'min_child_samples': 54, 'subsample': 0.5650433540729568}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:42:12,182]\u001b[0m Trial 25 finished with value: 0.374459276406404 and parameters: {'max_depth': 8, 'learning_rate': 0.0008211155134754221, 'n_estimators': 2749, 'min_child_samples': 63, 'subsample': 0.6393081255554448}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:42:41,271]\u001b[0m Trial 26 finished with value: 0.37990311762168644 and parameters: {'max_depth': 8, 'learning_rate': 0.00012272187354340748, 'n_estimators': 2275, 'min_child_samples': 84, 'subsample': 0.5052455574188839}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:43:07,086]\u001b[0m Trial 27 finished with value: 0.3797367823904468 and parameters: {'max_depth': 10, 'learning_rate': 0.00016009978608557898, 'n_estimators': 1885, 'min_child_samples': 37, 'subsample': 0.4257099506394959}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:43:37,117]\u001b[0m Trial 28 finished with value: 0.3743321360847384 and parameters: {'max_depth': 8, 'learning_rate': 0.001345146486278336, 'n_estimators': 2796, 'min_child_samples': 20, 'subsample': 0.47251338267208376}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:43:48,637]\u001b[0m Trial 29 finished with value: 0.3743366687456379 and parameters: {'max_depth': 4, 'learning_rate': 0.004476035392038651, 'n_estimators': 2596, 'min_child_samples': 60, 'subsample': 0.6410141895301197}. Best is trial 0 with value: 0.37420151700870447.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_trial_2 = optuna_lgbm.best_trial\n",
        "lgbm_best_params_2 = lgbm_best_trial_2.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_best_trial_2.value, lgbm_best_params_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxDMI-YdMKzE",
        "outputId": "aaa1b074-a2a8-4ec0-b25b-ec8238081f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.37420151700870447,\n",
            "params {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfZHSDn1MR_v",
        "outputId": "a4768553-7964-4b13-9725-52cf3607e789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 7,\n",
              " 'learning_rate': 0.005061576888752304,\n",
              " 'n_estimators': 2223,\n",
              " 'min_child_samples': 62,\n",
              " 'subsample': 0.46147273880126555}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2_model_2 = LGBMRegressor(**lgbm_best_params_2)"
      ],
      "metadata": {
        "id": "VWMV_epQMZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###y3"
      ],
      "metadata": {
        "id": "OlsQ8J2gMQ0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
        "        'n_estimators': 10000,\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
        "        'random_state': 42,\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_xgb = XGBRegressor(**param)\n",
        "    model_xgb = model_xgb.fit(X_drill_scaled, y_drill[:,2], eval_set=[(X_val_scaled,y_val[:,2])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,2], model_xgb.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "ESaDqCxZMRqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_xgb.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJkai6FOMjvt",
        "outputId": "6e23059b-1941-44d9-dd81-26364426f9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:00,088]\u001b[0m A new study created in memory with name: no-name-d9a0518a-de8a-4810-9280-6fd49192c16f\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:03,923]\u001b[0m Trial 0 finished with value: 0.355559607826247 and parameters: {'lambda': 0.03148911647956861, 'alpha': 6.351221010640703, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 183}. Best is trial 0 with value: 0.355559607826247.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:07,728]\u001b[0m Trial 1 finished with value: 0.35517054765424416 and parameters: {'lambda': 0.004809461967501573, 'alpha': 0.0018205657658407262, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 7, 'min_child_weight': 82}. Best is trial 1 with value: 0.35517054765424416.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:12,886]\u001b[0m Trial 2 finished with value: 0.3552269171668543 and parameters: {'lambda': 2.0651425578959257, 'alpha': 0.026730883107816707, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 11, 'min_child_weight': 229}. Best is trial 1 with value: 0.35517054765424416.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:23,062]\u001b[0m Trial 3 finished with value: 0.3563488683407155 and parameters: {'lambda': 0.17583640270008521, 'alpha': 1.2130221181165162, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 34}. Best is trial 1 with value: 0.35517054765424416.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:30,210]\u001b[0m Trial 4 finished with value: 0.3551928462203619 and parameters: {'lambda': 0.008160948743089917, 'alpha': 0.05110120656497164, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 11, 'min_child_weight': 296}. Best is trial 1 with value: 0.35517054765424416.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:33,686]\u001b[0m Trial 5 finished with value: 0.3556048482606508 and parameters: {'lambda': 0.009294394155644996, 'alpha': 0.4881375191603672, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 5, 'min_child_weight': 198}. Best is trial 1 with value: 0.35517054765424416.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:41,116]\u001b[0m Trial 6 finished with value: 0.35543859546994044 and parameters: {'lambda': 1.857328833311487, 'alpha': 0.16626592254031872, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'min_child_weight': 98}. Best is trial 1 with value: 0.35517054765424416.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:45,695]\u001b[0m Trial 7 finished with value: 0.3551795315827827 and parameters: {'lambda': 0.9682012086882473, 'alpha': 0.39676339357448603, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 7, 'min_child_weight': 290}. Best is trial 1 with value: 0.35517054765424416.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:44:53,640]\u001b[0m Trial 8 finished with value: 0.35509778342972875 and parameters: {'lambda': 7.152863022216533, 'alpha': 2.5824850844906155, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 211}. Best is trial 8 with value: 0.35509778342972875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:44:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:01,939]\u001b[0m Trial 9 finished with value: 0.35550849673100215 and parameters: {'lambda': 1.5246518242848615, 'alpha': 3.6309591863459096, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 82}. Best is trial 8 with value: 0.35509778342972875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:09,135]\u001b[0m Trial 10 finished with value: 0.35516490368263554 and parameters: {'lambda': 8.279350403364669, 'alpha': 0.012047666811939929, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 141}. Best is trial 8 with value: 0.35509778342972875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:16,253]\u001b[0m Trial 11 finished with value: 0.35519127416817387 and parameters: {'lambda': 8.351356671126828, 'alpha': 0.006391960026231511, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 142}. Best is trial 8 with value: 0.35509778342972875.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:25,106]\u001b[0m Trial 12 finished with value: 0.35499190084094284 and parameters: {'lambda': 9.462857782721922, 'alpha': 0.009125703046060935, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 238}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:29,450]\u001b[0m Trial 13 finished with value: 0.355506615841048 and parameters: {'lambda': 0.2713009772781659, 'alpha': 0.0014993772924073567, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 17, 'min_child_weight': 239}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:37,954]\u001b[0m Trial 14 finished with value: 0.35500016792230127 and parameters: {'lambda': 9.193124422119851, 'alpha': 0.11478407957753776, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 250}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:46,361]\u001b[0m Trial 15 finished with value: 0.35505073984533114 and parameters: {'lambda': 0.5521008712893732, 'alpha': 0.10559236941839761, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 254}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:50,758]\u001b[0m Trial 16 finished with value: 0.355655401554836 and parameters: {'lambda': 0.04579588598371662, 'alpha': 0.006270684688334842, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 17, 'min_child_weight': 254}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:55,202]\u001b[0m Trial 17 finished with value: 0.3552461161027382 and parameters: {'lambda': 3.319138532837898, 'alpha': 0.03316550427141604, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 13, 'min_child_weight': 172}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:45:59,371]\u001b[0m Trial 18 finished with value: 0.35513913938309427 and parameters: {'lambda': 0.0010580531606414745, 'alpha': 0.31914768556465617, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.016, 'max_depth': 17, 'min_child_weight': 271}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:45:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:46:08,594]\u001b[0m Trial 19 finished with value: 0.35567035429333643 and parameters: {'lambda': 0.4776213087783672, 'alpha': 0.011618658994824702, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 215}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:46:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:46:14,316]\u001b[0m Trial 20 finished with value: 0.3551375496919667 and parameters: {'lambda': 4.241989129713303, 'alpha': 0.003662682774828239, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 5, 'min_child_weight': 265}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:46:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:46:23,277]\u001b[0m Trial 21 finished with value: 0.35511828747497304 and parameters: {'lambda': 0.8798651174380997, 'alpha': 0.09678749800942096, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 245}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:46:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:46:30,889]\u001b[0m Trial 22 finished with value: 0.3551057959329397 and parameters: {'lambda': 0.5063372770920699, 'alpha': 0.10547389652146037, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 273}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:46:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:46:40,302]\u001b[0m Trial 23 finished with value: 0.3552894216248845 and parameters: {'lambda': 0.06697341383613581, 'alpha': 0.05234879341270121, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 163}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:46:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:46:48,042]\u001b[0m Trial 24 finished with value: 0.3550129746883087 and parameters: {'lambda': 3.8978963595592497, 'alpha': 0.022130172021307407, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 227}. Best is trial 12 with value: 0.35499190084094284.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:46:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:46:55,708]\u001b[0m Trial 25 finished with value: 0.35496641402329915 and parameters: {'lambda': 3.8848151073401094, 'alpha': 0.019851381063929176, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 223}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:46:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:46:59,698]\u001b[0m Trial 26 finished with value: 0.35522165463887184 and parameters: {'lambda': 9.416917228021687, 'alpha': 0.012431528909590928, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 193}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:46:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:47:05,778]\u001b[0m Trial 27 finished with value: 0.35526280854189524 and parameters: {'lambda': 3.4093844391630417, 'alpha': 0.005819252344626984, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.012, 'max_depth': 13, 'min_child_weight': 121}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:47:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:47:31,891]\u001b[0m Trial 28 finished with value: 0.3562244958360559 and parameters: {'lambda': 4.965171497423749, 'alpha': 0.00302615785492175, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.01, 'max_depth': 13, 'min_child_weight': 10}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:47:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:47:35,399]\u001b[0m Trial 29 finished with value: 0.35557493901940335 and parameters: {'lambda': 2.2185624815731058, 'alpha': 0.2057375904899793, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.016, 'max_depth': 5, 'min_child_weight': 190}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:47:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:47:39,409]\u001b[0m Trial 30 finished with value: 0.35540994689008254 and parameters: {'lambda': 0.13858974359702522, 'alpha': 0.0479786823409088, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.018, 'max_depth': 15, 'min_child_weight': 213}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:47:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:47:47,058]\u001b[0m Trial 31 finished with value: 0.3550451841428592 and parameters: {'lambda': 4.0644334904986845, 'alpha': 0.01982640374497035, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 226}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:47:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:47:52,180]\u001b[0m Trial 32 finished with value: 0.35519913324388125 and parameters: {'lambda': 1.095669052141704, 'alpha': 0.016020118273453007, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.014, 'max_depth': 13, 'min_child_weight': 280}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:47:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:47:58,768]\u001b[0m Trial 33 finished with value: 0.3550500508245405 and parameters: {'lambda': 2.488072254449236, 'alpha': 0.02749437605236705, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 7, 'min_child_weight': 237}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:47:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:48:06,208]\u001b[0m Trial 34 finished with value: 0.35528838823078585 and parameters: {'lambda': 6.487891640956987, 'alpha': 0.0027382683167750835, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 177}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:48:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:48:11,308]\u001b[0m Trial 35 finished with value: 0.35539068978706784 and parameters: {'lambda': 0.01834696951392378, 'alpha': 0.0010746111186170073, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 13, 'min_child_weight': 224}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:48:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:48:20,091]\u001b[0m Trial 36 finished with value: 0.3551473136151513 and parameters: {'lambda': 5.136756638092661, 'alpha': 0.9564892321143684, 'colsample_bytree': 0.4, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 11, 'min_child_weight': 200}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:48:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:48:23,192]\u001b[0m Trial 37 finished with value: 0.3551543239795577 and parameters: {'lambda': 1.469930812967103, 'alpha': 0.07027101022866246, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.016, 'max_depth': 7, 'min_child_weight': 300}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:48:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:48:28,321]\u001b[0m Trial 38 finished with value: 0.35522351045006617 and parameters: {'lambda': 2.5620819851390775, 'alpha': 0.03226005044656041, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 257}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:48:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:48:39,531]\u001b[0m Trial 39 finished with value: 0.355394422951001 and parameters: {'lambda': 9.733017764797264, 'alpha': 0.007549756948981884, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 157}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:48:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:48:49,097]\u001b[0m Trial 40 finished with value: 0.3551822541237612 and parameters: {'lambda': 0.27110278397957155, 'alpha': 0.0207160492687418, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 50}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:48:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:48:57,186]\u001b[0m Trial 41 finished with value: 0.35503762486272783 and parameters: {'lambda': 4.376977081867645, 'alpha': 0.020145087156701266, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 231}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:48:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:49:04,976]\u001b[0m Trial 42 finished with value: 0.35501355260795137 and parameters: {'lambda': 5.931461705327892, 'alpha': 0.043228445419496546, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 232}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:49:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:49:11,877]\u001b[0m Trial 43 finished with value: 0.35502265749939854 and parameters: {'lambda': 6.080301501815885, 'alpha': 0.15585026392785156, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 283}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:49:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:49:17,401]\u001b[0m Trial 44 finished with value: 0.3552204014293113 and parameters: {'lambda': 1.5024373238856568, 'alpha': 0.041543616109514715, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 202}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:49:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:49:23,739]\u001b[0m Trial 45 finished with value: 0.3553035034997716 and parameters: {'lambda': 9.910342136264132, 'alpha': 8.360603301436354, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 252}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:49:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:49:27,564]\u001b[0m Trial 46 finished with value: 0.3554073020928509 and parameters: {'lambda': 2.803783521925677, 'alpha': 0.06165207006716067, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.018, 'max_depth': 13, 'min_child_weight': 220}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:49:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:49:32,142]\u001b[0m Trial 47 finished with value: 0.35537909321506916 and parameters: {'lambda': 0.893226357077361, 'alpha': 0.251328348985497, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 5, 'min_child_weight': 241}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:49:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:49:40,490]\u001b[0m Trial 48 finished with value: 0.3551304523384604 and parameters: {'lambda': 6.649903042693145, 'alpha': 0.00946848856399576, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 263}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04:49:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:49:43,268]\u001b[0m Trial 49 finished with value: 0.3552169950210778 and parameters: {'lambda': 2.1940876770968782, 'alpha': 0.7273463510623219, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 206}. Best is trial 25 with value: 0.35496641402329915.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_trial_3 = optuna_xgb.best_trial\n",
        "xgb_best_params_3 = xgb_best_trial_3.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(xgb_best_trial_3.value, xgb_best_params_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5us_jzprMln9",
        "outputId": "afc62eb3-cc27-469e-ba06-9134cb776e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.35496641402329915,\n",
            "params {'lambda': 3.8848151073401094, 'alpha': 0.019851381063929176, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 223}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_params_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX4yrWYwM4hH",
        "outputId": "9bd5f1b0-b288-4d6c-bb02-30d0f0a80b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lambda': 3.8848151073401094,\n",
              " 'alpha': 0.019851381063929176,\n",
              " 'colsample_bytree': 0.9,\n",
              " 'subsample': 0.7,\n",
              " 'learning_rate': 0.008,\n",
              " 'max_depth': 13,\n",
              " 'min_child_weight': 223}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3_model_1 = XGBRegressor(**xgb_best_params_3)"
      ],
      "metadata": {
        "id": "dZsSkpdkM-xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'random_state': 42,\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "        \n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_drill_scaled, y_drill[:,2], eval_set=[(X_val_scaled,y_val[:,2])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,2], model_lgbm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "HAXd0-2-aeIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_lgbm.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iS1T9cPagUC",
        "outputId": "a05d306e-2ec7-4a06-e1b1-ac73374bd511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 04:50:39,930]\u001b[0m A new study created in memory with name: no-name-c07a337f-6a8c-438e-9c30-d8e6bd972db2\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:50:51,439]\u001b[0m Trial 0 finished with value: 0.3550414474413704 and parameters: {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:51:19,111]\u001b[0m Trial 1 finished with value: 0.36256314831695946 and parameters: {'max_depth': 5, 'learning_rate': 2.2310108018679158e-08, 'n_estimators': 2612, 'min_child_samples': 62, 'subsample': 0.765297684068612}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:51:27,809]\u001b[0m Trial 2 finished with value: 0.3561467433423532 and parameters: {'max_depth': 3, 'learning_rate': 0.006598711072054081, 'n_estimators': 2514, 'min_child_samples': 25, 'subsample': 0.4725148048142631}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:51:45,607]\u001b[0m Trial 3 finished with value: 0.3625520116870106 and parameters: {'max_depth': 5, 'learning_rate': 6.690421166498788e-07, 'n_estimators': 1622, 'min_child_samples': 46, 'subsample': 0.5223381155442193}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:51:58,736]\u001b[0m Trial 4 finished with value: 0.3625630707378992 and parameters: {'max_depth': 10, 'learning_rate': 6.870101665590006e-08, 'n_estimators': 947, 'min_child_samples': 40, 'subsample': 0.607503080954597}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:52:20,638]\u001b[0m Trial 5 finished with value: 0.36256109902947103 and parameters: {'max_depth': 13, 'learning_rate': 1.577766363058244e-07, 'n_estimators': 1591, 'min_child_samples': 61, 'subsample': 0.4173923345744613}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:52:24,482]\u001b[0m Trial 6 finished with value: 0.3625634412140307 and parameters: {'max_depth': 10, 'learning_rate': 1.0547383621352015e-07, 'n_estimators': 288, 'min_child_samples': 96, 'subsample': 0.9689996293810518}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:52:29,620]\u001b[0m Trial 7 finished with value: 0.36256102971171733 and parameters: {'max_depth': 13, 'learning_rate': 6.724850206557239e-07, 'n_estimators': 383, 'min_child_samples': 70, 'subsample': 0.5987069208932017}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:52:31,369]\u001b[0m Trial 8 finished with value: 0.3625464243255413 and parameters: {'max_depth': 4, 'learning_rate': 9.355380606452177e-06, 'n_estimators': 199, 'min_child_samples': 92, 'subsample': 0.5070361211081488}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:52:53,527]\u001b[0m Trial 9 finished with value: 0.3625511304554266 and parameters: {'max_depth': 11, 'learning_rate': 7.417652034871823e-07, 'n_estimators': 1608, 'min_child_samples': 57, 'subsample': 0.47382827709841974}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:53:05,279]\u001b[0m Trial 10 finished with value: 0.3557429355461426 and parameters: {'max_depth': 7, 'learning_rate': 0.003955232336089218, 'n_estimators': 2119, 'min_child_samples': 6, 'subsample': 0.405672369598035}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:53:11,603]\u001b[0m Trial 11 finished with value: 0.3555747159600703 and parameters: {'max_depth': 7, 'learning_rate': 0.007953409633698581, 'n_estimators': 2167, 'min_child_samples': 13, 'subsample': 0.4013720109047739}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:53:41,237]\u001b[0m Trial 12 finished with value: 0.3577778536404784 and parameters: {'max_depth': 7, 'learning_rate': 0.0004511388495675214, 'n_estimators': 2070, 'min_child_samples': 9, 'subsample': 0.4060696340155517}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:54:20,191]\u001b[0m Trial 13 finished with value: 0.35960199730399045 and parameters: {'max_depth': 7, 'learning_rate': 0.0001378296140671229, 'n_estimators': 2991, 'min_child_samples': 80, 'subsample': 0.7228898200777368}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:54:47,922]\u001b[0m Trial 14 finished with value: 0.35722071912395204 and parameters: {'max_depth': 8, 'learning_rate': 0.0005559231881814425, 'n_estimators': 2115, 'min_child_samples': 31, 'subsample': 0.5500437593750167}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:55:04,950]\u001b[0m Trial 15 finished with value: 0.36221543972840925 and parameters: {'max_depth': 15, 'learning_rate': 3.213476103996379e-05, 'n_estimators': 1094, 'min_child_samples': 21, 'subsample': 0.4595849978287922}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:55:29,977]\u001b[0m Trial 16 finished with value: 0.35536002009604173 and parameters: {'max_depth': 6, 'learning_rate': 0.001601446145845733, 'n_estimators': 2469, 'min_child_samples': 76, 'subsample': 0.7368481236544839}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:55:51,569]\u001b[0m Trial 17 finished with value: 0.35556153386805545 and parameters: {'max_depth': 5, 'learning_rate': 0.0017342958744185123, 'n_estimators': 2900, 'min_child_samples': 79, 'subsample': 0.7391188697913744}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:56:25,171]\u001b[0m Trial 18 finished with value: 0.36169108637073666 and parameters: {'max_depth': 9, 'learning_rate': 3.797935773199829e-05, 'n_estimators': 2495, 'min_child_samples': 77, 'subsample': 0.860752772266864}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:56:36,339]\u001b[0m Trial 19 finished with value: 0.3578317103473758 and parameters: {'max_depth': 3, 'learning_rate': 0.0011139995175226236, 'n_estimators': 1848, 'min_child_samples': 88, 'subsample': 0.6884417887303066}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:56:48,940]\u001b[0m Trial 20 finished with value: 0.3613546139339419 and parameters: {'max_depth': 6, 'learning_rate': 0.0001379020609068817, 'n_estimators': 988, 'min_child_samples': 69, 'subsample': 0.8307857150098001}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:57:11,905]\u001b[0m Trial 21 finished with value: 0.3555212291177131 and parameters: {'max_depth': 5, 'learning_rate': 0.0016834010522167406, 'n_estimators': 2985, 'min_child_samples': 79, 'subsample': 0.660164183827859}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:57:37,840]\u001b[0m Trial 22 finished with value: 0.3551448338806889 and parameters: {'max_depth': 6, 'learning_rate': 0.0019230366111619825, 'n_estimators': 2752, 'min_child_samples': 47, 'subsample': 0.6862782787134123}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:58:14,602]\u001b[0m Trial 23 finished with value: 0.3593581895018411 and parameters: {'max_depth': 8, 'learning_rate': 0.00016825565583805508, 'n_estimators': 2699, 'min_child_samples': 49, 'subsample': 0.5824966762523344}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:58:20,656]\u001b[0m Trial 24 finished with value: 0.35521963265671186 and parameters: {'max_depth': 6, 'learning_rate': 0.009815557522885744, 'n_estimators': 2355, 'min_child_samples': 39, 'subsample': 0.8226445040551433}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:58:27,569]\u001b[0m Trial 25 finished with value: 0.3554657562644811 and parameters: {'max_depth': 9, 'learning_rate': 0.007417447003353527, 'n_estimators': 2264, 'min_child_samples': 39, 'subsample': 0.8141195310534456}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:58:50,327]\u001b[0m Trial 26 finished with value: 0.35825805631150137 and parameters: {'max_depth': 6, 'learning_rate': 0.00041859733230219324, 'n_estimators': 1809, 'min_child_samples': 37, 'subsample': 0.9861901908351861}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:59:00,262]\u001b[0m Trial 27 finished with value: 0.3624910127266046 and parameters: {'max_depth': 4, 'learning_rate': 6.268549755666761e-06, 'n_estimators': 1259, 'min_child_samples': 54, 'subsample': 0.9103805812619469}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:59:18,362]\u001b[0m Trial 28 finished with value: 0.355269096032383 and parameters: {'max_depth': 8, 'learning_rate': 0.0027221094031173935, 'n_estimators': 2749, 'min_child_samples': 46, 'subsample': 0.6425919425168719}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 04:59:37,199]\u001b[0m Trial 29 finished with value: 0.3620013210757844 and parameters: {'max_depth': 4, 'learning_rate': 2.860849747230363e-05, 'n_estimators': 2379, 'min_child_samples': 67, 'subsample': 0.7936211961587101}. Best is trial 0 with value: 0.3550414474413704.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_trial_3 = optuna_lgbm.best_trial\n",
        "lgbm_best_params_3 = lgbm_best_trial_3.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_best_trial_3.value, lgbm_best_params_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYL8yoXdajxp",
        "outputId": "9cddd80b-9ff2-402f-e72e-18dd46d8e9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.3550414474413704,\n",
            "params {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct9EN1_QatFN",
        "outputId": "6cb77287-f426-4429-9e1b-a39caf942c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 7,\n",
              " 'learning_rate': 0.005061576888752304,\n",
              " 'n_estimators': 2223,\n",
              " 'min_child_samples': 62,\n",
              " 'subsample': 0.46147273880126555}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3_model_2 = LGBMRegressor(**lgbm_best_params_3)"
      ],
      "metadata": {
        "id": "0bBlIddcauD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQW8izPV-OVC"
      },
      "source": [
        "### y4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by9_ViiQxK-K"
      },
      "outputs": [],
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    cbrm_param = {\n",
        "        'random_state': 42,\n",
        "        'iterations':trial.suggest_int(\"iterations\", 4000, 25000),\n",
        "        'od_wait':trial.suggest_int('od_wait', 500, 2300),\n",
        "        'learning_rate' : trial.suggest_uniform('learning_rate',0.01, 1),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "        'subsample': trial.suggest_uniform('subsample',0,1),\n",
        "        'random_strength': trial.suggest_uniform('random_strength',10,50),\n",
        "        'depth': trial.suggest_int('depth',1, 15),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
        "        'colsample_bylevel':trial.suggest_float('colsample_bylevel', 0.4, 1.0),\n",
        "    }\n",
        "    \n",
        "    # Generate model\n",
        "    model_cbrm = CatBoostRegressor(**cbrm_param, verbose=False)\n",
        "    model_cbrm = model_cbrm.fit(X_drill_scaled, y_drill[:,3], eval_set=[(X_val_scaled,y_val[:,3])],early_stopping_rounds=20)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,3], model_cbrm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2z67jYN1WEV"
      },
      "outputs": [],
      "source": [
        "optuna_cbrm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_cbrm.optimize(objective, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MAbAlPC9vOP",
        "outputId": "249fa012-1bb4-4f36-c267-2cf782af9521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Trial: score 2.5568695741484317,\n",
            "params {'iterations': 15657, 'od_wait': 1553, 'learning_rate': 0.030487905795041025, 'reg_lambda': 34.00019239822573, 'subsample': 0.37397770574158457, 'random_strength': 37.94294097963467, 'depth': 11, 'min_data_in_leaf': 19, 'leaf_estimation_iterations': 1, 'bagging_temperature': 0.020178246873757116, 'colsample_bylevel': 0.6202779918035656}\n"
          ]
        }
      ],
      "source": [
        "cbrm_best_trial_4 = optuna_cbrm.best_trial\n",
        "cbrm_best_params_4 = cbrm_best_trial_4.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(cbrm_best_trial_4.value, cbrm_best_params_4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFUhEMgWaGH5"
      },
      "outputs": [],
      "source": [
        "cbrm_best_params_4 = {'iterations': 15657,\n",
        " 'od_wait': 1553,\n",
        " 'learning_rate': 0.030487905795041025,\n",
        " 'reg_lambda': 34.00019239822573,\n",
        " 'subsample': 0.37397770574158457,\n",
        " 'random_strength': 37.94294097963467,\n",
        " 'depth': 11,\n",
        " 'min_data_in_leaf': 19,\n",
        " 'leaf_estimation_iterations': 1,\n",
        " 'bagging_temperature': 0.020178246873757116,\n",
        " 'colsample_bylevel': 0.6202779918035656}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbrm_best_params_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1OuLA292Oxw",
        "outputId": "01cb503a-1765-4204-e9d9-2f161301b97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'iterations': 15657,\n",
              " 'od_wait': 1553,\n",
              " 'learning_rate': 0.030487905795041025,\n",
              " 'reg_lambda': 34.00019239822573,\n",
              " 'subsample': 0.37397770574158457,\n",
              " 'random_strength': 37.94294097963467,\n",
              " 'depth': 11,\n",
              " 'min_data_in_leaf': 19,\n",
              " 'leaf_estimation_iterations': 1,\n",
              " 'bagging_temperature': 0.020178246873757116,\n",
              " 'colsample_bylevel': 0.6202779918035656}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W603juLi-Xh-"
      },
      "outputs": [],
      "source": [
        "y4_model = CatBoostRegressor(**cbrm_best_params_4,verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ4h0B6hAZ_f",
        "outputId": "b20a9fb5-d4e0-4597-fa73-4599f0d8c2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test loss: 2.5563737023178223\n",
            "test loss: 2.5563737023178223\n"
          ]
        }
      ],
      "source": [
        "y4_model.fit(X_train_scaled,y_train[:,3]) #전체 test data fit\n",
        "y4_pred = y4_model.predict(X_test_scaled)\n",
        "print(f'test loss: {rmse(y_test[:,3],y4_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### y5"
      ],
      "metadata": {
        "id": "lhAauX4gcr9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
        "        'n_estimators': 10000,\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
        "        'random_state': 42,\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_xgb = XGBRegressor(**param)\n",
        "    model_xgb = model_xgb.fit(X_drill_scaled, y_drill[:,4], eval_set=[(X_val_scaled,y_val[:,4])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,4], model_xgb.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "Nn79SpFRcs85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_xgb.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsr_mOyQc0q-",
        "outputId": "7daf1e09-afae-443f-cecb-d453e2aa4b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:00:35,556]\u001b[0m A new study created in memory with name: no-name-fad5f27b-3a2b-41eb-b14e-d0b39f8b81c9\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:00:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:00:42,191]\u001b[0m Trial 0 finished with value: 2.4990680967751913 and parameters: {'lambda': 0.03148911647956861, 'alpha': 6.351221010640703, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 183}. Best is trial 0 with value: 2.4990680967751913.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:00:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:00:49,912]\u001b[0m Trial 1 finished with value: 2.501670187197153 and parameters: {'lambda': 0.004809461967501573, 'alpha': 0.0018205657658407262, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 7, 'min_child_weight': 82}. Best is trial 0 with value: 2.4990680967751913.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:00:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:00:57,740]\u001b[0m Trial 2 finished with value: 2.5006912937636527 and parameters: {'lambda': 2.0651425578959257, 'alpha': 0.026730883107816707, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 11, 'min_child_weight': 229}. Best is trial 0 with value: 2.4990680967751913.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:00:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:01:07,364]\u001b[0m Trial 3 finished with value: 2.5034149270688655 and parameters: {'lambda': 0.17583640270008521, 'alpha': 1.2130221181165162, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 34}. Best is trial 0 with value: 2.4990680967751913.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:01:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:01:21,310]\u001b[0m Trial 4 finished with value: 2.502539996274895 and parameters: {'lambda': 0.008160948743089917, 'alpha': 0.05110120656497164, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 11, 'min_child_weight': 296}. Best is trial 0 with value: 2.4990680967751913.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:01:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:01:25,706]\u001b[0m Trial 5 finished with value: 2.5135243190198797 and parameters: {'lambda': 0.009294394155644996, 'alpha': 0.4881375191603672, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 5, 'min_child_weight': 198}. Best is trial 0 with value: 2.4990680967751913.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:01:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:01:35,509]\u001b[0m Trial 6 finished with value: 2.500326151738251 and parameters: {'lambda': 1.857328833311487, 'alpha': 0.16626592254031872, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'min_child_weight': 98}. Best is trial 0 with value: 2.4990680967751913.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:01:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:01:42,207]\u001b[0m Trial 7 finished with value: 2.5056343659211513 and parameters: {'lambda': 0.9682012086882473, 'alpha': 0.39676339357448603, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 7, 'min_child_weight': 290}. Best is trial 0 with value: 2.4990680967751913.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:01:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:01:54,187]\u001b[0m Trial 8 finished with value: 2.4979164467712107 and parameters: {'lambda': 7.152863022216533, 'alpha': 2.5824850844906155, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 211}. Best is trial 8 with value: 2.4979164467712107.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:01:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:02:05,724]\u001b[0m Trial 9 finished with value: 2.4982084032442353 and parameters: {'lambda': 1.5246518242848615, 'alpha': 3.6309591863459096, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 82}. Best is trial 8 with value: 2.4979164467712107.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:02:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:02:18,670]\u001b[0m Trial 10 finished with value: 2.49815703985606 and parameters: {'lambda': 8.279350403364669, 'alpha': 0.012047666811939929, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 141}. Best is trial 8 with value: 2.4979164467712107.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:02:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:02:28,165]\u001b[0m Trial 11 finished with value: 2.500684998025554 and parameters: {'lambda': 8.351356671126828, 'alpha': 0.006391960026231511, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 142}. Best is trial 8 with value: 2.4979164467712107.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:02:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:02:45,797]\u001b[0m Trial 12 finished with value: 2.4986538704433827 and parameters: {'lambda': 9.462857782721922, 'alpha': 0.009125703046060935, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 238}. Best is trial 8 with value: 2.4979164467712107.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:02:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:02:52,108]\u001b[0m Trial 13 finished with value: 2.495173597189685 and parameters: {'lambda': 0.2500649904434222, 'alpha': 0.0015894230399720935, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 140}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:02:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:02:59,922]\u001b[0m Trial 14 finished with value: 2.499392949465652 and parameters: {'lambda': 0.2276933995624736, 'alpha': 0.0012565605786636939, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 180}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:02:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:03:06,600]\u001b[0m Trial 15 finished with value: 2.5001684905121584 and parameters: {'lambda': 0.04957206030704909, 'alpha': 2.3915437088171982, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 243}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:03:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:03:29,849]\u001b[0m Trial 16 finished with value: 2.5046173800168177 and parameters: {'lambda': 0.49230683152876065, 'alpha': 0.18068577598737837, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 4}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:03:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:03:36,780]\u001b[0m Trial 17 finished with value: 2.5043585205938643 and parameters: {'lambda': 0.001797476319369944, 'alpha': 8.525986234166632, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 17, 'min_child_weight': 117}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:03:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:03:42,372]\u001b[0m Trial 18 finished with value: 2.505854939986882 and parameters: {'lambda': 0.058990874765006, 'alpha': 0.0041581206084253825, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.016, 'max_depth': 5, 'min_child_weight': 208}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:03:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:03:47,663]\u001b[0m Trial 19 finished with value: 2.501341940726268 and parameters: {'lambda': 0.4776213087783672, 'alpha': 0.055567989531313984, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 170}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:03:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:03:53,434]\u001b[0m Trial 20 finished with value: 2.5058896478967503 and parameters: {'lambda': 0.021185819775176223, 'alpha': 1.204420405620433, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 55}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:03:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:04:06,240]\u001b[0m Trial 21 finished with value: 2.498471185950677 and parameters: {'lambda': 4.384226592036239, 'alpha': 0.013966979504275848, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 147}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:04:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:04:17,340]\u001b[0m Trial 22 finished with value: 2.5000385908589045 and parameters: {'lambda': 4.371958364600178, 'alpha': 0.0028104486004634985, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 134}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:04:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:04:28,395]\u001b[0m Trial 23 finished with value: 2.5044680369380043 and parameters: {'lambda': 0.5624437025630056, 'alpha': 0.01741889064898663, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 262}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:04:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:04:42,026]\u001b[0m Trial 24 finished with value: 2.499723268408982 and parameters: {'lambda': 3.7960945128178922, 'alpha': 0.001001841594941961, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 160}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:04:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:04:54,442]\u001b[0m Trial 25 finished with value: 2.4974318188216484 and parameters: {'lambda': 0.16582063135451983, 'alpha': 0.0050162245890582125, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 118}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:04:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:05:07,036]\u001b[0m Trial 26 finished with value: 2.498502246659204 and parameters: {'lambda': 0.15546059818883262, 'alpha': 0.003299634173605899, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.012, 'max_depth': 13, 'min_child_weight': 112}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:05:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:05:12,673]\u001b[0m Trial 27 finished with value: 2.504635778661611 and parameters: {'lambda': 0.08262002659475463, 'alpha': 0.005184984180813279, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.018, 'max_depth': 5, 'min_child_weight': 207}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:05:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:05:24,624]\u001b[0m Trial 28 finished with value: 2.501208369314802 and parameters: {'lambda': 0.23576910340833107, 'alpha': 0.029329871716798055, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 117}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:05:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:05:31,766]\u001b[0m Trial 29 finished with value: 2.5004044458514634 and parameters: {'lambda': 0.03628294690625192, 'alpha': 0.08823364875646358, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 185}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:05:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:05:43,864]\u001b[0m Trial 30 finished with value: 2.4997919960102615 and parameters: {'lambda': 0.017546264076352746, 'alpha': 0.002424129247002103, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 61}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:05:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:05:56,222]\u001b[0m Trial 31 finished with value: 2.5000147702396247 and parameters: {'lambda': 0.7283020175540932, 'alpha': 0.008089824404862202, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 132}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:05:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:06:05,988]\u001b[0m Trial 32 finished with value: 2.5019486393362134 and parameters: {'lambda': 3.3401267542268145, 'alpha': 0.001399152201898276, 'colsample_bytree': 0.9, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 168}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:06:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:06:15,234]\u001b[0m Trial 33 finished with value: 2.5041870550378316 and parameters: {'lambda': 6.139851456051191, 'alpha': 0.011434383429990603, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 7, 'min_child_weight': 95}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:06:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:06:27,851]\u001b[0m Trial 34 finished with value: 2.4990379874729665 and parameters: {'lambda': 1.2494461156802337, 'alpha': 0.021076678894014766, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 154}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:06:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:06:36,099]\u001b[0m Trial 35 finished with value: 2.4995346722284446 and parameters: {'lambda': 0.11849388435183991, 'alpha': 0.0020331599304960015, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 9, 'min_child_weight': 126}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:06:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:06:44,299]\u001b[0m Trial 36 finished with value: 2.4997892645790154 and parameters: {'lambda': 2.2229665522825663, 'alpha': 0.03475945445489542, 'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 11, 'min_child_weight': 224}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:06:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:06:58,998]\u001b[0m Trial 37 finished with value: 2.501570659988998 and parameters: {'lambda': 0.35260493581015634, 'alpha': 0.004319738405291874, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 7, 'min_child_weight': 103}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:06:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:07:12,094]\u001b[0m Trial 38 finished with value: 2.497055555659281 and parameters: {'lambda': 0.0010242038198979768, 'alpha': 0.820462567167935, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 65}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:07:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:07:21,927]\u001b[0m Trial 39 finished with value: 2.500643896561681 and parameters: {'lambda': 0.0016059338039639511, 'alpha': 0.7747798107137802, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 73}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:07:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:07:37,496]\u001b[0m Trial 40 finished with value: 2.4991600059891863 and parameters: {'lambda': 0.0040293527431423445, 'alpha': 5.213347785688265, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 35}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:07:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:07:50,834]\u001b[0m Trial 41 finished with value: 2.4989399875641083 and parameters: {'lambda': 2.2681141107868283, 'alpha': 2.5872854626866744, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 13, 'min_child_weight': 48}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:07:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:08:01,189]\u001b[0m Trial 42 finished with value: 2.497218151498794 and parameters: {'lambda': 0.0034050459729426533, 'alpha': 0.3087282762301763, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 87}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:08:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:08:12,048]\u001b[0m Trial 43 finished with value: 2.497749924522968 and parameters: {'lambda': 0.0030760793590131398, 'alpha': 0.4046209426655887, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 79}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:08:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:08:22,473]\u001b[0m Trial 44 finished with value: 2.495553797097537 and parameters: {'lambda': 0.0010683826037378133, 'alpha': 0.3538727786416545, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 84}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:08:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:08:31,346]\u001b[0m Trial 45 finished with value: 2.499505247539676 and parameters: {'lambda': 0.0010928422808991714, 'alpha': 0.18601444412245444, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 92}. Best is trial 13 with value: 2.495173597189685.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:08:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:08:45,348]\u001b[0m Trial 46 finished with value: 2.494927588442104 and parameters: {'lambda': 0.002723617340417816, 'alpha': 0.29168853521770466, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 67}. Best is trial 46 with value: 2.494927588442104.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:08:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:09:05,517]\u001b[0m Trial 47 finished with value: 2.5048325973738756 and parameters: {'lambda': 0.007987033138391173, 'alpha': 0.2760929389247098, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 14}. Best is trial 46 with value: 2.494927588442104.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:09:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:09:14,790]\u001b[0m Trial 48 finished with value: 2.502574184770181 and parameters: {'lambda': 0.00239524431561687, 'alpha': 0.7062221149992459, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 69}. Best is trial 46 with value: 2.494927588442104.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:09:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:09:33,148]\u001b[0m Trial 49 finished with value: 2.499049132707606 and parameters: {'lambda': 0.0010247702646258604, 'alpha': 0.10747798040599806, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 36}. Best is trial 46 with value: 2.494927588442104.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_trial_5 = optuna_xgb.best_trial\n",
        "xgb_best_params_5 = xgb_best_trial_5.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(xgb_best_trial_5.value, xgb_best_params_5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0VFERggc2Yl",
        "outputId": "ef3d7bf7-9cf9-4735-d03b-66562eb39a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 2.494927588442104,\n",
            "params {'lambda': 0.002723617340417816, 'alpha': 0.29168853521770466, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 67}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_params_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xInoot5Rc4SW",
        "outputId": "fb8e4446-75f1-4fe8-edc0-c963490bc5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lambda': 0.002723617340417816,\n",
              " 'alpha': 0.29168853521770466,\n",
              " 'colsample_bytree': 0.6,\n",
              " 'subsample': 0.5,\n",
              " 'learning_rate': 0.012,\n",
              " 'max_depth': 15,\n",
              " 'min_child_weight': 67}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y5_model_1 = XGBRegressor(**xgb_best_params_5)"
      ],
      "metadata": {
        "id": "fIPk0KDgc7g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'random_state': 42,\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "        \n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_drill_scaled, y_drill[:,4], eval_set=[(X_val_scaled,y_val[:,4])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,4], model_lgbm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "KMLVxhq5dN-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_lgbm.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_134r49dSW7",
        "outputId": "13f5a4fc-ae9f-450d-92c7-890d1774f42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:11:33,377]\u001b[0m A new study created in memory with name: no-name-ee3cd4bb-fbb7-4a60-974c-4376369a1c33\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:11:53,348]\u001b[0m Trial 0 finished with value: 2.503715737914062 and parameters: {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:12:14,090]\u001b[0m Trial 1 finished with value: 2.567919751195191 and parameters: {'max_depth': 5, 'learning_rate': 2.2310108018679158e-08, 'n_estimators': 2612, 'min_child_samples': 62, 'subsample': 0.765297684068612}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:12:26,176]\u001b[0m Trial 2 finished with value: 2.515599372441863 and parameters: {'max_depth': 3, 'learning_rate': 0.006598711072054081, 'n_estimators': 2514, 'min_child_samples': 25, 'subsample': 0.4725148048142631}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:12:39,836]\u001b[0m Trial 3 finished with value: 2.5678851886050627 and parameters: {'max_depth': 5, 'learning_rate': 6.690421166498788e-07, 'n_estimators': 1622, 'min_child_samples': 46, 'subsample': 0.5223381155442193}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:12:53,814]\u001b[0m Trial 4 finished with value: 2.5679189452220124 and parameters: {'max_depth': 10, 'learning_rate': 6.870101665590006e-08, 'n_estimators': 947, 'min_child_samples': 40, 'subsample': 0.607503080954597}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:13:15,450]\u001b[0m Trial 5 finished with value: 2.5679106771986056 and parameters: {'max_depth': 13, 'learning_rate': 1.577766363058244e-07, 'n_estimators': 1591, 'min_child_samples': 61, 'subsample': 0.4173923345744613}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:13:19,198]\u001b[0m Trial 6 finished with value: 2.567920459558016 and parameters: {'max_depth': 10, 'learning_rate': 1.0547383621352015e-07, 'n_estimators': 288, 'min_child_samples': 96, 'subsample': 0.9689996293810518}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:13:24,038]\u001b[0m Trial 7 finished with value: 2.567909070470541 and parameters: {'max_depth': 13, 'learning_rate': 6.724850206557239e-07, 'n_estimators': 383, 'min_child_samples': 70, 'subsample': 0.5987069208932017}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:13:25,405]\u001b[0m Trial 8 finished with value: 2.5678721509860245 and parameters: {'max_depth': 4, 'learning_rate': 9.355380606452177e-06, 'n_estimators': 199, 'min_child_samples': 92, 'subsample': 0.5070361211081488}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:13:46,488]\u001b[0m Trial 9 finished with value: 2.5678688692262543 and parameters: {'max_depth': 11, 'learning_rate': 7.417652034871823e-07, 'n_estimators': 1608, 'min_child_samples': 57, 'subsample': 0.47382827709841974}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:14:07,503]\u001b[0m Trial 10 finished with value: 2.5139480773015985 and parameters: {'max_depth': 7, 'learning_rate': 0.003955232336089218, 'n_estimators': 2119, 'min_child_samples': 6, 'subsample': 0.405672369598035}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:14:19,821]\u001b[0m Trial 11 finished with value: 2.5115841657135984 and parameters: {'max_depth': 7, 'learning_rate': 0.007953409633698581, 'n_estimators': 2167, 'min_child_samples': 13, 'subsample': 0.4013720109047739}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:14:43,061]\u001b[0m Trial 12 finished with value: 2.5397344587907327 and parameters: {'max_depth': 7, 'learning_rate': 0.0004511388495675214, 'n_estimators': 2070, 'min_child_samples': 9, 'subsample': 0.4060696340155517}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:15:15,370]\u001b[0m Trial 13 finished with value: 2.551302867920623 and parameters: {'max_depth': 7, 'learning_rate': 0.0001378296140671229, 'n_estimators': 2991, 'min_child_samples': 80, 'subsample': 0.7228898200777368}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:15:40,495]\u001b[0m Trial 14 finished with value: 2.5354192828672857 and parameters: {'max_depth': 8, 'learning_rate': 0.0005559231881814425, 'n_estimators': 2115, 'min_child_samples': 31, 'subsample': 0.5500437593750167}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:15:55,677]\u001b[0m Trial 15 finished with value: 2.566170375376956 and parameters: {'max_depth': 15, 'learning_rate': 3.213476103996379e-05, 'n_estimators': 1094, 'min_child_samples': 21, 'subsample': 0.4595849978287922}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:16:18,694]\u001b[0m Trial 16 finished with value: 2.516533687698826 and parameters: {'max_depth': 6, 'learning_rate': 0.001601446145845733, 'n_estimators': 2469, 'min_child_samples': 76, 'subsample': 0.7368481236544839}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:16:30,202]\u001b[0m Trial 17 finished with value: 2.5083030945274407 and parameters: {'max_depth': 9, 'learning_rate': 0.008316150164448028, 'n_estimators': 2900, 'min_child_samples': 43, 'subsample': 0.45027291545271725}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:17:08,937]\u001b[0m Trial 18 finished with value: 2.560546887639228 and parameters: {'max_depth': 9, 'learning_rate': 5.486211499853922e-05, 'n_estimators': 2945, 'min_child_samples': 46, 'subsample': 0.45613294757278283}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:17:40,274]\u001b[0m Trial 19 finished with value: 2.5221177552021796 and parameters: {'max_depth': 12, 'learning_rate': 0.001021046080653488, 'n_estimators': 2599, 'min_child_samples': 36, 'subsample': 0.5520069211471134}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:18:03,964]\u001b[0m Trial 20 finished with value: 2.567432154746968 and parameters: {'max_depth': 9, 'learning_rate': 6.095354604255733e-06, 'n_estimators': 1867, 'min_child_samples': 52, 'subsample': 0.6768718740044972}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:18:14,815]\u001b[0m Trial 21 finished with value: 2.5117326003425817 and parameters: {'max_depth': 8, 'learning_rate': 0.009089386482629344, 'n_estimators': 2418, 'min_child_samples': 14, 'subsample': 0.4354452103569147}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:18:26,267]\u001b[0m Trial 22 finished with value: 2.523345127373407 and parameters: {'max_depth': 6, 'learning_rate': 0.0020417993584852506, 'n_estimators': 1174, 'min_child_samples': 69, 'subsample': 0.4992680283516898}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:18:58,362]\u001b[0m Trial 23 finished with value: 2.5487431828984626 and parameters: {'max_depth': 8, 'learning_rate': 0.00018096476089975177, 'n_estimators': 2754, 'min_child_samples': 22, 'subsample': 0.43167396373416245}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:19:11,172]\u001b[0m Trial 24 finished with value: 2.5038645733257567 and parameters: {'max_depth': 10, 'learning_rate': 0.009645650178023714, 'n_estimators': 2255, 'min_child_samples': 82, 'subsample': 0.4416212265567748}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:19:33,353]\u001b[0m Trial 25 finished with value: 2.5124087274680513 and parameters: {'max_depth': 12, 'learning_rate': 0.002021294602036967, 'n_estimators': 1815, 'min_child_samples': 85, 'subsample': 0.5595552082741766}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:20:01,604]\u001b[0m Trial 26 finished with value: 2.5420721555730283 and parameters: {'max_depth': 10, 'learning_rate': 0.0003114437872300216, 'n_estimators': 2361, 'min_child_samples': 89, 'subsample': 0.8783284546015736}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:20:16,275]\u001b[0m Trial 27 finished with value: 2.510400359696501 and parameters: {'max_depth': 11, 'learning_rate': 0.003448231841879388, 'n_estimators': 1333, 'min_child_samples': 99, 'subsample': 0.49406632444230614}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:20:47,613]\u001b[0m Trial 28 finished with value: 2.522765947607717 and parameters: {'max_depth': 9, 'learning_rate': 0.0007765419387338608, 'n_estimators': 2754, 'min_child_samples': 68, 'subsample': 0.44993566453065575}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:21:06,857]\u001b[0m Trial 29 finished with value: 2.5643804628795315 and parameters: {'max_depth': 5, 'learning_rate': 4.277904530725489e-05, 'n_estimators': 2290, 'min_child_samples': 56, 'subsample': 0.8138686866650632}. Best is trial 0 with value: 2.503715737914062.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_trial_5 = optuna_lgbm.best_trial\n",
        "lgbm_best_params_5 = lgbm_best_trial_5.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_best_trial_5.value, lgbm_best_params_5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqeQHNP0dVgk",
        "outputId": "b77ee86d-149f-4e78-dd53-d93a66b31d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 2.503715737914062,\n",
            "params {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE8wypODdZYW",
        "outputId": "54f639f9-5667-40c2-d3cf-90d8776c412e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 7,\n",
              " 'learning_rate': 0.005061576888752304,\n",
              " 'n_estimators': 2223,\n",
              " 'min_child_samples': 62,\n",
              " 'subsample': 0.46147273880126555}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y5_model_2 = LGBMRegressor(**lgbm_best_params_5)"
      ],
      "metadata": {
        "id": "l9aOOmKUdck2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###y6"
      ],
      "metadata": {
        "id": "mqGH09VQ_enn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = param = {\n",
        "        'random_state': 42,\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "        \n",
        "    \n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_drill_scaled, y_drill[:,5], eval_set=[(X_val_scaled,y_val[:,5])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,5], model_lgbm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "qfbtKqEz_fbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_lgbm.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18dRDwYkBm5c",
        "outputId": "8b1dbe58-8bd3-4c19-ae4b-1aa200776da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-24 17:02:32,641]\u001b[0m A new study created in memory with name: no-name-9090bbe3-fb12-44a7-ae5b-f14517a35a0c\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:02:38,897]\u001b[0m Trial 0 finished with value: 1.9980108096803486 and parameters: {'max_depth': 9, 'learning_rate': 0.008447206699076698, 'n_estimators': 495, 'min_child_samples': 71, 'subsample': 0.5793681348667392}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:03:06,208]\u001b[0m Trial 1 finished with value: 2.121535655751017 and parameters: {'max_depth': 8, 'learning_rate': 0.0002021094377698375, 'n_estimators': 2108, 'min_child_samples': 100, 'subsample': 0.44993856200261195}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:03:19,129]\u001b[0m Trial 2 finished with value: 2.122778473759613 and parameters: {'max_depth': 4, 'learning_rate': 0.00022183644799066016, 'n_estimators': 1777, 'min_child_samples': 31, 'subsample': 0.43019378882165005}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:03:24,295]\u001b[0m Trial 3 finished with value: 2.0635626552381043 and parameters: {'max_depth': 4, 'learning_rate': 0.002318169822598358, 'n_estimators': 656, 'min_child_samples': 36, 'subsample': 0.4923292538394288}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:03:42,215]\u001b[0m Trial 4 finished with value: 2.1742700699023447 and parameters: {'max_depth': 7, 'learning_rate': 2.6094144106694207e-08, 'n_estimators': 1605, 'min_child_samples': 11, 'subsample': 0.8328252176657457}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:04:10,692]\u001b[0m Trial 5 finished with value: 2.1634356325734214 and parameters: {'max_depth': 6, 'learning_rate': 1.7380869053354734e-05, 'n_estimators': 2653, 'min_child_samples': 67, 'subsample': 0.651846319206616}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:04:34,676]\u001b[0m Trial 6 finished with value: 2.1739041076961847 and parameters: {'max_depth': 7, 'learning_rate': 9.954317261406766e-07, 'n_estimators': 2042, 'min_child_samples': 100, 'subsample': 0.7335543288177968}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:04:50,011]\u001b[0m Trial 7 finished with value: 2.0906967465337134 and parameters: {'max_depth': 10, 'learning_rate': 0.00024204887108590935, 'n_estimators': 1449, 'min_child_samples': 10, 'subsample': 0.669607626040148}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:05:15,094]\u001b[0m Trial 8 finished with value: 2.174220855477571 and parameters: {'max_depth': 15, 'learning_rate': 1.1267242826774528e-07, 'n_estimators': 2101, 'min_child_samples': 24, 'subsample': 0.653562709737029}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:05:30,143]\u001b[0m Trial 9 finished with value: 2.1721784739383727 and parameters: {'max_depth': 4, 'learning_rate': 5.037622471245856e-06, 'n_estimators': 2293, 'min_child_samples': 38, 'subsample': 0.7356224398496244}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:05:32,023]\u001b[0m Trial 10 finished with value: 2.0589032937831013 and parameters: {'max_depth': 11, 'learning_rate': 0.009015517712381512, 'n_estimators': 122, 'min_child_samples': 69, 'subsample': 0.548808947078922}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:05:33,924]\u001b[0m Trial 11 finished with value: 2.0663901896802437 and parameters: {'max_depth': 11, 'learning_rate': 0.007643701169455004, 'n_estimators': 124, 'min_child_samples': 69, 'subsample': 0.5498962560483088}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:05:35,765]\u001b[0m Trial 12 finished with value: 2.066666388308071 and parameters: {'max_depth': 12, 'learning_rate': 0.008135431572964145, 'n_estimators': 117, 'min_child_samples': 71, 'subsample': 0.5478188655512897}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:05:48,330]\u001b[0m Trial 13 finished with value: 2.068053585463145 and parameters: {'max_depth': 13, 'learning_rate': 0.0011488045084771998, 'n_estimators': 939, 'min_child_samples': 83, 'subsample': 0.5480460625584209}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:05:56,552]\u001b[0m Trial 14 finished with value: 2.0749406717973082 and parameters: {'max_depth': 9, 'learning_rate': 0.001131249756089175, 'n_estimators': 618, 'min_child_samples': 54, 'subsample': 0.980098181038472}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:06:11,583]\u001b[0m Trial 15 finished with value: 2.1685440184962337 and parameters: {'max_depth': 14, 'learning_rate': 2.1876295661046103e-05, 'n_estimators': 1101, 'min_child_samples': 52, 'subsample': 0.5005047775770944}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:06:17,293]\u001b[0m Trial 16 finished with value: 2.0030457008954325 and parameters: {'max_depth': 10, 'learning_rate': 0.009067614001158476, 'n_estimators': 444, 'min_child_samples': 84, 'subsample': 0.6017702257537921}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:06:24,387]\u001b[0m Trial 17 finished with value: 2.158096902850641 and parameters: {'max_depth': 9, 'learning_rate': 0.0001322039454264703, 'n_estimators': 541, 'min_child_samples': 84, 'subsample': 0.608407127766422}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:06:38,441]\u001b[0m Trial 18 finished with value: 2.042441415404406 and parameters: {'max_depth': 6, 'learning_rate': 0.0016315824838645532, 'n_estimators': 1266, 'min_child_samples': 85, 'subsample': 0.7809449860395715}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:06:50,595]\u001b[0m Trial 19 finished with value: 2.1740295695281624 and parameters: {'max_depth': 10, 'learning_rate': 1.1716709625899399e-06, 'n_estimators': 885, 'min_child_samples': 53, 'subsample': 0.5960988368965721}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:06:56,255]\u001b[0m Trial 20 finished with value: 2.167756917677579 and parameters: {'max_depth': 13, 'learning_rate': 6.400852699956213e-05, 'n_estimators': 424, 'min_child_samples': 79, 'subsample': 0.4012093485089297}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:07:08,066]\u001b[0m Trial 21 finished with value: 2.049562195576753 and parameters: {'max_depth': 6, 'learning_rate': 0.0017650438782828553, 'n_estimators': 1061, 'min_child_samples': 91, 'subsample': 0.8149275925757616}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:07:21,070]\u001b[0m Trial 22 finished with value: 2.0143518954329487 and parameters: {'max_depth': 6, 'learning_rate': 0.0033526304096887635, 'n_estimators': 1318, 'min_child_samples': 89, 'subsample': 0.9240140956066207}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:07:59,831]\u001b[0m Trial 23 finished with value: 2.064106504175608 and parameters: {'max_depth': 8, 'learning_rate': 0.00044021477365728746, 'n_estimators': 2991, 'min_child_samples': 92, 'subsample': 0.9459329978568443}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:08:02,629]\u001b[0m Trial 24 finished with value: 2.107404076891309 and parameters: {'max_depth': 3, 'learning_rate': 0.004252695571587228, 'n_estimators': 437, 'min_child_samples': 78, 'subsample': 0.9048056098068249}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:08:12,539]\u001b[0m Trial 25 finished with value: 2.094661783490231 and parameters: {'max_depth': 10, 'learning_rate': 0.0007847920473062855, 'n_estimators': 719, 'min_child_samples': 61, 'subsample': 0.7201356274414125}. Best is trial 0 with value: 1.9980108096803486.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:08:27,546]\u001b[0m Trial 26 finished with value: 1.9677491098724134 and parameters: {'max_depth': 8, 'learning_rate': 0.009863203379666792, 'n_estimators': 1350, 'min_child_samples': 92, 'subsample': 0.4992904639069806}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:08:32,296]\u001b[0m Trial 27 finished with value: 2.1696887934970124 and parameters: {'max_depth': 8, 'learning_rate': 5.342937702973003e-05, 'n_estimators': 354, 'min_child_samples': 78, 'subsample': 0.4939943495601201}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:08:42,484]\u001b[0m Trial 28 finished with value: 2.0147098805615924 and parameters: {'max_depth': 9, 'learning_rate': 0.0042220360650408115, 'n_estimators': 807, 'min_child_samples': 95, 'subsample': 0.5869995947178831}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:09:05,769]\u001b[0m Trial 29 finished with value: 2.081193715846886 and parameters: {'max_depth': 11, 'learning_rate': 0.0005928969105408393, 'n_estimators': 1715, 'min_child_samples': 100, 'subsample': 0.4675211695517729}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:09:10,039]\u001b[0m Trial 30 finished with value: 2.0098619364116206 and parameters: {'max_depth': 8, 'learning_rate': 0.008890379179874628, 'n_estimators': 331, 'min_child_samples': 63, 'subsample': 0.4571072013344692}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:09:14,033]\u001b[0m Trial 31 finished with value: 2.0286804603315507 and parameters: {'max_depth': 7, 'learning_rate': 0.007513804333559855, 'n_estimators': 314, 'min_child_samples': 62, 'subsample': 0.4461714170743281}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:09:27,368]\u001b[0m Trial 32 finished with value: 2.006270245081379 and parameters: {'max_depth': 8, 'learning_rate': 0.0029147697777695825, 'n_estimators': 1078, 'min_child_samples': 74, 'subsample': 0.5092066758606121}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:09:42,223]\u001b[0m Trial 33 finished with value: 2.001723811378396 and parameters: {'max_depth': 9, 'learning_rate': 0.0031542949866983955, 'n_estimators': 1176, 'min_child_samples': 75, 'subsample': 0.5180947084517032}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:10:02,646]\u001b[0m Trial 34 finished with value: 2.0991261368218286 and parameters: {'max_depth': 9, 'learning_rate': 0.0003841924046878558, 'n_estimators': 1470, 'min_child_samples': 86, 'subsample': 0.5209337094264276}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:10:18,892]\u001b[0m Trial 35 finished with value: 1.9987041707949613 and parameters: {'max_depth': 10, 'learning_rate': 0.002934093065536431, 'n_estimators': 1269, 'min_child_samples': 75, 'subsample': 0.5740498276701022}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:10:43,909]\u001b[0m Trial 36 finished with value: 1.990011884931332 and parameters: {'max_depth': 12, 'learning_rate': 0.002369748508942477, 'n_estimators': 1963, 'min_child_samples': 75, 'subsample': 0.42913437622065503}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:11:10,340]\u001b[0m Trial 37 finished with value: 2.1077776689407006 and parameters: {'max_depth': 13, 'learning_rate': 0.00020849844263608845, 'n_estimators': 1864, 'min_child_samples': 57, 'subsample': 0.47121310632514374}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:11:36,443]\u001b[0m Trial 38 finished with value: 2.174274412150176 and parameters: {'max_depth': 12, 'learning_rate': 2.0477374027401885e-08, 'n_estimators': 1865, 'min_child_samples': 44, 'subsample': 0.4442355317893754}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:12:10,603]\u001b[0m Trial 39 finished with value: 2.1742418379945954 and parameters: {'max_depth': 12, 'learning_rate': 6.905651117799874e-08, 'n_estimators': 2480, 'min_child_samples': 46, 'subsample': 0.41885773522637815}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:12:28,938]\u001b[0m Trial 40 finished with value: 2.1721855448306298 and parameters: {'max_depth': 11, 'learning_rate': 4.365416715426119e-06, 'n_estimators': 1533, 'min_child_samples': 17, 'subsample': 0.6926038648429188}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:12:44,006]\u001b[0m Trial 41 finished with value: 2.0125433980643104 and parameters: {'max_depth': 7, 'learning_rate': 0.0023445463189430494, 'n_estimators': 1266, 'min_child_samples': 75, 'subsample': 0.5726700861592015}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:13:04,198]\u001b[0m Trial 42 finished with value: 1.982332696663786 and parameters: {'max_depth': 9, 'learning_rate': 0.0040476523717373515, 'n_estimators': 1660, 'min_child_samples': 80, 'subsample': 0.5290112544288552}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:13:26,444]\u001b[0m Trial 43 finished with value: 2.044148163903456 and parameters: {'max_depth': 10, 'learning_rate': 0.000983822901466511, 'n_estimators': 1646, 'min_child_samples': 66, 'subsample': 0.629514448085484}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:13:51,494]\u001b[0m Trial 44 finished with value: 1.9700532884132778 and parameters: {'max_depth': 11, 'learning_rate': 0.005211491796574555, 'n_estimators': 1968, 'min_child_samples': 94, 'subsample': 0.5675856742166139}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:14:19,953]\u001b[0m Trial 45 finished with value: 1.9710119909550479 and parameters: {'max_depth': 11, 'learning_rate': 0.00457434627303934, 'n_estimators': 2243, 'min_child_samples': 95, 'subsample': 0.480350202387644}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:14:50,342]\u001b[0m Trial 46 finished with value: 2.0160547446543355 and parameters: {'max_depth': 14, 'learning_rate': 0.0015469830607383037, 'n_estimators': 2278, 'min_child_samples': 96, 'subsample': 0.4817855989656167}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:15:15,461]\u001b[0m Trial 47 finished with value: 1.9694570809463998 and parameters: {'max_depth': 11, 'learning_rate': 0.004803809815986998, 'n_estimators': 1980, 'min_child_samples': 95, 'subsample': 0.42863892490013156}. Best is trial 26 with value: 1.9677491098724134.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:15:43,950]\u001b[0m Trial 48 finished with value: 1.9578403305280385 and parameters: {'max_depth': 11, 'learning_rate': 0.005864483607881246, 'n_estimators': 2270, 'min_child_samples': 97, 'subsample': 0.52990104251027}. Best is trial 48 with value: 1.9578403305280385.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:16:12,244]\u001b[0m Trial 49 finished with value: 1.9658011825484618 and parameters: {'max_depth': 11, 'learning_rate': 0.005648563194256571, 'n_estimators': 2230, 'min_child_samples': 100, 'subsample': 0.48920258500635166}. Best is trial 48 with value: 1.9578403305280385.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_trial_6 = optuna_lgbm.best_trial\n",
        "lgbm_best_params_6 = lgbm_best_trial_6.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_best_trial_6.value, lgbm_best_params_6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YRHJsctBuBq",
        "outputId": "24d975b0-69fd-4673-8d18-b7f8848d46e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 1.8929070008972775,\n",
            "params {'num_leaves': 250, 'colsample_bytree': 0.7899230648126035, 'reg_alpha': 0.8972634283195944, 'reg_lambda': 8.653932998753637, 'max_depth': 13, 'learning_rate': 0.008935490309713207, 'n_estimators': 2449, 'min_child_samples': 18, 'subsample': 0.400964503628992}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params_6 = {'num_leaves': 250,\n",
        " 'colsample_bytree': 0.7899230648126035,\n",
        " 'reg_alpha': 0.8972634283195944,\n",
        " 'reg_lambda': 8.653932998753637,\n",
        " 'max_depth': 13,\n",
        " 'learning_rate': 0.008935490309713207,\n",
        " 'n_estimators': 2449,\n",
        " 'min_child_samples': 18,\n",
        " 'subsample': 0.400964503628992}"
      ],
      "metadata": {
        "id": "UxsLJG2SB-BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y6_model = LGBMRegressor(**lgbm_best_params_6)"
      ],
      "metadata": {
        "id": "8c6WfzuiCAia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y6_model.fit(X_train_scaled,y_train[:,5]) #전체 test data fit\n",
        "y6_pred = y6_model.predict(X_test_scaled)\n",
        "print(f'test loss: {rmse(y_test[:,5],y6_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCQhk-f7CH7B",
        "outputId": "45231d77-d59f-4590-c69e-edb64898ae82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 1.5757269761152912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    cbrm_param = {\n",
        "        'random_state': 42,\n",
        "        'iterations':trial.suggest_int(\"iterations\", 4000, 25000),\n",
        "        'od_wait':trial.suggest_int('od_wait', 500, 2300),\n",
        "        'learning_rate' : trial.suggest_uniform('learning_rate',0.01, 1),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "        'subsample': trial.suggest_uniform('subsample',0,1),\n",
        "        'random_strength': trial.suggest_uniform('random_strength',10,50),\n",
        "        'depth': trial.suggest_int('depth',1, 15),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
        "        'colsample_bylevel':trial.suggest_float('colsample_bylevel', 0.4, 1.0),\n",
        "    }\n",
        "    \n",
        "    # Generate model\n",
        "    model_cbrm = CatBoostRegressor(**cbrm_param, verbose=False)\n",
        "    model_cbrm = model_cbrm.fit(X_drill_scaled, y_drill[:,5], eval_set=[(X_val_scaled,y_val[:,5])],early_stopping_rounds=25)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,5], model_cbrm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "kgb5AWRt7z0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_cbrm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_cbrm.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiTwmLF577xJ",
        "outputId": "12f6b1cf-dc49-4c75-de9a-c9ed0a40c4bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-25 02:59:10,269]\u001b[0m A new study created in memory with name: no-name-e131894d-fc91-4ace-a41f-5e412bc065e3\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 02:59:33,025]\u001b[0m Trial 0 finished with value: 1.9380576397485003 and parameters: {'iterations': 6122, 'od_wait': 1746, 'learning_rate': 0.07166888014876206, 'reg_lambda': 50.94221772075769, 'subsample': 0.9966968538529768, 'random_strength': 42.558810780240755, 'depth': 10, 'min_data_in_leaf': 10, 'leaf_estimation_iterations': 10, 'bagging_temperature': 1.282820394047189, 'colsample_bylevel': 0.655650030334223}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 02:59:56,904]\u001b[0m Trial 1 finished with value: 2.083157775027816 and parameters: {'iterations': 6745, 'od_wait': 2096, 'learning_rate': 0.4552868023331093, 'reg_lambda': 19.462259235851388, 'subsample': 0.3677593508772896, 'random_strength': 26.565190101157082, 'depth': 13, 'min_data_in_leaf': 23, 'leaf_estimation_iterations': 12, 'bagging_temperature': 0.011069424888528075, 'colsample_bylevel': 0.6496923989078569}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 02:59:58,307]\u001b[0m Trial 2 finished with value: 2.0028568044077844 and parameters: {'iterations': 14108, 'od_wait': 534, 'learning_rate': 0.26721507665758387, 'reg_lambda': 76.02898470931527, 'subsample': 0.13710970572899905, 'random_strength': 31.412405258103668, 'depth': 4, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 4, 'bagging_temperature': 80.07464457322739, 'colsample_bylevel': 0.8809222671297938}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:00:00,138]\u001b[0m Trial 3 finished with value: 2.11889057004034 and parameters: {'iterations': 24152, 'od_wait': 1378, 'learning_rate': 0.11863883669072846, 'reg_lambda': 54.795953417774406, 'subsample': 0.4543773345599609, 'random_strength': 43.77428330958464, 'depth': 2, 'min_data_in_leaf': 15, 'leaf_estimation_iterations': 3, 'bagging_temperature': 0.1989315688058567, 'colsample_bylevel': 0.8424142464326798}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:02:39,129]\u001b[0m Trial 4 finished with value: 2.0536267589939623 and parameters: {'iterations': 13996, 'od_wait': 1176, 'learning_rate': 0.40053151578433493, 'reg_lambda': 45.94468224613098, 'subsample': 0.7850165438370569, 'random_strength': 45.68338755760938, 'depth': 15, 'min_data_in_leaf': 24, 'leaf_estimation_iterations': 5, 'bagging_temperature': 5.6563832083638745, 'colsample_bylevel': 0.6625618744332351}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:02:58,302]\u001b[0m Trial 5 finished with value: 1.9602881399146732 and parameters: {'iterations': 9348, 'od_wait': 2014, 'learning_rate': 0.04804208547270175, 'reg_lambda': 90.17620019592243, 'subsample': 0.46147746462473416, 'random_strength': 35.48805907233122, 'depth': 10, 'min_data_in_leaf': 27, 'leaf_estimation_iterations': 10, 'bagging_temperature': 2.8558430698597497, 'colsample_bylevel': 0.439991224336414}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:02:59,357]\u001b[0m Trial 6 finished with value: 2.126030708517905 and parameters: {'iterations': 14887, 'od_wait': 770, 'learning_rate': 0.7400594310342707, 'reg_lambda': 51.22219695904824, 'subsample': 0.6802277792083533, 'random_strength': 11.666916024095372, 'depth': 2, 'min_data_in_leaf': 22, 'leaf_estimation_iterations': 2, 'bagging_temperature': 0.019276443559881524, 'colsample_bylevel': 0.4072650851409325}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:03:04,206]\u001b[0m Trial 7 finished with value: 1.954038258365155 and parameters: {'iterations': 24087, 'od_wait': 1828, 'learning_rate': 0.3597188944170435, 'reg_lambda': 29.65356516340971, 'subsample': 0.34970322974584955, 'random_strength': 40.986141247247275, 'depth': 10, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 3, 'bagging_temperature': 0.024750421470385142, 'colsample_bylevel': 0.7961816318208028}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:08,652]\u001b[0m Trial 8 finished with value: 2.0043763439998536 and parameters: {'iterations': 20052, 'od_wait': 977, 'learning_rate': 0.030735511420603684, 'reg_lambda': 8.217175925926059, 'subsample': 0.9678600348450305, 'random_strength': 21.81779109909681, 'depth': 12, 'min_data_in_leaf': 19, 'leaf_estimation_iterations': 6, 'bagging_temperature': 0.06648888481118996, 'colsample_bylevel': 0.4728318508956439}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:17,831]\u001b[0m Trial 9 finished with value: 2.1173433212813046 and parameters: {'iterations': 16915, 'od_wait': 1895, 'learning_rate': 0.6474652110057194, 'reg_lambda': 53.0302180218945, 'subsample': 0.041951223431636264, 'random_strength': 48.739551103775355, 'depth': 12, 'min_data_in_leaf': 9, 'leaf_estimation_iterations': 15, 'bagging_temperature': 2.5557970148172795, 'colsample_bylevel': 0.7494535949243479}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:19,087]\u001b[0m Trial 10 finished with value: 2.064046783112342 and parameters: {'iterations': 4187, 'od_wait': 1569, 'learning_rate': 0.9621570275028126, 'reg_lambda': 75.62417117786123, 'subsample': 0.9573049419334722, 'random_strength': 37.64700114739619, 'depth': 6, 'min_data_in_leaf': 13, 'leaf_estimation_iterations': 8, 'bagging_temperature': 0.42726151892405295, 'colsample_bylevel': 0.9739306689954442}. Best is trial 0 with value: 1.9380576397485003.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:24,903]\u001b[0m Trial 11 finished with value: 1.8918292769760403 and parameters: {'iterations': 23020, 'od_wait': 1661, 'learning_rate': 0.2592388535617171, 'reg_lambda': 28.782134542704007, 'subsample': 0.2508383756329571, 'random_strength': 40.263052583920164, 'depth': 8, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 8, 'bagging_temperature': 24.832842833684783, 'colsample_bylevel': 0.5725230216162469}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:27,890]\u001b[0m Trial 12 finished with value: 1.983527515324517 and parameters: {'iterations': 10004, 'od_wait': 1562, 'learning_rate': 0.19865764504245034, 'reg_lambda': 34.2599009269, 'subsample': 0.22418688599285164, 'random_strength': 33.88715819972912, 'depth': 7, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 10, 'bagging_temperature': 27.40405811099627, 'colsample_bylevel': 0.5543688938947994}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:32,231]\u001b[0m Trial 13 finished with value: 1.9988066622365048 and parameters: {'iterations': 19510, 'od_wait': 2259, 'learning_rate': 0.21725674981790377, 'reg_lambda': 3.4331756055863742, 'subsample': 0.6902363212062546, 'random_strength': 40.416687728382776, 'depth': 9, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 8, 'bagging_temperature': 14.900974496585633, 'colsample_bylevel': 0.5773668272803433}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:33,940]\u001b[0m Trial 14 finished with value: 2.0187137860991236 and parameters: {'iterations': 10431, 'od_wait': 1681, 'learning_rate': 0.3098541945258754, 'reg_lambda': 35.01182730475843, 'subsample': 0.21888373360262664, 'random_strength': 49.567492999608305, 'depth': 5, 'min_data_in_leaf': 10, 'leaf_estimation_iterations': 13, 'bagging_temperature': 1.0019686217580768, 'colsample_bylevel': 0.5633562148032073}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:36,098]\u001b[0m Trial 15 finished with value: 1.9300471218625246 and parameters: {'iterations': 20955, 'od_wait': 1308, 'learning_rate': 0.5257014778576744, 'reg_lambda': 63.0028854456517, 'subsample': 0.5800728046933966, 'random_strength': 26.55134522660447, 'depth': 8, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 11, 'bagging_temperature': 79.38435370741738, 'colsample_bylevel': 0.7075124967844779}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:38,392]\u001b[0m Trial 16 finished with value: 1.944042429725 and parameters: {'iterations': 21317, 'od_wait': 1290, 'learning_rate': 0.5715882509623927, 'reg_lambda': 66.94071286896244, 'subsample': 0.594790276836661, 'random_strength': 25.301813981215165, 'depth': 8, 'min_data_in_leaf': 5, 'leaf_estimation_iterations': 7, 'bagging_temperature': 89.14004923901989, 'colsample_bylevel': 0.7334512800558357}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:39,436]\u001b[0m Trial 17 finished with value: 2.0736955387016502 and parameters: {'iterations': 22052, 'od_wait': 1057, 'learning_rate': 0.7217218012774274, 'reg_lambda': 17.632784926901273, 'subsample': 0.3309174513515108, 'random_strength': 10.536557925042782, 'depth': 4, 'min_data_in_leaf': 17, 'leaf_estimation_iterations': 12, 'bagging_temperature': 15.373922286539157, 'colsample_bylevel': 0.49811572659535347}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:41,523]\u001b[0m Trial 18 finished with value: 1.9982994320906684 and parameters: {'iterations': 17924, 'od_wait': 1481, 'learning_rate': 0.5032000598163733, 'reg_lambda': 92.94773939051669, 'subsample': 0.5684660445107144, 'random_strength': 18.346205219672463, 'depth': 7, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 14, 'bagging_temperature': 33.215331298802376, 'colsample_bylevel': 0.6080582108245142}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:43,550]\u001b[0m Trial 19 finished with value: 2.0098947306782544 and parameters: {'iterations': 24494, 'od_wait': 802, 'learning_rate': 0.9040962140342597, 'reg_lambda': 66.2024196786533, 'subsample': 0.7826115293818869, 'random_strength': 28.88802098070069, 'depth': 8, 'min_data_in_leaf': 13, 'leaf_estimation_iterations': 11, 'bagging_temperature': 8.415602542269957, 'colsample_bylevel': 0.7107540547959976}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:45,242]\u001b[0m Trial 20 finished with value: 2.1004049279743136 and parameters: {'iterations': 22150, 'od_wait': 1189, 'learning_rate': 0.599361948840144, 'reg_lambda': 39.32653868394552, 'subsample': 0.017015086033460525, 'random_strength': 17.293561917933996, 'depth': 6, 'min_data_in_leaf': 8, 'leaf_estimation_iterations': 9, 'bagging_temperature': 42.75807829901573, 'colsample_bylevel': 0.7964172040242149}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:05:57,179]\u001b[0m Trial 21 finished with value: 1.9196480270314658 and parameters: {'iterations': 16756, 'od_wait': 1746, 'learning_rate': 0.1569617090474434, 'reg_lambda': 60.33719391930142, 'subsample': 0.8966116456516124, 'random_strength': 38.04693985811826, 'depth': 10, 'min_data_in_leaf': 11, 'leaf_estimation_iterations': 10, 'bagging_temperature': 1.1725195336627088, 'colsample_bylevel': 0.6604666712509125}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:06:16,031]\u001b[0m Trial 22 finished with value: 1.9402165117141474 and parameters: {'iterations': 17234, 'od_wait': 1654, 'learning_rate': 0.15936286173320616, 'reg_lambda': 64.14610213773307, 'subsample': 0.8574293520021945, 'random_strength': 38.14080106695854, 'depth': 11, 'min_data_in_leaf': 13, 'leaf_estimation_iterations': 7, 'bagging_temperature': 0.12197188664417682, 'colsample_bylevel': 0.6192725419963726}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:06:20,222]\u001b[0m Trial 23 finished with value: 1.9731170713456887 and parameters: {'iterations': 18857, 'od_wait': 1357, 'learning_rate': 0.42354644217760307, 'reg_lambda': 78.38359029173469, 'subsample': 0.5558616295248144, 'random_strength': 32.687422776799984, 'depth': 9, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 9, 'bagging_temperature': 0.45882134225511323, 'colsample_bylevel': 0.5117470743515798}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:06:46,490]\u001b[0m Trial 24 finished with value: 2.03212423385187 and parameters: {'iterations': 15466, 'od_wait': 1921, 'learning_rate': 0.30147297107244087, 'reg_lambda': 23.864946996916082, 'subsample': 0.8823997287478096, 'random_strength': 29.930893416708262, 'depth': 13, 'min_data_in_leaf': 7, 'leaf_estimation_iterations': 12, 'bagging_temperature': 5.692335750834968, 'colsample_bylevel': 0.695394662289592}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:06:51,961]\u001b[0m Trial 25 finished with value: 1.9833679246491365 and parameters: {'iterations': 21543, 'od_wait': 1480, 'learning_rate': 0.23350742370566877, 'reg_lambda': 59.743313121329095, 'subsample': 0.6798011278417172, 'random_strength': 36.87239117728269, 'depth': 9, 'min_data_in_leaf': 11, 'leaf_estimation_iterations': 11, 'bagging_temperature': 52.931423899606735, 'colsample_bylevel': 0.7795641919114028}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:06:53,414]\u001b[0m Trial 26 finished with value: 1.987981442797792 and parameters: {'iterations': 22816, 'od_wait': 2107, 'learning_rate': 0.5108510100203163, 'reg_lambda': 42.69533622657748, 'subsample': 0.23192600485423837, 'random_strength': 23.583227350907073, 'depth': 7, 'min_data_in_leaf': 3, 'leaf_estimation_iterations': 6, 'bagging_temperature': 16.90094224254385, 'colsample_bylevel': 0.6035954382589733}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:09:47,927]\u001b[0m Trial 27 finished with value: 2.0034170676365823 and parameters: {'iterations': 20067, 'od_wait': 1784, 'learning_rate': 0.3471783799059338, 'reg_lambda': 83.58687036075995, 'subsample': 0.4169332626293704, 'random_strength': 45.80484511025802, 'depth': 15, 'min_data_in_leaf': 8, 'leaf_estimation_iterations': 9, 'bagging_temperature': 2.8507308731982937, 'colsample_bylevel': 0.6985973649545917}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:09:52,934]\u001b[0m Trial 28 finished with value: 2.0907230477053016 and parameters: {'iterations': 11662, 'od_wait': 1207, 'learning_rate': 0.8148440692265055, 'reg_lambda': 69.03586930112678, 'subsample': 0.1293860468579987, 'random_strength': 27.82434518128616, 'depth': 11, 'min_data_in_leaf': 16, 'leaf_estimation_iterations': 14, 'bagging_temperature': 8.379928970950859, 'colsample_bylevel': 0.8809703266363083}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 03:09:59,414]\u001b[0m Trial 29 finished with value: 1.9785545511626554 and parameters: {'iterations': 15911, 'od_wait': 1759, 'learning_rate': 0.14338049275799536, 'reg_lambda': 58.149437424891225, 'subsample': 0.2736674554891033, 'random_strength': 41.362132589005874, 'depth': 9, 'min_data_in_leaf': 11, 'leaf_estimation_iterations': 11, 'bagging_temperature': 1.775389131114445, 'colsample_bylevel': 0.5343737055314193}. Best is trial 11 with value: 1.8918292769760403.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbrm_best_trial_6 = optuna_cbrm.best_trial\n",
        "cbrm_best_params_6 = cbrm_best_trial_6.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(cbrm_best_trial_6.value, cbrm_best_params_6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCjTXXIR8KlN",
        "outputId": "655fa37f-2431-4c10-e254-16d72024d16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 1.8918292769760403,\n",
            "params {'iterations': 23020, 'od_wait': 1661, 'learning_rate': 0.2592388535617171, 'reg_lambda': 28.782134542704007, 'subsample': 0.2508383756329571, 'random_strength': 40.263052583920164, 'depth': 8, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 8, 'bagging_temperature': 24.832842833684783, 'colsample_bylevel': 0.5725230216162469}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbrm_best_params_6 = {'iterations': 23020,\n",
        " 'od_wait': 1661,\n",
        " 'learning_rate': 0.2592388535617171,\n",
        " 'reg_lambda': 28.782134542704007,\n",
        " 'subsample': 0.2508383756329571,\n",
        " 'random_strength': 40.263052583920164,\n",
        " 'depth': 8,\n",
        " 'min_data_in_leaf': 6,\n",
        " 'leaf_estimation_iterations': 8,\n",
        " 'bagging_temperature': 24.832842833684783,\n",
        " 'colsample_bylevel': 0.5725230216162469}"
      ],
      "metadata": {
        "id": "MCyaxSQW8QVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbrm_best_params_6 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cIb4q8V2w6h",
        "outputId": "27e4d126-4fee-407e-d3b9-a7587af05f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'iterations': 23020,\n",
              " 'od_wait': 1661,\n",
              " 'learning_rate': 0.2592388535617171,\n",
              " 'reg_lambda': 28.782134542704007,\n",
              " 'subsample': 0.2508383756329571,\n",
              " 'random_strength': 40.263052583920164,\n",
              " 'depth': 8,\n",
              " 'min_data_in_leaf': 6,\n",
              " 'leaf_estimation_iterations': 8,\n",
              " 'bagging_temperature': 24.832842833684783,\n",
              " 'colsample_bylevel': 0.5725230216162469}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### y7"
      ],
      "metadata": {
        "id": "hroylomRd6jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
        "        'n_estimators': 10000,\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
        "        'random_state': 42,\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_xgb = XGBRegressor(**param)\n",
        "    model_xgb = model_xgb.fit(X_drill_scaled, y_drill[:,6], eval_set=[(X_val_scaled,y_val[:,6])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,6], model_xgb.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "sxv2If-Ad7qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_xgb.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKcz7PsveBci",
        "outputId": "5bf205b9-269a-4220-ee87-cf258704c38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:25:23,177]\u001b[0m A new study created in memory with name: no-name-7429d222-eb4c-4226-9067-01e05baa09e3\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:25:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:25:29,489]\u001b[0m Trial 0 finished with value: 0.41186182774587676 and parameters: {'lambda': 0.03148911647956861, 'alpha': 6.351221010640703, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 183}. Best is trial 0 with value: 0.41186182774587676.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:25:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:25:37,000]\u001b[0m Trial 1 finished with value: 0.41109977817197335 and parameters: {'lambda': 0.004809461967501573, 'alpha': 0.0018205657658407262, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 7, 'min_child_weight': 82}. Best is trial 1 with value: 0.41109977817197335.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:25:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:25:45,434]\u001b[0m Trial 2 finished with value: 0.41184797025483944 and parameters: {'lambda': 2.0651425578959257, 'alpha': 0.026730883107816707, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 11, 'min_child_weight': 229}. Best is trial 1 with value: 0.41109977817197335.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:25:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:25:55,878]\u001b[0m Trial 3 finished with value: 0.41132856633984827 and parameters: {'lambda': 0.17583640270008521, 'alpha': 1.2130221181165162, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 34}. Best is trial 1 with value: 0.41109977817197335.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:25:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:26:06,436]\u001b[0m Trial 4 finished with value: 0.4116842164638607 and parameters: {'lambda': 0.008160948743089917, 'alpha': 0.05110120656497164, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 11, 'min_child_weight': 296}. Best is trial 1 with value: 0.41109977817197335.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:26:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:26:11,691]\u001b[0m Trial 5 finished with value: 0.4126576789647163 and parameters: {'lambda': 0.009294394155644996, 'alpha': 0.4881375191603672, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 5, 'min_child_weight': 198}. Best is trial 1 with value: 0.41109977817197335.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:26:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:26:20,539]\u001b[0m Trial 6 finished with value: 0.4116250870794309 and parameters: {'lambda': 1.857328833311487, 'alpha': 0.16626592254031872, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'min_child_weight': 98}. Best is trial 1 with value: 0.41109977817197335.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:26:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:26:26,819]\u001b[0m Trial 7 finished with value: 0.4123118209818183 and parameters: {'lambda': 0.9682012086882473, 'alpha': 0.39676339357448603, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 7, 'min_child_weight': 290}. Best is trial 1 with value: 0.41109977817197335.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:26:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:26:37,019]\u001b[0m Trial 8 finished with value: 0.41137730639487663 and parameters: {'lambda': 7.152863022216533, 'alpha': 2.5824850844906155, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 211}. Best is trial 1 with value: 0.41109977817197335.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:26:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:26:46,190]\u001b[0m Trial 9 finished with value: 0.41059205464668436 and parameters: {'lambda': 1.5246518242848615, 'alpha': 3.6309591863459096, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 82}. Best is trial 9 with value: 0.41059205464668436.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:26:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:28:12,055]\u001b[0m Trial 10 finished with value: 0.41070519570880853 and parameters: {'lambda': 0.1632209274580005, 'alpha': 0.009646572175508749, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 5}. Best is trial 9 with value: 0.41059205464668436.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:28:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:28:57,676]\u001b[0m Trial 11 finished with value: 0.41147544916262235 and parameters: {'lambda': 0.31356971313563703, 'alpha': 0.005674563804536959, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 9}. Best is trial 9 with value: 0.41059205464668436.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:28:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:29:11,605]\u001b[0m Trial 12 finished with value: 0.4102745871347062 and parameters: {'lambda': 0.07777786661662818, 'alpha': 0.009125703046060935, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 66}. Best is trial 12 with value: 0.4102745871347062.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:29:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:29:17,043]\u001b[0m Trial 13 finished with value: 0.4112265595611154 and parameters: {'lambda': 0.0012748888933395578, 'alpha': 0.0014993772924073567, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 103}. Best is trial 12 with value: 0.4102745871347062.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:29:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:29:26,575]\u001b[0m Trial 14 finished with value: 0.4103076800460568 and parameters: {'lambda': 0.04394959647420904, 'alpha': 9.278182550393057, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 63}. Best is trial 12 with value: 0.4102745871347062.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:29:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:29:38,506]\u001b[0m Trial 15 finished with value: 0.4108830988253508 and parameters: {'lambda': 0.03561077254857067, 'alpha': 0.013784196121210561, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 138}. Best is trial 12 with value: 0.4102745871347062.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:29:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:29:43,095]\u001b[0m Trial 16 finished with value: 0.41188762219127073 and parameters: {'lambda': 0.04579588598371662, 'alpha': 0.1117592345829819, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 49}. Best is trial 12 with value: 0.4102745871347062.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:29:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:29:48,670]\u001b[0m Trial 17 finished with value: 0.41185550550908023 and parameters: {'lambda': 0.49944079649545703, 'alpha': 0.004433497249380858, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 13, 'min_child_weight': 135}. Best is trial 12 with value: 0.4102745871347062.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:29:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:29:59,085]\u001b[0m Trial 18 finished with value: 0.41100547126025705 and parameters: {'lambda': 0.06968180273396758, 'alpha': 0.02955912750814023, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.016, 'max_depth': 17, 'min_child_weight': 54}. Best is trial 12 with value: 0.4102745871347062.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:29:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:30:09,177]\u001b[0m Trial 19 finished with value: 0.4112109750310001 and parameters: {'lambda': 0.015942663179898196, 'alpha': 0.3024277391284497, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 164}. Best is trial 12 with value: 0.4102745871347062.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:30:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:30:24,495]\u001b[0m Trial 20 finished with value: 0.41080988441177907 and parameters: {'lambda': 0.0019392141847861726, 'alpha': 0.9964998200234327, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 121}. Best is trial 12 with value: 0.4102745871347062.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:30:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:30:33,975]\u001b[0m Trial 21 finished with value: 0.4102583751689644 and parameters: {'lambda': 0.112439407592414, 'alpha': 5.707222347454895, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 65}. Best is trial 21 with value: 0.4102583751689644.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:30:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:30:42,988]\u001b[0m Trial 22 finished with value: 0.41089683703573393 and parameters: {'lambda': 0.10363413842879877, 'alpha': 8.262654586760114, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 75}. Best is trial 21 with value: 0.4102583751689644.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:30:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:30:55,647]\u001b[0m Trial 23 finished with value: 0.41063028259484496 and parameters: {'lambda': 0.019805502413464293, 'alpha': 2.072465272071877, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 26}. Best is trial 21 with value: 0.4102583751689644.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:30:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:31:08,662]\u001b[0m Trial 24 finished with value: 0.410154462956673 and parameters: {'lambda': 0.3198825676931121, 'alpha': 3.290222470745352, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 60}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:31:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:31:19,231]\u001b[0m Trial 25 finished with value: 0.4107644292912432 and parameters: {'lambda': 0.21683779226894223, 'alpha': 1.0180403450303055, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 109}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:31:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:31:38,523]\u001b[0m Trial 26 finished with value: 0.41035443600185273 and parameters: {'lambda': 0.335446712290986, 'alpha': 4.043948463907397, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 13, 'min_child_weight': 38}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:31:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:31:45,100]\u001b[0m Trial 27 finished with value: 0.41155788150765216 and parameters: {'lambda': 0.7040894536106072, 'alpha': 0.07573203834509522, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.012, 'max_depth': 5, 'min_child_weight': 23}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:31:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:31:52,794]\u001b[0m Trial 28 finished with value: 0.41146237839572947 and parameters: {'lambda': 0.09223165634875609, 'alpha': 0.00302615785492175, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 9, 'min_child_weight': 159}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:31:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:31:59,160]\u001b[0m Trial 29 finished with value: 0.4111581416952664 and parameters: {'lambda': 5.1583841829882795, 'alpha': 4.768845380805232, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.016, 'max_depth': 15, 'min_child_weight': 67}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:31:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:32:03,715]\u001b[0m Trial 30 finished with value: 0.41155935400514304 and parameters: {'lambda': 0.10850365753600505, 'alpha': 1.7862886173344998, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 96}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:32:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:32:16,726]\u001b[0m Trial 31 finished with value: 0.410154462956673 and parameters: {'lambda': 0.055167891299689444, 'alpha': 7.112837203902287, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 60}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:32:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:32:27,599]\u001b[0m Trial 32 finished with value: 0.41110113938612136 and parameters: {'lambda': 0.021124978715100096, 'alpha': 7.445297340354733, 'colsample_bytree': 0.4, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 56}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:32:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:32:39,293]\u001b[0m Trial 33 finished with value: 0.41038113393940884 and parameters: {'lambda': 0.06979104667318185, 'alpha': 0.7061956737193926, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 87}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:32:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:32:44,248]\u001b[0m Trial 34 finished with value: 0.41092429594322144 and parameters: {'lambda': 0.35316987654591514, 'alpha': 4.743960935039289, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.018, 'max_depth': 11, 'min_child_weight': 119}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:32:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:32:49,808]\u001b[0m Trial 35 finished with value: 0.41113585348116194 and parameters: {'lambda': 0.1576441246092149, 'alpha': 2.564601933071706, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 9, 'min_child_weight': 43}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:32:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:32:56,755]\u001b[0m Trial 36 finished with value: 0.41159401035157556 and parameters: {'lambda': 0.004897346086957609, 'alpha': 0.22315373580630476, 'colsample_bytree': 0.4, 'subsample': 0.7, 'learning_rate': 0.016, 'max_depth': 11, 'min_child_weight': 254}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:32:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:33:04,534]\u001b[0m Trial 37 finished with value: 0.4111717925116626 and parameters: {'lambda': 0.02775322883723054, 'alpha': 0.04396361854224921, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 75}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:33:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:33:20,955]\u001b[0m Trial 38 finished with value: 0.4111566501672522 and parameters: {'lambda': 0.06287374082411426, 'alpha': 1.458319035093027, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 25}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:33:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:34:01,927]\u001b[0m Trial 39 finished with value: 0.4109485925269664 and parameters: {'lambda': 0.013856190961983816, 'alpha': 0.01376258277344918, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 12}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:34:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:34:13,185]\u001b[0m Trial 40 finished with value: 0.4117205853869107 and parameters: {'lambda': 0.7343745618913529, 'alpha': 0.5360428176216764, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 11, 'min_child_weight': 177}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:34:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:34:22,754]\u001b[0m Trial 41 finished with value: 0.4103076800460568 and parameters: {'lambda': 0.044835060482035505, 'alpha': 7.023877289315252, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 63}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:34:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:34:32,059]\u001b[0m Trial 42 finished with value: 0.41065416056138465 and parameters: {'lambda': 0.229079307006334, 'alpha': 3.3338066116377156, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 90}. Best is trial 24 with value: 0.410154462956673.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:34:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:34:44,540]\u001b[0m Trial 43 finished with value: 0.41000050251629505 and parameters: {'lambda': 0.12361759256547197, 'alpha': 5.732044395840606, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 67}. Best is trial 43 with value: 0.41000050251629505.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:34:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:34:57,557]\u001b[0m Trial 44 finished with value: 0.4104265192462943 and parameters: {'lambda': 0.12450921520136139, 'alpha': 9.98404664196567, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 39}. Best is trial 43 with value: 0.41000050251629505.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:34:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:35:06,551]\u001b[0m Trial 45 finished with value: 0.41149701080500156 and parameters: {'lambda': 3.0840675442290486, 'alpha': 5.839302905144795, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 76}. Best is trial 43 with value: 0.41000050251629505.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:35:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:35:12,538]\u001b[0m Trial 46 finished with value: 0.41180998025248655 and parameters: {'lambda': 1.2459840975526697, 'alpha': 3.0657505633610413, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.018, 'max_depth': 5, 'min_child_weight': 113}. Best is trial 43 with value: 0.41000050251629505.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:35:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:35:20,800]\u001b[0m Trial 47 finished with value: 0.41109839083725325 and parameters: {'lambda': 0.49590516158585796, 'alpha': 1.89363595019152, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.014, 'max_depth': 17, 'min_child_weight': 131}. Best is trial 43 with value: 0.41000050251629505.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:35:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:35:31,880]\u001b[0m Trial 48 finished with value: 0.4110323604430693 and parameters: {'lambda': 0.22675671091412966, 'alpha': 0.0022772690886919047, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 2}. Best is trial 43 with value: 0.41000050251629505.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:35:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:35:41,696]\u001b[0m Trial 49 finished with value: 0.4106858640408689 and parameters: {'lambda': 0.010048498138270273, 'alpha': 0.7511500894199348, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 49}. Best is trial 43 with value: 0.41000050251629505.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_trial_7 = optuna_xgb.best_trial\n",
        "xgb_best_params_7 = xgb_best_trial_7.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(xgb_best_trial_7.value, xgb_best_params_7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-7MRBymeEl4",
        "outputId": "314e7376-413d-4632-baf3-5aa3fc030a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.41000050251629505,\n",
            "params {'lambda': 0.12361759256547197, 'alpha': 5.732044395840606, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 67}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_params_7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW-6NrfjeH6k",
        "outputId": "3ffbfec2-deb0-4e82-834b-0242edca0742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lambda': 0.12361759256547197,\n",
              " 'alpha': 5.732044395840606,\n",
              " 'colsample_bytree': 0.6,\n",
              " 'subsample': 0.7,\n",
              " 'learning_rate': 0.01,\n",
              " 'max_depth': 11,\n",
              " 'min_child_weight': 67}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y7_model_1 = XGBRegressor(**xgb_best_params_7)"
      ],
      "metadata": {
        "id": "9cYRl0zeeJeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'random_state': 42,\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "        \n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_drill_scaled, y_drill[:,6], eval_set=[(X_val_scaled,y_val[:,6])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,6], model_lgbm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "NzA2LrKZeLj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_lgbm.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJe491_3eRS0",
        "outputId": "22d54b5a-c42f-429f-9533-bb25df180b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:37:02,412]\u001b[0m A new study created in memory with name: no-name-eae76859-45e4-4627-b217-24fb29f5d7fc\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:37:20,695]\u001b[0m Trial 0 finished with value: 0.4120554032979852 and parameters: {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:37:44,533]\u001b[0m Trial 1 finished with value: 0.4233442215976571 and parameters: {'max_depth': 5, 'learning_rate': 2.2310108018679158e-08, 'n_estimators': 2612, 'min_child_samples': 62, 'subsample': 0.765297684068612}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:37:56,140]\u001b[0m Trial 2 finished with value: 0.4136607942223334 and parameters: {'max_depth': 3, 'learning_rate': 0.006598711072054081, 'n_estimators': 2514, 'min_child_samples': 25, 'subsample': 0.4725148048142631}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:38:11,146]\u001b[0m Trial 3 finished with value: 0.4233327732829535 and parameters: {'max_depth': 5, 'learning_rate': 6.690421166498788e-07, 'n_estimators': 1622, 'min_child_samples': 46, 'subsample': 0.5223381155442193}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:38:23,445]\u001b[0m Trial 4 finished with value: 0.42334407733595814 and parameters: {'max_depth': 10, 'learning_rate': 6.870101665590006e-08, 'n_estimators': 947, 'min_child_samples': 40, 'subsample': 0.607503080954597}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:38:43,401]\u001b[0m Trial 5 finished with value: 0.42334165089756387 and parameters: {'max_depth': 13, 'learning_rate': 1.577766363058244e-07, 'n_estimators': 1591, 'min_child_samples': 61, 'subsample': 0.4173923345744613}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:38:47,021]\u001b[0m Trial 6 finished with value: 0.4233444816132131 and parameters: {'max_depth': 10, 'learning_rate': 1.0547383621352015e-07, 'n_estimators': 288, 'min_child_samples': 96, 'subsample': 0.9689996293810518}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:38:51,820]\u001b[0m Trial 7 finished with value: 0.42334159552492706 and parameters: {'max_depth': 13, 'learning_rate': 6.724850206557239e-07, 'n_estimators': 383, 'min_child_samples': 70, 'subsample': 0.5987069208932017}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:38:53,350]\u001b[0m Trial 8 finished with value: 0.4233287627983783 and parameters: {'max_depth': 4, 'learning_rate': 9.355380606452177e-06, 'n_estimators': 199, 'min_child_samples': 92, 'subsample': 0.5070361211081488}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:39:13,260]\u001b[0m Trial 9 finished with value: 0.42332989845508884 and parameters: {'max_depth': 11, 'learning_rate': 7.417652034871823e-07, 'n_estimators': 1608, 'min_child_samples': 57, 'subsample': 0.47382827709841974}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:39:33,284]\u001b[0m Trial 10 finished with value: 0.4132134056431754 and parameters: {'max_depth': 7, 'learning_rate': 0.003955232336089218, 'n_estimators': 2119, 'min_child_samples': 6, 'subsample': 0.405672369598035}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:39:47,756]\u001b[0m Trial 11 finished with value: 0.4128905422511318 and parameters: {'max_depth': 7, 'learning_rate': 0.007953409633698581, 'n_estimators': 2167, 'min_child_samples': 13, 'subsample': 0.4013720109047739}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:40:12,259]\u001b[0m Trial 12 finished with value: 0.4176467251448496 and parameters: {'max_depth': 7, 'learning_rate': 0.0004511388495675214, 'n_estimators': 2070, 'min_child_samples': 9, 'subsample': 0.4060696340155517}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:40:44,988]\u001b[0m Trial 13 finished with value: 0.4198558461203649 and parameters: {'max_depth': 7, 'learning_rate': 0.0001378296140671229, 'n_estimators': 2991, 'min_child_samples': 80, 'subsample': 0.7228898200777368}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:41:09,978]\u001b[0m Trial 14 finished with value: 0.4167388409560398 and parameters: {'max_depth': 8, 'learning_rate': 0.0005559231881814425, 'n_estimators': 2115, 'min_child_samples': 31, 'subsample': 0.5500437593750167}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:41:23,539]\u001b[0m Trial 15 finished with value: 0.4229334277022182 and parameters: {'max_depth': 15, 'learning_rate': 3.213476103996379e-05, 'n_estimators': 1094, 'min_child_samples': 21, 'subsample': 0.4595849978287922}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:41:46,629]\u001b[0m Trial 16 finished with value: 0.4132802442674188 and parameters: {'max_depth': 6, 'learning_rate': 0.001601446145845733, 'n_estimators': 2469, 'min_child_samples': 76, 'subsample': 0.7368481236544839}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:41:57,816]\u001b[0m Trial 17 finished with value: 0.41208656861869924 and parameters: {'max_depth': 9, 'learning_rate': 0.008316150164448028, 'n_estimators': 2900, 'min_child_samples': 43, 'subsample': 0.45027291545271725}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:42:33,666]\u001b[0m Trial 18 finished with value: 0.4215987617334192 and parameters: {'max_depth': 9, 'learning_rate': 5.486211499853922e-05, 'n_estimators': 2945, 'min_child_samples': 46, 'subsample': 0.45613294757278283}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:43:03,915]\u001b[0m Trial 19 finished with value: 0.41421715978816986 and parameters: {'max_depth': 12, 'learning_rate': 0.001021046080653488, 'n_estimators': 2599, 'min_child_samples': 36, 'subsample': 0.5520069211471134}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:43:27,106]\u001b[0m Trial 20 finished with value: 0.42320532427578084 and parameters: {'max_depth': 9, 'learning_rate': 6.095354604255733e-06, 'n_estimators': 1867, 'min_child_samples': 52, 'subsample': 0.6768718740044972}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:43:39,386]\u001b[0m Trial 21 finished with value: 0.41250674171812385 and parameters: {'max_depth': 8, 'learning_rate': 0.009089386482629344, 'n_estimators': 2418, 'min_child_samples': 14, 'subsample': 0.4354452103569147}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:44:06,935]\u001b[0m Trial 22 finished with value: 0.4131902176332002 and parameters: {'max_depth': 9, 'learning_rate': 0.0020417993584852506, 'n_estimators': 2738, 'min_child_samples': 18, 'subsample': 0.43775951386524686}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:44:35,402]\u001b[0m Trial 23 finished with value: 0.419809621720906 and parameters: {'max_depth': 8, 'learning_rate': 0.0001857886589272106, 'n_estimators': 2353, 'min_child_samples': 30, 'subsample': 0.5026402845715225}. Best is trial 0 with value: 0.4120554032979852.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:44:44,228]\u001b[0m Trial 24 finished with value: 0.41181784650281184 and parameters: {'max_depth': 11, 'learning_rate': 0.009645650178023714, 'n_estimators': 2803, 'min_child_samples': 69, 'subsample': 0.5585321307624258}. Best is trial 24 with value: 0.41181784650281184.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:45:13,233]\u001b[0m Trial 25 finished with value: 0.41225645175000564 and parameters: {'max_depth': 12, 'learning_rate': 0.002021294602036967, 'n_estimators': 2800, 'min_child_samples': 68, 'subsample': 0.5678302972926775}. Best is trial 24 with value: 0.41181784650281184.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:45:46,833]\u001b[0m Trial 26 finished with value: 0.4173518763144103 and parameters: {'max_depth': 11, 'learning_rate': 0.0003114437872300216, 'n_estimators': 2839, 'min_child_samples': 84, 'subsample': 0.6447234993618074}. Best is trial 24 with value: 0.41181784650281184.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:46:00,414]\u001b[0m Trial 27 finished with value: 0.4131030189464419 and parameters: {'max_depth': 15, 'learning_rate': 0.003448231841879388, 'n_estimators': 1259, 'min_child_samples': 51, 'subsample': 0.49406632444230614}. Best is trial 24 with value: 0.41181784650281184.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:46:32,110]\u001b[0m Trial 28 finished with value: 0.41444860855322885 and parameters: {'max_depth': 10, 'learning_rate': 0.0007765419387338608, 'n_estimators': 2743, 'min_child_samples': 71, 'subsample': 0.925687032584981}. Best is trial 24 with value: 0.41181784650281184.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 05:46:49,560]\u001b[0m Trial 29 finished with value: 0.42250957507740317 and parameters: {'max_depth': 5, 'learning_rate': 4.277904530725489e-05, 'n_estimators': 1916, 'min_child_samples': 62, 'subsample': 0.8138686866650632}. Best is trial 24 with value: 0.41181784650281184.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_trial_7 = optuna_lgbm.best_trial\n",
        "lgbm_best_params_7 = lgbm_best_trial_7.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_best_trial_7.value, lgbm_best_params_7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI5L8y-feTid",
        "outputId": "f7fc0510-d443-4926-f0ac-73a51544d3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.41181784650281184,\n",
            "params {'max_depth': 11, 'learning_rate': 0.009645650178023714, 'n_estimators': 2803, 'min_child_samples': 69, 'subsample': 0.5585321307624258}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params_7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElsEs-1KeWAe",
        "outputId": "69d55c9b-36b0-46b2-aada-db0c06b7ca3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 11,\n",
              " 'learning_rate': 0.009645650178023714,\n",
              " 'n_estimators': 2803,\n",
              " 'min_child_samples': 69,\n",
              " 'subsample': 0.5585321307624258}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y7_model_2 = LGBMRegressor(**lgbm_best_params_7)"
      ],
      "metadata": {
        "id": "xucUDd53eX9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### y8"
      ],
      "metadata": {
        "id": "VhSvxcode4Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
        "        'n_estimators': 10000,\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
        "        'random_state': 42,\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_xgb = XGBRegressor(**param)\n",
        "    model_xgb = model_xgb.fit(X_drill_scaled, y_drill[:,7], eval_set=[(X_val_scaled,y_val[:,7])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,7], model_xgb.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "NzfEQ-tee6U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_xgb.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaqD5gKge9oL",
        "outputId": "8415fa83-15c1-4680-fcd6-890da51ecfc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:48:10,479]\u001b[0m A new study created in memory with name: no-name-43a153d9-26a5-4244-9b86-9697c6a8584d\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:48:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:48:17,787]\u001b[0m Trial 0 finished with value: 0.6276136042039416 and parameters: {'lambda': 0.03148911647956861, 'alpha': 6.351221010640703, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 183}. Best is trial 0 with value: 0.6276136042039416.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:48:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:48:24,209]\u001b[0m Trial 1 finished with value: 0.6281898769311786 and parameters: {'lambda': 0.004809461967501573, 'alpha': 0.0018205657658407262, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 7, 'min_child_weight': 82}. Best is trial 0 with value: 0.6276136042039416.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:48:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:48:34,562]\u001b[0m Trial 2 finished with value: 0.627421915771432 and parameters: {'lambda': 2.0651425578959257, 'alpha': 0.026730883107816707, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 11, 'min_child_weight': 229}. Best is trial 2 with value: 0.627421915771432.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:48:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:48:46,493]\u001b[0m Trial 3 finished with value: 0.6264709308512273 and parameters: {'lambda': 0.17583640270008521, 'alpha': 1.2130221181165162, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 34}. Best is trial 3 with value: 0.6264709308512273.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:48:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:49:04,428]\u001b[0m Trial 4 finished with value: 0.6270223237462148 and parameters: {'lambda': 0.008160948743089917, 'alpha': 0.05110120656497164, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 11, 'min_child_weight': 296}. Best is trial 3 with value: 0.6264709308512273.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:49:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:49:10,250]\u001b[0m Trial 5 finished with value: 0.6299859866758569 and parameters: {'lambda': 0.009294394155644996, 'alpha': 0.4881375191603672, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 5, 'min_child_weight': 198}. Best is trial 3 with value: 0.6264709308512273.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:49:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:49:22,133]\u001b[0m Trial 6 finished with value: 0.6267703860338532 and parameters: {'lambda': 1.857328833311487, 'alpha': 0.16626592254031872, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'min_child_weight': 98}. Best is trial 3 with value: 0.6264709308512273.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:49:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:49:28,592]\u001b[0m Trial 7 finished with value: 0.6286849211124863 and parameters: {'lambda': 0.9682012086882473, 'alpha': 0.39676339357448603, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 7, 'min_child_weight': 290}. Best is trial 3 with value: 0.6264709308512273.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:49:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:49:40,362]\u001b[0m Trial 8 finished with value: 0.6274026141275009 and parameters: {'lambda': 7.152863022216533, 'alpha': 2.5824850844906155, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 211}. Best is trial 3 with value: 0.6264709308512273.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:49:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:49:54,434]\u001b[0m Trial 9 finished with value: 0.6266056154274229 and parameters: {'lambda': 1.5246518242848615, 'alpha': 3.6309591863459096, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 82}. Best is trial 3 with value: 0.6264709308512273.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:49:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:50:47,898]\u001b[0m Trial 10 finished with value: 0.6252488835170149 and parameters: {'lambda': 0.16697295888685793, 'alpha': 0.009635229193674733, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 5}. Best is trial 10 with value: 0.6252488835170149.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:50:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:51:23,363]\u001b[0m Trial 11 finished with value: 0.6252220456329415 and parameters: {'lambda': 0.1236174499166602, 'alpha': 0.005672288338688626, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 9}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:51:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:51:47,212]\u001b[0m Trial 12 finished with value: 0.6256472933322076 and parameters: {'lambda': 0.18591785832514982, 'alpha': 0.006976356270783062, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 14}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:51:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:52:23,799]\u001b[0m Trial 13 finished with value: 0.6290200045213857 and parameters: {'lambda': 0.051748825226130744, 'alpha': 0.001385924458667549, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 17, 'min_child_weight': 6}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:52:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:52:33,032]\u001b[0m Trial 14 finished with value: 0.626315248249556 and parameters: {'lambda': 0.40184929679812087, 'alpha': 0.01039960899356607, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 13, 'min_child_weight': 55}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:52:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:52:42,312]\u001b[0m Trial 15 finished with value: 0.6265996986107575 and parameters: {'lambda': 0.03286753384474591, 'alpha': 0.006235746744480956, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 120}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:52:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:52:47,810]\u001b[0m Trial 16 finished with value: 0.6278410633048012 and parameters: {'lambda': 0.0019469783916597162, 'alpha': 0.023297128497245675, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 15, 'min_child_weight': 140}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:52:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:52:56,105]\u001b[0m Trial 17 finished with value: 0.6278479495093302 and parameters: {'lambda': 0.08176196343708847, 'alpha': 0.002742025132201674, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 13, 'min_child_weight': 53}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:52:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:53:01,274]\u001b[0m Trial 18 finished with value: 0.6293579823076415 and parameters: {'lambda': 0.3513546575240783, 'alpha': 0.08690076100606756, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.016, 'max_depth': 5, 'min_child_weight': 4}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:53:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:53:17,363]\u001b[0m Trial 19 finished with value: 0.6263877361565892 and parameters: {'lambda': 0.4776213087783672, 'alpha': 0.004373418583164028, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.014, 'max_depth': 17, 'min_child_weight': 50}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:53:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:53:26,616]\u001b[0m Trial 20 finished with value: 0.6265556393609061 and parameters: {'lambda': 0.021185819775176223, 'alpha': 0.017469690476374842, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 166}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:53:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:53:46,558]\u001b[0m Trial 21 finished with value: 0.6253468499780525 and parameters: {'lambda': 0.15812709398027336, 'alpha': 0.007377289870630554, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 23}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:53:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:54:00,568]\u001b[0m Trial 22 finished with value: 0.626267767945347 and parameters: {'lambda': 0.2184382383591662, 'alpha': 0.010195521821091402, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 35}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:54:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:54:16,854]\u001b[0m Trial 23 finished with value: 0.6257002477860855 and parameters: {'lambda': 0.10824866364009231, 'alpha': 0.0029138675315482335, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 24}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:54:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:54:29,853]\u001b[0m Trial 24 finished with value: 0.6258730782473457 and parameters: {'lambda': 0.08670165859377171, 'alpha': 0.0010042853944168485, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 69}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:54:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:54:42,253]\u001b[0m Trial 25 finished with value: 0.6263425666405625 and parameters: {'lambda': 0.8288075176264164, 'alpha': 0.04655786556091119, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 101}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:54:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:55:14,606]\u001b[0m Trial 26 finished with value: 0.6253542478146998 and parameters: {'lambda': 6.604756546839392, 'alpha': 0.01538582021694404, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 31}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:55:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:55:21,904]\u001b[0m Trial 27 finished with value: 0.628054248255012 and parameters: {'lambda': 0.01710496795435557, 'alpha': 0.0034288070374056067, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 5, 'min_child_weight': 258}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:55:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:55:33,763]\u001b[0m Trial 28 finished with value: 0.6272716583098482 and parameters: {'lambda': 0.061930248168311254, 'alpha': 0.04257214005383983, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.01, 'max_depth': 9, 'min_child_weight': 6}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:55:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:55:43,554]\u001b[0m Trial 29 finished with value: 0.6263966942214928 and parameters: {'lambda': 0.03628294690625192, 'alpha': 0.1359523662965301, 'colsample_bytree': 0.4, 'subsample': 0.7, 'learning_rate': 0.016, 'max_depth': 13, 'min_child_weight': 133}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:55:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:55:48,459]\u001b[0m Trial 30 finished with value: 0.6286396702607905 and parameters: {'lambda': 0.1295255659598741, 'alpha': 0.006555658307149991, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 43}. Best is trial 11 with value: 0.6252220456329415.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:55:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:56:16,168]\u001b[0m Trial 31 finished with value: 0.6248406665800584 and parameters: {'lambda': 4.4267691662747115, 'alpha': 0.013590484679193908, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 25}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:56:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:56:34,933]\u001b[0m Trial 32 finished with value: 0.6256159829936689 and parameters: {'lambda': 0.6194655020250844, 'alpha': 0.011543642132824666, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 73}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:56:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:57:02,704]\u001b[0m Trial 33 finished with value: 0.6248406665800584 and parameters: {'lambda': 3.1622230925317396, 'alpha': 0.0020341735627118175, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 25}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:57:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:57:23,013]\u001b[0m Trial 34 finished with value: 0.6260260347124654 and parameters: {'lambda': 4.033194018775432, 'alpha': 0.0016434768994838663, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 17, 'min_child_weight': 65}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:57:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:57:40,809]\u001b[0m Trial 35 finished with value: 0.6256393864371821 and parameters: {'lambda': 9.572707953141247, 'alpha': 0.0023923955054066847, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 91}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:57:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 05:57:53,932]\u001b[0m Trial 36 finished with value: 0.6256799765634077 and parameters: {'lambda': 3.833784884909615, 'alpha': 0.004224258202362786, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.012, 'max_depth': 11, 'min_child_weight': 20}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:57:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:02:23,722]\u001b[0m Trial 37 finished with value: 0.6255935556475225 and parameters: {'lambda': 3.2896275964101838, 'alpha': 0.021644606518536433, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 1}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:02:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:02:38,187]\u001b[0m Trial 38 finished with value: 0.6267113412283065 and parameters: {'lambda': 1.2437020518997564, 'alpha': 0.034656823855606055, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 7, 'min_child_weight': 113}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:02:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:02:47,195]\u001b[0m Trial 39 finished with value: 0.6280444250645798 and parameters: {'lambda': 2.741600987483571, 'alpha': 0.0692107278667394, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.012, 'max_depth': 9, 'min_child_weight': 40}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:02:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:03:02,097]\u001b[0m Trial 40 finished with value: 0.6275680622997225 and parameters: {'lambda': 0.27110278397957155, 'alpha': 0.0018633130779470088, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 177}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:03:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:03:17,004]\u001b[0m Trial 41 finished with value: 0.6253721000993119 and parameters: {'lambda': 0.0012233931917065113, 'alpha': 0.0049780058081786635, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 30}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:03:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:03:35,069]\u001b[0m Trial 42 finished with value: 0.6255983805062019 and parameters: {'lambda': 0.1423549729270048, 'alpha': 0.011161957514158494, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 15, 'min_child_weight': 18}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:03:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:03:58,047]\u001b[0m Trial 43 finished with value: 0.625567116995009 and parameters: {'lambda': 0.7256289132407253, 'alpha': 0.0012205053202560643, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 20}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:03:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:04:10,387]\u001b[0m Trial 44 finished with value: 0.6260521025132945 and parameters: {'lambda': 0.005166309734861866, 'alpha': 0.007168275563748881, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 60}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:04:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:04:28,806]\u001b[0m Trial 45 finished with value: 0.6259074545589434 and parameters: {'lambda': 2.0847821010777485, 'alpha': 8.360603301436354, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 44}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:04:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:04:36,435]\u001b[0m Trial 46 finished with value: 0.6279861638601569 and parameters: {'lambda': 0.012797007017896505, 'alpha': 0.2283415321295718, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 5, 'min_child_weight': 82}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:04:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:04:52,999]\u001b[0m Trial 47 finished with value: 0.6275555108804883 and parameters: {'lambda': 0.05564885174389405, 'alpha': 0.002206515834295995, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.018, 'max_depth': 15, 'min_child_weight': 14}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:04:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:05:02,702]\u001b[0m Trial 48 finished with value: 0.627244101745312 and parameters: {'lambda': 0.2857047508403888, 'alpha': 0.007790765025030559, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.014, 'max_depth': 7, 'min_child_weight': 1}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:05:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:05:08,618]\u001b[0m Trial 49 finished with value: 0.6271217882388664 and parameters: {'lambda': 1.1207882428622291, 'alpha': 0.03049954663516557, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 34}. Best is trial 31 with value: 0.6248406665800584.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_trial_8 = optuna_xgb.best_trial\n",
        "xgb_best_params_8 = xgb_best_trial_8.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(xgb_best_trial_8.value, xgb_best_params_8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-mHaQL4fBjX",
        "outputId": "8eb2b709-54e2-490f-8c9e-640bc25adc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.6248406665800584,\n",
            "params {'lambda': 4.4267691662747115, 'alpha': 0.013590484679193908, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_params_8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmKOK4GFfGHM",
        "outputId": "5227fd2c-6972-4159-c8ca-6f59f3c2f314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lambda': 4.4267691662747115,\n",
              " 'alpha': 0.013590484679193908,\n",
              " 'colsample_bytree': 0.8,\n",
              " 'subsample': 0.8,\n",
              " 'learning_rate': 0.008,\n",
              " 'max_depth': 15,\n",
              " 'min_child_weight': 25}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y8_model_1 = XGBRegressor(**xgb_best_params_8)"
      ],
      "metadata": {
        "id": "ffSYQTLsfHgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'random_state': 42,\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "        \n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_drill_scaled, y_drill[:,7], eval_set=[(X_val_scaled,y_val[:,7])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,7], model_lgbm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "-6ddhIy7fVpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_lgbm.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skcciw3Efaz7",
        "outputId": "b1d18e05-4497-4cf4-c0c1-df2e436a5534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:07:50,791]\u001b[0m A new study created in memory with name: no-name-9319e670-5180-4ad9-b1dc-8b74129c8ee6\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:08:06,858]\u001b[0m Trial 0 finished with value: 0.6286091546254732 and parameters: {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:08:33,657]\u001b[0m Trial 1 finished with value: 0.6633297399771081 and parameters: {'max_depth': 5, 'learning_rate': 2.2310108018679158e-08, 'n_estimators': 2612, 'min_child_samples': 62, 'subsample': 0.765297684068612}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:08:45,055]\u001b[0m Trial 2 finished with value: 0.6319773804627898 and parameters: {'max_depth': 3, 'learning_rate': 0.006598711072054081, 'n_estimators': 2514, 'min_child_samples': 25, 'subsample': 0.4725148048142631}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:09:01,756]\u001b[0m Trial 3 finished with value: 0.6632842591828755 and parameters: {'max_depth': 5, 'learning_rate': 6.690421166498788e-07, 'n_estimators': 1622, 'min_child_samples': 46, 'subsample': 0.5223381155442193}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:09:15,010]\u001b[0m Trial 4 finished with value: 0.6633293645855544 and parameters: {'max_depth': 10, 'learning_rate': 6.870101665590006e-08, 'n_estimators': 947, 'min_child_samples': 40, 'subsample': 0.607503080954597}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:09:36,443]\u001b[0m Trial 5 finished with value: 0.6633206605985638 and parameters: {'max_depth': 13, 'learning_rate': 1.577766363058244e-07, 'n_estimators': 1591, 'min_child_samples': 61, 'subsample': 0.4173923345744613}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:09:40,326]\u001b[0m Trial 6 finished with value: 0.6633309514015324 and parameters: {'max_depth': 10, 'learning_rate': 1.0547383621352015e-07, 'n_estimators': 288, 'min_child_samples': 96, 'subsample': 0.9689996293810518}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:09:45,438]\u001b[0m Trial 7 finished with value: 0.6633203553860857 and parameters: {'max_depth': 13, 'learning_rate': 6.724850206557239e-07, 'n_estimators': 383, 'min_child_samples': 70, 'subsample': 0.5987069208932017}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:09:47,114]\u001b[0m Trial 8 finished with value: 0.6632570055322433 and parameters: {'max_depth': 4, 'learning_rate': 9.355380606452177e-06, 'n_estimators': 199, 'min_child_samples': 92, 'subsample': 0.5070361211081488}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:10:08,628]\u001b[0m Trial 9 finished with value: 0.6632762547846157 and parameters: {'max_depth': 11, 'learning_rate': 7.417652034871823e-07, 'n_estimators': 1608, 'min_child_samples': 57, 'subsample': 0.47382827709841974}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:10:24,847]\u001b[0m Trial 10 finished with value: 0.6287938200754575 and parameters: {'max_depth': 7, 'learning_rate': 0.003955232336089218, 'n_estimators': 2119, 'min_child_samples': 6, 'subsample': 0.405672369598035}. Best is trial 0 with value: 0.6286091546254732.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:10:35,916]\u001b[0m Trial 11 finished with value: 0.6284549061109906 and parameters: {'max_depth': 7, 'learning_rate': 0.007953409633698581, 'n_estimators': 2167, 'min_child_samples': 13, 'subsample': 0.4013720109047739}. Best is trial 11 with value: 0.6284549061109906.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:11:02,868]\u001b[0m Trial 12 finished with value: 0.640037339947259 and parameters: {'max_depth': 7, 'learning_rate': 0.0004511388495675214, 'n_estimators': 2070, 'min_child_samples': 9, 'subsample': 0.4060696340155517}. Best is trial 11 with value: 0.6284549061109906.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:11:39,079]\u001b[0m Trial 13 finished with value: 0.6491249907440281 and parameters: {'max_depth': 7, 'learning_rate': 0.0001378296140671229, 'n_estimators': 2991, 'min_child_samples': 80, 'subsample': 0.7228898200777368}. Best is trial 11 with value: 0.6284549061109906.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:12:06,357]\u001b[0m Trial 14 finished with value: 0.6375627366463222 and parameters: {'max_depth': 8, 'learning_rate': 0.0005559231881814425, 'n_estimators': 2115, 'min_child_samples': 31, 'subsample': 0.5500437593750167}. Best is trial 11 with value: 0.6284549061109906.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:12:21,459]\u001b[0m Trial 15 finished with value: 0.6617333297013214 and parameters: {'max_depth': 15, 'learning_rate': 3.213476103996379e-05, 'n_estimators': 1094, 'min_child_samples': 21, 'subsample': 0.4595849978287922}. Best is trial 11 with value: 0.6284549061109906.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:12:45,172]\u001b[0m Trial 16 finished with value: 0.6305726671151809 and parameters: {'max_depth': 6, 'learning_rate': 0.001601446145845733, 'n_estimators': 2469, 'min_child_samples': 76, 'subsample': 0.7368481236544839}. Best is trial 11 with value: 0.6284549061109906.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:12:54,519]\u001b[0m Trial 17 finished with value: 0.6284205070626291 and parameters: {'max_depth': 9, 'learning_rate': 0.008316150164448028, 'n_estimators': 2900, 'min_child_samples': 43, 'subsample': 0.45027291545271725}. Best is trial 17 with value: 0.6284205070626291.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:13:33,411]\u001b[0m Trial 18 finished with value: 0.6573215432679171 and parameters: {'max_depth': 9, 'learning_rate': 4.954868118986831e-05, 'n_estimators': 2945, 'min_child_samples': 41, 'subsample': 0.6679923989057894}. Best is trial 17 with value: 0.6284205070626291.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:14:06,290]\u001b[0m Trial 19 finished with value: 0.6311568089477844 and parameters: {'max_depth': 12, 'learning_rate': 0.001021046080653488, 'n_estimators': 2595, 'min_child_samples': 16, 'subsample': 0.8437581760674224}. Best is trial 17 with value: 0.6284205070626291.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:14:31,452]\u001b[0m Trial 20 finished with value: 0.6628107729589426 and parameters: {'max_depth': 9, 'learning_rate': 6.095354604255733e-06, 'n_estimators': 1866, 'min_child_samples': 34, 'subsample': 0.43636853690846394}. Best is trial 17 with value: 0.6284205070626291.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:14:41,308]\u001b[0m Trial 21 finished with value: 0.6284098715344606 and parameters: {'max_depth': 8, 'learning_rate': 0.009089386482629344, 'n_estimators': 2418, 'min_child_samples': 50, 'subsample': 0.4451927927234888}. Best is trial 21 with value: 0.6284098715344606.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:14:54,588]\u001b[0m Trial 22 finished with value: 0.628291007665037 and parameters: {'max_depth': 9, 'learning_rate': 0.008376293745312098, 'n_estimators': 2738, 'min_child_samples': 49, 'subsample': 0.5493834891731214}. Best is trial 22 with value: 0.628291007665037.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:15:24,952]\u001b[0m Trial 23 finished with value: 0.6291605989819753 and parameters: {'max_depth': 10, 'learning_rate': 0.0018277027540175286, 'n_estimators': 2743, 'min_child_samples': 51, 'subsample': 0.5586999886950182}. Best is trial 22 with value: 0.628291007665037.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:15:33,830]\u001b[0m Trial 24 finished with value: 0.6283843951786804 and parameters: {'max_depth': 8, 'learning_rate': 0.00964580510961756, 'n_estimators': 2798, 'min_child_samples': 47, 'subsample': 0.5055987722129028}. Best is trial 22 with value: 0.628291007665037.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:16:04,348]\u001b[0m Trial 25 finished with value: 0.6510585320621075 and parameters: {'max_depth': 8, 'learning_rate': 0.00014193693470811313, 'n_estimators': 2383, 'min_child_samples': 51, 'subsample': 0.5073839601678833}. Best is trial 22 with value: 0.628291007665037.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:16:39,751]\u001b[0m Trial 26 finished with value: 0.6464514255997024 and parameters: {'max_depth': 8, 'learning_rate': 0.00019679107270342814, 'n_estimators': 2705, 'min_child_samples': 35, 'subsample': 0.559247714637479}. Best is trial 22 with value: 0.628291007665037.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:17:02,242]\u001b[0m Trial 27 finished with value: 0.6299873797246787 and parameters: {'max_depth': 11, 'learning_rate': 0.001980708090926508, 'n_estimators': 1894, 'min_child_samples': 51, 'subsample': 0.4990767865739739}. Best is trial 22 with value: 0.628291007665037.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:17:28,285]\u001b[0m Trial 28 finished with value: 0.6374617748362883 and parameters: {'max_depth': 6, 'learning_rate': 0.0005334253253019623, 'n_estimators': 2385, 'min_child_samples': 74, 'subsample': 0.643810350435093}. Best is trial 22 with value: 0.628291007665037.\u001b[0m\n",
            "\u001b[32m[I 2022-08-26 06:17:39,722]\u001b[0m Trial 29 finished with value: 0.6305693924316487 and parameters: {'max_depth': 6, 'learning_rate': 0.003175961174288122, 'n_estimators': 1151, 'min_child_samples': 66, 'subsample': 0.5848750813809881}. Best is trial 22 with value: 0.628291007665037.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_trial_8 = optuna_lgbm.best_trial\n",
        "lgbm_best_params_8 = lgbm_best_trial_8.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_best_trial_8.value, lgbm_best_params_8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SQvj0QTfdQb",
        "outputId": "297b525f-a7e8-423c-8f7f-08110720cd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.628291007665037,\n",
            "params {'max_depth': 9, 'learning_rate': 0.008376293745312098, 'n_estimators': 2738, 'min_child_samples': 49, 'subsample': 0.5493834891731214}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params_8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZvznEjFffby",
        "outputId": "90fc0d1b-f771-4f98-b0c3-8872e3e578fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 9,\n",
              " 'learning_rate': 0.008376293745312098,\n",
              " 'n_estimators': 2738,\n",
              " 'min_child_samples': 49,\n",
              " 'subsample': 0.5493834891731214}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y8_model_2 = LGBMRegressor(**lgbm_best_params_8)"
      ],
      "metadata": {
        "id": "xI7s2u7nfkC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###y9"
      ],
      "metadata": {
        "id": "Rnk6VHU9geK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
        "        'n_estimators': 10000,\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
        "        'random_state': 42,\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_xgb = XGBRegressor(**param)\n",
        "    model_xgb = model_xgb.fit(X_drill_scaled, y_drill[:,8], eval_set=[(X_val_scaled,y_val[:,8])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,8], model_xgb.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "ozEmBATjgfZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_xgb.optimize(objective, n_trials=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4dOXnPLxgkgW",
        "outputId": "5ad93b7a-2f6b-48e3-8326-fb6dd0931b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:18:07,401]\u001b[0m A new study created in memory with name: no-name-e14a545d-6f2e-4ab3-987b-76dd6e9148ea\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:18:11,978]\u001b[0m Trial 0 finished with value: 0.6241180182982188 and parameters: {'lambda': 0.03148911647956861, 'alpha': 6.351221010640703, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 9, 'min_child_weight': 183}. Best is trial 0 with value: 0.6241180182982188.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:18:21,245]\u001b[0m Trial 1 finished with value: 0.6230916030267956 and parameters: {'lambda': 0.004809461967501573, 'alpha': 0.0018205657658407262, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 7, 'min_child_weight': 82}. Best is trial 1 with value: 0.6230916030267956.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:18:28,771]\u001b[0m Trial 2 finished with value: 0.624258084049217 and parameters: {'lambda': 2.0651425578959257, 'alpha': 0.026730883107816707, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 11, 'min_child_weight': 229}. Best is trial 1 with value: 0.6230916030267956.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:18:41,053]\u001b[0m Trial 3 finished with value: 0.6230113745016821 and parameters: {'lambda': 0.17583640270008521, 'alpha': 1.2130221181165162, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 15, 'min_child_weight': 34}. Best is trial 3 with value: 0.6230113745016821.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:18:56,746]\u001b[0m Trial 4 finished with value: 0.6239029559148724 and parameters: {'lambda': 0.008160948743089917, 'alpha': 0.05110120656497164, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 11, 'min_child_weight': 296}. Best is trial 3 with value: 0.6230113745016821.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:18:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:19:04,334]\u001b[0m Trial 5 finished with value: 0.6255209573647214 and parameters: {'lambda': 0.009294394155644996, 'alpha': 0.4881375191603672, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 5, 'min_child_weight': 198}. Best is trial 3 with value: 0.6230113745016821.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:19:15,932]\u001b[0m Trial 6 finished with value: 0.6228278926868595 and parameters: {'lambda': 1.857328833311487, 'alpha': 0.16626592254031872, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.01, 'max_depth': 15, 'min_child_weight': 98}. Best is trial 6 with value: 0.6228278926868595.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:19:22,204]\u001b[0m Trial 7 finished with value: 0.6247884422955784 and parameters: {'lambda': 0.9682012086882473, 'alpha': 0.39676339357448603, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 7, 'min_child_weight': 290}. Best is trial 6 with value: 0.6228278926868595.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:19:37,437]\u001b[0m Trial 8 finished with value: 0.6227983776424745 and parameters: {'lambda': 7.152863022216533, 'alpha': 2.5824850844906155, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'min_child_weight': 211}. Best is trial 8 with value: 0.6227983776424745.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:19:50,696]\u001b[0m Trial 9 finished with value: 0.6221939730855492 and parameters: {'lambda': 1.5246518242848615, 'alpha': 3.6309591863459096, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 82}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:21:17,426]\u001b[0m Trial 10 finished with value: 0.6225931666083752 and parameters: {'lambda': 0.1632209274580005, 'alpha': 0.009646572175508749, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 5}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:21:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:22:06,724]\u001b[0m Trial 11 finished with value: 0.6226666244026143 and parameters: {'lambda': 0.31356971313563703, 'alpha': 0.005674563804536959, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 9}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:22:22,435]\u001b[0m Trial 12 finished with value: 0.6222109255463218 and parameters: {'lambda': 0.07777786661662818, 'alpha': 0.009125703046060935, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 66}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:22:30,457]\u001b[0m Trial 13 finished with value: 0.6225510395696838 and parameters: {'lambda': 0.0012748888933395578, 'alpha': 0.0014993772924073567, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 103}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:22:41,085]\u001b[0m Trial 14 finished with value: 0.6229109443726882 and parameters: {'lambda': 0.04394959647420904, 'alpha': 9.278182550393057, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 63}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:22:53,640]\u001b[0m Trial 15 finished with value: 0.6227347091691529 and parameters: {'lambda': 0.5521008712893732, 'alpha': 0.014654417505747804, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 141}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:22:59,652]\u001b[0m Trial 16 finished with value: 0.6242467330031242 and parameters: {'lambda': 0.04579588598371662, 'alpha': 0.088202647578437, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 141}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:23:05,883]\u001b[0m Trial 17 finished with value: 0.6222734698363093 and parameters: {'lambda': 4.291819288125171, 'alpha': 0.004433497249380858, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 13, 'min_child_weight': 52}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:23:14,781]\u001b[0m Trial 18 finished with value: 0.623016956839217 and parameters: {'lambda': 0.08686865419501431, 'alpha': 0.31914768556465617, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.016, 'max_depth': 17, 'min_child_weight': 116}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:23:29,938]\u001b[0m Trial 19 finished with value: 0.6232906265517146 and parameters: {'lambda': 0.4776213087783672, 'alpha': 2.2126802758815494, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 38}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:23:46,178]\u001b[0m Trial 20 finished with value: 0.6228257479762433 and parameters: {'lambda': 9.928205727612593, 'alpha': 0.03450109010513152, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 11, 'min_child_weight': 74}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:23:54,029]\u001b[0m Trial 21 finished with value: 0.6226013489630314 and parameters: {'lambda': 3.4499321897805735, 'alpha': 0.0025152381542064917, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 13, 'min_child_weight': 46}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:23:59,773]\u001b[0m Trial 22 finished with value: 0.6233351116991257 and parameters: {'lambda': 3.5331362135879716, 'alpha': 0.0034104430998429204, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 13, 'min_child_weight': 119}. Best is trial 9 with value: 0.6221939730855492.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:23:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:24:07,700]\u001b[0m Trial 23 finished with value: 0.6217560958562188 and parameters: {'lambda': 1.1854313156839986, 'alpha': 0.009589978720009221, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.018, 'max_depth': 13, 'min_child_weight': 54}. Best is trial 23 with value: 0.6217560958562188.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:24:15,495]\u001b[0m Trial 24 finished with value: 0.6227366229827334 and parameters: {'lambda': 0.7359974431492611, 'alpha': 0.015020678970455708, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.018, 'max_depth': 17, 'min_child_weight': 83}. Best is trial 23 with value: 0.6217560958562188.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:24:23,600]\u001b[0m Trial 25 finished with value: 0.6239895911501878 and parameters: {'lambda': 1.6710551227518402, 'alpha': 0.1257159461363366, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.01, 'max_depth': 13, 'min_child_weight': 163}. Best is trial 23 with value: 0.6217560958562188.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:24:59,462]\u001b[0m Trial 26 finished with value: 0.6216370527150059 and parameters: {'lambda': 0.24923032032190026, 'alpha': 0.008142176350127131, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 23}. Best is trial 26 with value: 0.6216370527150059.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:24:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:25:25,990]\u001b[0m Trial 27 finished with value: 0.6220613534528748 and parameters: {'lambda': 0.33688139440668996, 'alpha': 0.00118371947367639, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 21}. Best is trial 26 with value: 0.6216370527150059.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:25:50,541]\u001b[0m Trial 28 finished with value: 0.6215007500588882 and parameters: {'lambda': 0.28960232464207414, 'alpha': 0.0010307371681676119, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 24}. Best is trial 28 with value: 0.6215007500588882.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:25:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:26:15,074]\u001b[0m Trial 29 finished with value: 0.6215007500588882 and parameters: {'lambda': 0.20288076962851576, 'alpha': 0.004630372762269713, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 24}. Best is trial 28 with value: 0.6215007500588882.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:26:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:26:39,405]\u001b[0m Trial 30 finished with value: 0.6215801039754304 and parameters: {'lambda': 0.019901713117523357, 'alpha': 0.0011365544133512507, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 27}. Best is trial 28 with value: 0.6215007500588882.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:26:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-26 06:27:03,353]\u001b[0m Trial 31 finished with value: 0.6207634963864082 and parameters: {'lambda': 0.018004235380130837, 'alpha': 0.0012257151406560275, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 26}. Best is trial 31 with value: 0.6207634963864082.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/core.py:613: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "  warnings.warn(\"Use subset (sliced data) of np.ndarray is not recommended \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:27:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-5fe8d9e48db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptuna_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptuna_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-881abed4fe8b>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Generate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_drill_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_drill\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_trial_9 = optuna_xgb.best_trial\n",
        "xgb_best_params_9 = xgb_best_trial_9.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(xgb_best_trial_9.value, xgb_best_params_9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K9MhE_dgl8I",
        "outputId": "b73a1c54-1bb3-4dc7-d56f-ddef2d0f0932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.6207634963864082,\n",
            "params {'lambda': 0.018004235380130837, 'alpha': 0.0012257151406560275, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 15, 'min_child_weight': 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_params_9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krTmY75xglzJ",
        "outputId": "c00cbb97-0468-4a6e-a0d7-0baf949455db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lambda': 0.018004235380130837,\n",
              " 'alpha': 0.0012257151406560275,\n",
              " 'colsample_bytree': 1.0,\n",
              " 'subsample': 0.6,\n",
              " 'learning_rate': 0.008,\n",
              " 'max_depth': 15,\n",
              " 'min_child_weight': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y9_model_1 = XGBRegressor(**xgb_best_params_9)"
      ],
      "metadata": {
        "id": "cfPhdvw3glqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'random_state': 42,\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "        \n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_drill_scaled, y_drill[:,8], eval_set=[(X_val_scaled,y_val[:,8])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,8], model_lgbm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "ihVWRL91glh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_lgbm.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "id": "raMR1LxxglYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_trial_9 = optuna_lgbm.best_trial\n",
        "lgbm_best_params_9 = lgbm_best_trial_9.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_best_trial_9.value, lgbm_best_params_9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui_CPQ88glOt",
        "outputId": "9868ac6d-44ee-446c-c870-388dcb3ecd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.6243633587162151,\n",
            "params {'max_depth': 9, 'learning_rate': 0.008316150164448028, 'n_estimators': 2900, 'min_child_samples': 43, 'subsample': 0.45027291545271725}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params_9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo87gwkggk4d",
        "outputId": "57fdf43b-71ee-4385-bf9d-aef046e289c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 9,\n",
              " 'learning_rate': 0.008316150164448028,\n",
              " 'n_estimators': 2900,\n",
              " 'min_child_samples': 43,\n",
              " 'subsample': 0.45027291545271725}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y9_model_2 = LGBMRegressor(**lgbm_best_params_9)"
      ],
      "metadata": {
        "id": "DAGnCtCVgzrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5emDZOuZ-irL"
      },
      "source": [
        "### y10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "invoRSPKBgx-"
      },
      "outputs": [],
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    cbrm_param = {\n",
        "        'random_state': 42,\n",
        "        'iterations':trial.suggest_int(\"iterations\", 4000, 25000),\n",
        "        'od_wait':trial.suggest_int('od_wait', 500, 2300),\n",
        "        'learning_rate' : trial.suggest_uniform('learning_rate',0.01, 1),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "        'subsample': trial.suggest_uniform('subsample',0,1),\n",
        "        'random_strength': trial.suggest_uniform('random_strength',10,50),\n",
        "        'depth': trial.suggest_int('depth',1, 15),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
        "        'colsample_bylevel':trial.suggest_float('colsample_bylevel', 0.4, 1.0),\n",
        "    }\n",
        "    \n",
        "    # Generate model\n",
        "    model_cbrm = CatBoostRegressor(**cbrm_param, verbose=False)\n",
        "    model_cbrm = model_cbrm.fit(X_drill_scaled, y_drill[:,9], eval_set=[(X_val_scaled,y_val[:,9])],early_stopping_rounds=25)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,9], model_cbrm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p1a7zTqBq-t",
        "outputId": "81434088-ad8a-4d69-ba2d-e523afab8759"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-08-24 11:20:27,746]\u001b[0m A new study created in memory with name: no-name-a1a4ec10-7e87-4f40-ad72-2458c722858c\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:20:41,399]\u001b[0m Trial 0 finished with value: 0.9304031522211641 and parameters: {'iterations': 10085, 'od_wait': 790, 'learning_rate': 0.9304006758191473, 'reg_lambda': 80.8120398752379, 'subsample': 0.6334037565104235, 'random_strength': 44.85842360750871, 'depth': 13, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 14, 'bagging_temperature': 1.4367095138664232, 'colsample_bylevel': 0.8844640930984375}. Best is trial 0 with value: 0.9304031522211641.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:21:30,448]\u001b[0m Trial 1 finished with value: 0.9057505113122615 and parameters: {'iterations': 22818, 'od_wait': 1072, 'learning_rate': 0.11895140528239999, 'reg_lambda': 22.793523974842543, 'subsample': 0.4271077886262563, 'random_strength': 42.72059063689972, 'depth': 13, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 8, 'bagging_temperature': 0.4673518999562751, 'colsample_bylevel': 0.5332646862824382}. Best is trial 1 with value: 0.9057505113122615.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:21:31,605]\u001b[0m Trial 2 finished with value: 0.9142912727048713 and parameters: {'iterations': 6517, 'od_wait': 1108, 'learning_rate': 0.943480606873394, 'reg_lambda': 32.32029997004621, 'subsample': 0.5187906217433661, 'random_strength': 38.12075835580711, 'depth': 6, 'min_data_in_leaf': 30, 'leaf_estimation_iterations': 15, 'bagging_temperature': 0.10165510266418734, 'colsample_bylevel': 0.6983491035354312}. Best is trial 1 with value: 0.9057505113122615.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:21:40,222]\u001b[0m Trial 3 finished with value: 0.8912935407866764 and parameters: {'iterations': 10318, 'od_wait': 1012, 'learning_rate': 0.04651807788098747, 'reg_lambda': 60.956437302346345, 'subsample': 0.5026790232288615, 'random_strength': 12.059150049999573, 'depth': 5, 'min_data_in_leaf': 28, 'leaf_estimation_iterations': 4, 'bagging_temperature': 0.03798214508453259, 'colsample_bylevel': 0.6936716561665378}. Best is trial 3 with value: 0.8912935407866764.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:21:41,490]\u001b[0m Trial 4 finished with value: 0.9125133651677073 and parameters: {'iterations': 24699, 'od_wait': 935, 'learning_rate': 0.6754141919318197, 'reg_lambda': 76.1619639166756, 'subsample': 0.23763754399239967, 'random_strength': 39.12865394447438, 'depth': 6, 'min_data_in_leaf': 19, 'leaf_estimation_iterations': 10, 'bagging_temperature': 1.390268671103501, 'colsample_bylevel': 0.454173862032645}. Best is trial 3 with value: 0.8912935407866764.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:21:43,154]\u001b[0m Trial 5 finished with value: 0.9195171015954101 and parameters: {'iterations': 21542, 'od_wait': 1077, 'learning_rate': 0.1946533252958557, 'reg_lambda': 4.0775237477249755, 'subsample': 0.5908929431882418, 'random_strength': 37.1025744736913, 'depth': 1, 'min_data_in_leaf': 16, 'leaf_estimation_iterations': 4, 'bagging_temperature': 3.8079493367685617, 'colsample_bylevel': 0.5046198574029949}. Best is trial 3 with value: 0.8912935407866764.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:22:02,390]\u001b[0m Trial 6 finished with value: 0.9370484254150139 and parameters: {'iterations': 18510, 'od_wait': 1196, 'learning_rate': 0.9373626888493671, 'reg_lambda': 13.752103039389883, 'subsample': 0.3410663510502585, 'random_strength': 14.538940849623563, 'depth': 14, 'min_data_in_leaf': 27, 'leaf_estimation_iterations': 4, 'bagging_temperature': 4.364516946807794, 'colsample_bylevel': 0.8903333201207295}. Best is trial 3 with value: 0.8912935407866764.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:22:08,323]\u001b[0m Trial 7 finished with value: 0.9082554290946602 and parameters: {'iterations': 15659, 'od_wait': 1453, 'learning_rate': 0.24943376799144718, 'reg_lambda': 9.310285849562243, 'subsample': 0.8972157579533268, 'random_strength': 46.016722286533216, 'depth': 10, 'min_data_in_leaf': 11, 'leaf_estimation_iterations': 6, 'bagging_temperature': 8.013508750140629, 'colsample_bylevel': 0.9382661559715463}. Best is trial 3 with value: 0.8912935407866764.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:22:10,154]\u001b[0m Trial 8 finished with value: 0.9205895464151146 and parameters: {'iterations': 22629, 'od_wait': 1904, 'learning_rate': 0.6456113296927449, 'reg_lambda': 8.414005658105232, 'subsample': 0.16162871409461377, 'random_strength': 45.94216754108317, 'depth': 10, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 2, 'bagging_temperature': 4.508240502480683, 'colsample_bylevel': 0.40303695030773123}. Best is trial 3 with value: 0.8912935407866764.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:22:11,446]\u001b[0m Trial 9 finished with value: 0.9146394805014616 and parameters: {'iterations': 7377, 'od_wait': 1488, 'learning_rate': 0.6949762457157663, 'reg_lambda': 65.19612943064746, 'subsample': 0.22426930946055978, 'random_strength': 38.48716885390144, 'depth': 4, 'min_data_in_leaf': 10, 'leaf_estimation_iterations': 12, 'bagging_temperature': 3.9676339357448613, 'colsample_bylevel': 0.9095340462965068}. Best is trial 3 with value: 0.8912935407866764.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:22:12,691]\u001b[0m Trial 10 finished with value: 0.9218611823425179 and parameters: {'iterations': 12104, 'od_wait': 576, 'learning_rate': 0.35767488726468777, 'reg_lambda': 98.72734870256296, 'subsample': 0.024006625852345476, 'random_strength': 11.570415176784032, 'depth': 1, 'min_data_in_leaf': 23, 'leaf_estimation_iterations': 1, 'bagging_temperature': 0.024061187857993147, 'colsample_bylevel': 0.7241008248915682}. Best is trial 3 with value: 0.8912935407866764.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:23:55,984]\u001b[0m Trial 11 finished with value: 0.8850903489819966 and parameters: {'iterations': 15326, 'od_wait': 1703, 'learning_rate': 0.020244954579405283, 'reg_lambda': 41.27827735619585, 'subsample': 0.7095421532212168, 'random_strength': 22.79111087059836, 'depth': 11, 'min_data_in_leaf': 2, 'leaf_estimation_iterations': 8, 'bagging_temperature': 87.31881337591867, 'colsample_bylevel': 0.5982655171720273}. Best is trial 11 with value: 0.8850903489819966.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:24:22,385]\u001b[0m Trial 12 finished with value: 0.8897178862809084 and parameters: {'iterations': 15011, 'od_wait': 1881, 'learning_rate': 0.03765269952902989, 'reg_lambda': 45.108638782371955, 'subsample': 0.7839568839004376, 'random_strength': 20.361862124814422, 'depth': 9, 'min_data_in_leaf': 21, 'leaf_estimation_iterations': 8, 'bagging_temperature': 85.05469019270728, 'colsample_bylevel': 0.6551894206417428}. Best is trial 11 with value: 0.8850903489819966.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:25:46,979]\u001b[0m Trial 13 finished with value: 0.8841459712254987 and parameters: {'iterations': 16387, 'od_wait': 2192, 'learning_rate': 0.015938239371125627, 'reg_lambda': 41.41674800364156, 'subsample': 0.8131881339174662, 'random_strength': 21.740329418814632, 'depth': 10, 'min_data_in_leaf': 21, 'leaf_estimation_iterations': 9, 'bagging_temperature': 93.0217039923052, 'colsample_bylevel': 0.6032070180326743}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:25:52,913]\u001b[0m Trial 14 finished with value: 0.9116063051681956 and parameters: {'iterations': 17547, 'od_wait': 2189, 'learning_rate': 0.3642318133445177, 'reg_lambda': 45.013794389097114, 'subsample': 0.9835769909151288, 'random_strength': 24.74277163841602, 'depth': 11, 'min_data_in_leaf': 16, 'leaf_estimation_iterations': 10, 'bagging_temperature': 45.71292636738302, 'colsample_bylevel': 0.5968732497636713}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:25:55,087]\u001b[0m Trial 15 finished with value: 0.9101969065168117 and parameters: {'iterations': 18561, 'od_wait': 2286, 'learning_rate': 0.46309652522856853, 'reg_lambda': 34.54433573300266, 'subsample': 0.7089610050789534, 'random_strength': 28.900568305074906, 'depth': 8, 'min_data_in_leaf': 12, 'leaf_estimation_iterations': 10, 'bagging_temperature': 19.445413273894676, 'colsample_bylevel': 0.8096507878048161}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:27:51,447]\u001b[0m Trial 16 finished with value: 0.9096959542926221 and parameters: {'iterations': 12927, 'od_wait': 1736, 'learning_rate': 0.2528437307095528, 'reg_lambda': 56.85494628826885, 'subsample': 0.8296137323251708, 'random_strength': 19.89626861995838, 'depth': 15, 'min_data_in_leaf': 7, 'leaf_estimation_iterations': 6, 'bagging_temperature': 25.9839644872692, 'colsample_bylevel': 0.5807676635909436}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:31:17,509]\u001b[0m Trial 17 finished with value: 0.8856285322550094 and parameters: {'iterations': 16695, 'od_wait': 2052, 'learning_rate': 0.011768747688240808, 'reg_lambda': 34.51215295353619, 'subsample': 0.7204608807194838, 'random_strength': 32.3195246997055, 'depth': 11, 'min_data_in_leaf': 24, 'leaf_estimation_iterations': 12, 'bagging_temperature': 79.29194725026437, 'colsample_bylevel': 0.7984515669743938}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:31:37,344]\u001b[0m Trial 18 finished with value: 0.89965592930432 and parameters: {'iterations': 20825, 'od_wait': 1694, 'learning_rate': 0.13776574693834862, 'reg_lambda': 23.016159955112244, 'subsample': 0.9474769143058591, 'random_strength': 18.87610630959861, 'depth': 12, 'min_data_in_leaf': 19, 'leaf_estimation_iterations': 7, 'bagging_temperature': 17.836712476948342, 'colsample_bylevel': 0.611320886783836}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:31:39,988]\u001b[0m Trial 19 finished with value: 0.9032496208550947 and parameters: {'iterations': 19683, 'od_wait': 2078, 'learning_rate': 0.3681941065649203, 'reg_lambda': 50.16943028704198, 'subsample': 0.8337541824074743, 'random_strength': 25.88037136540172, 'depth': 8, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 12, 'bagging_temperature': 0.35165124955503774, 'colsample_bylevel': 0.5253036936664268}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:31:41,605]\u001b[0m Trial 20 finished with value: 0.9130257424825825 and parameters: {'iterations': 4559, 'od_wait': 1674, 'learning_rate': 0.5245020264104298, 'reg_lambda': 72.57445390846415, 'subsample': 0.6478828301254735, 'random_strength': 31.148107103583463, 'depth': 7, 'min_data_in_leaf': 14, 'leaf_estimation_iterations': 9, 'bagging_temperature': 11.472855766216428, 'colsample_bylevel': 0.9937939791049382}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:32:59,482]\u001b[0m Trial 21 finished with value: 0.8874637289707487 and parameters: {'iterations': 15876, 'od_wait': 2067, 'learning_rate': 0.02808102389785221, 'reg_lambda': 35.7420215520479, 'subsample': 0.7150928930798253, 'random_strength': 32.86513589881622, 'depth': 11, 'min_data_in_leaf': 25, 'leaf_estimation_iterations': 12, 'bagging_temperature': 92.82239600316942, 'colsample_bylevel': 0.7769342342319527}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:33:27,914]\u001b[0m Trial 22 finished with value: 0.9053790353483161 and parameters: {'iterations': 17078, 'od_wait': 1909, 'learning_rate': 0.15267451276624922, 'reg_lambda': 26.858772761931704, 'subsample': 0.7386239719822635, 'random_strength': 24.324172608166077, 'depth': 12, 'min_data_in_leaf': 22, 'leaf_estimation_iterations': 13, 'bagging_temperature': 43.667683143127775, 'colsample_bylevel': 0.747977129667807}. Best is trial 13 with value: 0.8841459712254987.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:34:53,262]\u001b[0m Trial 23 finished with value: 0.8838046184423408 and parameters: {'iterations': 13857, 'od_wait': 2122, 'learning_rate': 0.01829837416617811, 'reg_lambda': 41.5111282449525, 'subsample': 0.8748593944280048, 'random_strength': 17.09029650343802, 'depth': 10, 'min_data_in_leaf': 24, 'leaf_estimation_iterations': 11, 'bagging_temperature': 94.17352111885091, 'colsample_bylevel': 0.8151518886699509}. Best is trial 23 with value: 0.8838046184423408.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:35:03,211]\u001b[0m Trial 24 finished with value: 0.8899923124023444 and parameters: {'iterations': 12820, 'od_wait': 2202, 'learning_rate': 0.10471308563729076, 'reg_lambda': 49.86430970526266, 'subsample': 0.8962881056238055, 'random_strength': 15.560196912603415, 'depth': 9, 'min_data_in_leaf': 19, 'leaf_estimation_iterations': 9, 'bagging_temperature': 41.67036866395551, 'colsample_bylevel': 0.627535135371258}. Best is trial 23 with value: 0.8838046184423408.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:35:08,416]\u001b[0m Trial 25 finished with value: 0.8980037470625083 and parameters: {'iterations': 13281, 'od_wait': 1589, 'learning_rate': 0.22758049224391638, 'reg_lambda': 41.98769503409154, 'subsample': 0.8686615731194038, 'random_strength': 22.159041964588855, 'depth': 9, 'min_data_in_leaf': 26, 'leaf_estimation_iterations': 11, 'bagging_temperature': 36.65097959411488, 'colsample_bylevel': 0.5696633414535573}. Best is trial 23 with value: 0.8838046184423408.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:35:13,824]\u001b[0m Trial 26 finished with value: 0.90003385322539 and parameters: {'iterations': 10957, 'od_wait': 1326, 'learning_rate': 0.3100064323648121, 'reg_lambda': 55.754902094933314, 'subsample': 0.9985299078350927, 'random_strength': 16.50415322092896, 'depth': 10, 'min_data_in_leaf': 21, 'leaf_estimation_iterations': 6, 'bagging_temperature': 12.549814550609115, 'colsample_bylevel': 0.8417022669567366}. Best is trial 23 with value: 0.8838046184423408.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:36:23,451]\u001b[0m Trial 27 finished with value: 0.9026281967775241 and parameters: {'iterations': 14080, 'od_wait': 1809, 'learning_rate': 0.09305954297106504, 'reg_lambda': 17.998643397507387, 'subsample': 0.570956713789497, 'random_strength': 28.19015322367776, 'depth': 13, 'min_data_in_leaf': 30, 'leaf_estimation_iterations': 9, 'bagging_temperature': 98.3130334995259, 'colsample_bylevel': 0.6720921381926342}. Best is trial 23 with value: 0.8838046184423408.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:38:46,204]\u001b[0m Trial 28 finished with value: 0.9001594698148171 and parameters: {'iterations': 9048, 'od_wait': 1999, 'learning_rate': 0.16988454517628215, 'reg_lambda': 40.72296735145085, 'subsample': 0.8157307607248975, 'random_strength': 17.626447608508062, 'depth': 15, 'min_data_in_leaf': 17, 'leaf_estimation_iterations': 7, 'bagging_temperature': 26.584922144836227, 'colsample_bylevel': 0.4883044310506041}. Best is trial 23 with value: 0.8838046184423408.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 11:38:51,124]\u001b[0m Trial 29 finished with value: 0.9372650968863221 and parameters: {'iterations': 15074, 'od_wait': 2236, 'learning_rate': 0.8400379185420792, 'reg_lambda': 90.83942639132678, 'subsample': 0.6507396799522658, 'random_strength': 22.68247903120038, 'depth': 12, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 15, 'bagging_temperature': 0.5428155350077335, 'colsample_bylevel': 0.6443247881220349}. Best is trial 23 with value: 0.8838046184423408.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "optuna_cbrm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_cbrm.optimize(objective, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwipAUXxB07C",
        "outputId": "677858fb-7201-4be0-dd46-18ae2f5d0ef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Trial: score 0.8838046184423408,\n",
            "params {'iterations': 13857, 'od_wait': 2122, 'learning_rate': 0.01829837416617811, 'reg_lambda': 41.5111282449525, 'subsample': 0.8748593944280048, 'random_strength': 17.09029650343802, 'depth': 10, 'min_data_in_leaf': 24, 'leaf_estimation_iterations': 11, 'bagging_temperature': 94.17352111885091, 'colsample_bylevel': 0.8151518886699509}\n"
          ]
        }
      ],
      "source": [
        "cbrm_best_trial_10 = optuna_cbrm.best_trial\n",
        "cbrm_best_params_10 = cbrm_best_trial_10.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(cbrm_best_trial_10.value, cbrm_best_params_10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVxX899JlRzq"
      },
      "outputs": [],
      "source": [
        "cbrm_best_params_10 = {'iterations': 13857,\n",
        " 'od_wait': 2122,\n",
        " 'learning_rate': 0.01829837416617811,\n",
        " 'reg_lambda': 41.5111282449525,\n",
        " 'subsample': 0.8748593944280048,\n",
        " 'random_strength': 17.09029650343802,\n",
        " 'depth': 10,\n",
        " 'min_data_in_leaf': 24,\n",
        " 'leaf_estimation_iterations': 11,\n",
        " 'bagging_temperature': 94.17352111885091,\n",
        " 'colsample_bylevel': 0.8151518886699509}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbrm_best_params_10 = "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61DzZgBD28GG",
        "outputId": "462a19e0-1889-4309-9907-49f6e190d079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'iterations': 13857,\n",
              " 'od_wait': 2122,\n",
              " 'learning_rate': 0.01829837416617811,\n",
              " 'reg_lambda': 41.5111282449525,\n",
              " 'subsample': 0.8748593944280048,\n",
              " 'random_strength': 17.09029650343802,\n",
              " 'depth': 10,\n",
              " 'min_data_in_leaf': 24,\n",
              " 'leaf_estimation_iterations': 11,\n",
              " 'bagging_temperature': 94.17352111885091,\n",
              " 'colsample_bylevel': 0.8151518886699509}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lYwEGDfCMNB"
      },
      "outputs": [],
      "source": [
        "y10_model = CatBoostRegressor(**cbrm_best_params_10,verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tni-kYg0CQX3",
        "outputId": "4b665b24-110b-4b3c-a2e8-ce66c1c15e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test loss: 0.8398904150826285\n"
          ]
        }
      ],
      "source": [
        "y10_model.fit(X_train_scaled,y_train[:,9]) #전체 test data fit\n",
        "y10_pred = y10_model.predict(X_test_scaled)\n",
        "print(f'test loss: {rmse(y_test[:,9],y10_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HYvxZt7DUCj"
      },
      "source": [
        "### Y11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGHJ80z6DVKK"
      },
      "outputs": [],
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    cbrm_param = {\n",
        "        'random_state': 42,\n",
        "        'iterations':trial.suggest_int(\"iterations\", 4000, 25000),\n",
        "        'od_wait':trial.suggest_int('od_wait', 500, 2300),\n",
        "        'learning_rate' : trial.suggest_uniform('learning_rate',0.01, 1),\n",
        "        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "        'subsample': trial.suggest_uniform('subsample',0,1),\n",
        "        'random_strength': trial.suggest_uniform('random_strength',10,50),\n",
        "        'depth': trial.suggest_int('depth',1, 15),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
        "        'colsample_bylevel':trial.suggest_float('colsample_bylevel', 0.4, 1.0),\n",
        "    }\n",
        "    \n",
        "    # Generate model\n",
        "    model_cbrm = CatBoostRegressor(**cbrm_param, verbose=False)\n",
        "    model_cbrm = model_cbrm.fit(X_drill_scaled, y_drill[:,10], eval_set=[(X_val_scaled,y_val[:,10])],early_stopping_rounds=20)\n",
        "    #early stopping roundS를 넘어갔는데도 성능향상 없으면 중단\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,10], model_cbrm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiIGassuEZ18"
      },
      "outputs": [],
      "source": [
        "optuna_cbrm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_cbrm.optimize(objective, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSL466gaEbyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae353dcd-04ab-4fc9-c2b2-d9104aeea87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.8113013244625743,\n",
            "params {'iterations': 4009, 'od_wait': 1292, 'learning_rate': 0.02407247984826967, 'reg_lambda': 51.02141769858517, 'subsample': 0.6155395247060361, 'random_strength': 42.179839919773, 'depth': 9, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 9, 'bagging_temperature': 27.54114280742721, 'colsample_bylevel': 0.6162018869852633}\n"
          ]
        }
      ],
      "source": [
        "cbrm_best_trial_11 = optuna_cbrm.best_trial\n",
        "cbrm_best_params_11 = cbrm_best_trial_11.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(cbrm_best_trial_11.value, cbrm_best_params_11))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbrm_best_params_11 = {'iterations': 4009, 'od_wait': 1292, 'learning_rate': 0.02407247984826967, 'reg_lambda': 51.02141769858517, 'subsample': 0.6155395247060361, 'random_strength': 42.179839919773, 'depth': 9, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 9, 'bagging_temperature': 27.54114280742721, 'colsample_bylevel': 0.6162018869852633}"
      ],
      "metadata": {
        "id": "kwF2rbds3A5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whmaTEVlEeZ0"
      },
      "outputs": [],
      "source": [
        "y11_model = CatBoostRegressor(**cbrm_best_params_11,verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43NcWb8REgyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f62d49c-e0ee-4674-d26a-ed3c93bb4605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.8014265347474039\n"
          ]
        }
      ],
      "source": [
        "y11_model.fit(X_train_scaled,y_train[:,10]) #전체 test data fit\n",
        "y11_pred = y11_model.predict(X_test_scaled)\n",
        "print(f'test loss: {rmse(y_test[:,10],y11_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N4oKBrqEo8H"
      },
      "source": [
        "### y12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otZr_08dEqBK"
      },
      "outputs": [],
      "source": [
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    cbrm_param = {\n",
        "            'random_state':42,\n",
        "            'iterations':trial.suggest_int(\"iterations\", 4000, 25000),\n",
        "            'od_wait':trial.suggest_int('od_wait', 500, 2300),\n",
        "            'learning_rate' : trial.suggest_uniform('learning_rate',0.01, 1),\n",
        "            'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "            'subsample': trial.suggest_uniform('subsample',0,1),\n",
        "            'random_strength': trial.suggest_uniform('random_strength',10,50),\n",
        "            'depth': trial.suggest_int('depth',1, 15),\n",
        "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_cbrm = CatBoostRegressor(**cbrm_param, verbose=False)\n",
        "    model_cbrm = model_cbrm.fit(X_drill_scaled, y_drill[:,11], eval_set=[(X_val_scaled,y_val[:,11])],early_stopping_rounds=20)\n",
        "    #early stopping roundS를 넘어갔는데도 성능향상 없으면 중단\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,11], model_cbrm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mayS7w6PFEde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ce1fd2-9212-40dd-e274-9c1b056b0bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-24 17:43:36,997]\u001b[0m A new study created in memory with name: no-name-7af598fb-f698-4084-aa4b-d6fe90ee2b75\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:44:25,265]\u001b[0m Trial 0 finished with value: 0.6402541628333454 and parameters: {'iterations': 20705, 'od_wait': 2169, 'learning_rate': 0.242295661036899, 'reg_lambda': 39.931597587771655, 'subsample': 0.15241601333041743, 'random_strength': 49.699340086335006, 'depth': 14, 'min_data_in_leaf': 17, 'leaf_estimation_iterations': 13}. Best is trial 0 with value: 0.6402541628333454.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:34,758]\u001b[0m Trial 1 finished with value: 0.631524647300951 and parameters: {'iterations': 14940, 'od_wait': 1623, 'learning_rate': 0.09823318779485644, 'reg_lambda': 75.52704449697659, 'subsample': 0.12771348363523483, 'random_strength': 43.04270521010113, 'depth': 12, 'min_data_in_leaf': 22, 'leaf_estimation_iterations': 1}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:36,087]\u001b[0m Trial 2 finished with value: 0.6355284289940065 and parameters: {'iterations': 10365, 'od_wait': 973, 'learning_rate': 0.36653504339680393, 'reg_lambda': 8.764283799956386, 'subsample': 0.9369578230310628, 'random_strength': 32.15208962849505, 'depth': 5, 'min_data_in_leaf': 12, 'leaf_estimation_iterations': 7}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:37,006]\u001b[0m Trial 3 finished with value: 0.6396036104177809 and parameters: {'iterations': 16613, 'od_wait': 1428, 'learning_rate': 0.9201980534822731, 'reg_lambda': 49.6963533209482, 'subsample': 0.9921580148233127, 'random_strength': 44.05699830980383, 'depth': 4, 'min_data_in_leaf': 28, 'leaf_estimation_iterations': 2}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:38,147]\u001b[0m Trial 4 finished with value: 0.6394366470096663 and parameters: {'iterations': 21167, 'od_wait': 1185, 'learning_rate': 0.8791945772406188, 'reg_lambda': 86.80567033017813, 'subsample': 0.8059254001176211, 'random_strength': 41.601217452282455, 'depth': 5, 'min_data_in_leaf': 3, 'leaf_estimation_iterations': 7}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:39,949]\u001b[0m Trial 5 finished with value: 0.6339668950712194 and parameters: {'iterations': 7644, 'od_wait': 1751, 'learning_rate': 0.3526387292724077, 'reg_lambda': 97.56102032988949, 'subsample': 0.640972077345332, 'random_strength': 42.899222545374435, 'depth': 2, 'min_data_in_leaf': 26, 'leaf_estimation_iterations': 14}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:40,972]\u001b[0m Trial 6 finished with value: 0.6344616987573718 and parameters: {'iterations': 14228, 'od_wait': 1591, 'learning_rate': 0.7671617028939655, 'reg_lambda': 17.48387097765498, 'subsample': 0.5025660764634424, 'random_strength': 25.946521110892526, 'depth': 3, 'min_data_in_leaf': 12, 'leaf_estimation_iterations': 2}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:41,994]\u001b[0m Trial 7 finished with value: 0.6409701541745223 and parameters: {'iterations': 4542, 'od_wait': 743, 'learning_rate': 0.9634839604732821, 'reg_lambda': 54.95295809420634, 'subsample': 0.96582216115322, 'random_strength': 27.29991513320528, 'depth': 5, 'min_data_in_leaf': 16, 'leaf_estimation_iterations': 7}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:44,152]\u001b[0m Trial 8 finished with value: 0.6384098672019458 and parameters: {'iterations': 6219, 'od_wait': 1654, 'learning_rate': 0.2238778006845036, 'reg_lambda': 61.95879929390341, 'subsample': 0.6502010923981534, 'random_strength': 16.080994125145924, 'depth': 1, 'min_data_in_leaf': 24, 'leaf_estimation_iterations': 7}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:48,269]\u001b[0m Trial 9 finished with value: 0.6326644022709779 and parameters: {'iterations': 5221, 'od_wait': 2291, 'learning_rate': 0.06720275538640297, 'reg_lambda': 69.50352593550303, 'subsample': 0.9836789252634136, 'random_strength': 19.567204168637026, 'depth': 3, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 5}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:45:53,081]\u001b[0m Trial 10 finished with value: 0.6501745095596893 and parameters: {'iterations': 24565, 'od_wait': 536, 'learning_rate': 0.683379025993381, 'reg_lambda': 78.37401825909053, 'subsample': 0.010039999587509077, 'random_strength': 35.52308657780228, 'depth': 12, 'min_data_in_leaf': 21, 'leaf_estimation_iterations': 11}. Best is trial 1 with value: 0.631524647300951.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:46:10,178]\u001b[0m Trial 11 finished with value: 0.6295116216914077 and parameters: {'iterations': 13221, 'od_wait': 2297, 'learning_rate': 0.04671012961670374, 'reg_lambda': 72.13226661760014, 'subsample': 0.27819646415698096, 'random_strength': 15.560094308563581, 'depth': 9, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 4}. Best is trial 11 with value: 0.6295116216914077.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:46:44,339]\u001b[0m Trial 12 finished with value: 0.6302890122030994 and parameters: {'iterations': 13706, 'od_wait': 1969, 'learning_rate': 0.029182811753289722, 'reg_lambda': 36.298834527307626, 'subsample': 0.2390943274186898, 'random_strength': 11.624579936036904, 'depth': 10, 'min_data_in_leaf': 9, 'leaf_estimation_iterations': 1}. Best is trial 11 with value: 0.6295116216914077.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:47:02,157]\u001b[0m Trial 13 finished with value: 0.6296797890451256 and parameters: {'iterations': 10549, 'od_wait': 1965, 'learning_rate': 0.04462040631871611, 'reg_lambda': 36.77840080488848, 'subsample': 0.34270028686801274, 'random_strength': 10.436308178159928, 'depth': 9, 'min_data_in_leaf': 8, 'leaf_estimation_iterations': 4}. Best is trial 11 with value: 0.6295116216914077.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:47:03,672]\u001b[0m Trial 14 finished with value: 0.6378546955821902 and parameters: {'iterations': 10915, 'od_wait': 2021, 'learning_rate': 0.5217003154772439, 'reg_lambda': 25.57479538002053, 'subsample': 0.3640202011533338, 'random_strength': 10.21987910887476, 'depth': 8, 'min_data_in_leaf': 7, 'leaf_estimation_iterations': 4}. Best is trial 11 with value: 0.6295116216914077.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:47:06,661]\u001b[0m Trial 15 finished with value: 0.6335564329785864 and parameters: {'iterations': 10373, 'od_wait': 1959, 'learning_rate': 0.19482463000582922, 'reg_lambda': 37.798049780897074, 'subsample': 0.37729658422583223, 'random_strength': 20.94468970359883, 'depth': 8, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 5}. Best is trial 11 with value: 0.6295116216914077.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:47:09,424]\u001b[0m Trial 16 finished with value: 0.6410190812869601 and parameters: {'iterations': 17371, 'od_wait': 2199, 'learning_rate': 0.5179785499574886, 'reg_lambda': 49.386281343961215, 'subsample': 0.33605506228859294, 'random_strength': 15.463191858170969, 'depth': 10, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 10}. Best is trial 11 with value: 0.6295116216914077.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:47:10,951]\u001b[0m Trial 17 finished with value: 0.6389883783960942 and parameters: {'iterations': 8716, 'od_wait': 1862, 'learning_rate': 0.3827490601710497, 'reg_lambda': 1.401887707935856, 'subsample': 0.5147476189276744, 'random_strength': 21.326824516223773, 'depth': 7, 'min_data_in_leaf': 11, 'leaf_estimation_iterations': 4}. Best is trial 11 with value: 0.6295116216914077.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:47:18,355]\u001b[0m Trial 18 finished with value: 0.6360078728966582 and parameters: {'iterations': 12292, 'od_wait': 1313, 'learning_rate': 0.1451033703584102, 'reg_lambda': 25.989520925136517, 'subsample': 0.24421867996241364, 'random_strength': 15.191337461877096, 'depth': 10, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 9}. Best is trial 11 with value: 0.6295116216914077.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:48:52,444]\u001b[0m Trial 19 finished with value: 0.641424596830672 and parameters: {'iterations': 18109, 'od_wait': 2121, 'learning_rate': 0.32262260795001385, 'reg_lambda': 60.21199093444122, 'subsample': 0.014328068864461863, 'random_strength': 24.953148361921805, 'depth': 15, 'min_data_in_leaf': 7, 'leaf_estimation_iterations': 3}. Best is trial 11 with value: 0.6295116216914077.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:53:37,059]\u001b[0m Trial 20 finished with value: 0.6273099377854614 and parameters: {'iterations': 8426, 'od_wait': 2282, 'learning_rate': 0.01641416682919672, 'reg_lambda': 92.44968140587697, 'subsample': 0.5948931250553261, 'random_strength': 12.82043911557924, 'depth': 12, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 5}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:56:40,377]\u001b[0m Trial 21 finished with value: 0.629821940963595 and parameters: {'iterations': 8256, 'od_wait': 2298, 'learning_rate': 0.016226950917666603, 'reg_lambda': 98.18938877158746, 'subsample': 0.6137642302812928, 'random_strength': 12.595898712829646, 'depth': 12, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 5}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:56:56,002]\u001b[0m Trial 22 finished with value: 0.631900752281044 and parameters: {'iterations': 12304, 'od_wait': 2051, 'learning_rate': 0.1381983488414013, 'reg_lambda': 85.62310753792052, 'subsample': 0.42730676741995943, 'random_strength': 18.601754460168216, 'depth': 11, 'min_data_in_leaf': 9, 'leaf_estimation_iterations': 4}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:56:57,919]\u001b[0m Trial 23 finished with value: 0.6330360174451299 and parameters: {'iterations': 6837, 'od_wait': 1804, 'learning_rate': 0.24726728252407187, 'reg_lambda': 87.99010855886966, 'subsample': 0.7299362389597492, 'random_strength': 10.266563937551808, 'depth': 7, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 6}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:57:50,153]\u001b[0m Trial 24 finished with value: 0.627625616714823 and parameters: {'iterations': 9468, 'od_wait': 2287, 'learning_rate': 0.016579961055315125, 'reg_lambda': 69.04165802112148, 'subsample': 0.26956908166374505, 'random_strength': 14.579949551522963, 'depth': 9, 'min_data_in_leaf': 5, 'leaf_estimation_iterations': 2}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:58:43,768]\u001b[0m Trial 25 finished with value: 0.6341226238472366 and parameters: {'iterations': 9211, 'od_wait': 2178, 'learning_rate': 0.13628580403821472, 'reg_lambda': 68.4241791843841, 'subsample': 0.23027054299621302, 'random_strength': 23.61760338319083, 'depth': 13, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 3}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:58:45,091]\u001b[0m Trial 26 finished with value: 0.6391435244925359 and parameters: {'iterations': 12346, 'od_wait': 2300, 'learning_rate': 0.6068266913083011, 'reg_lambda': 78.39906444436728, 'subsample': 0.44985101567977376, 'random_strength': 17.210648020255597, 'depth': 7, 'min_data_in_leaf': 14, 'leaf_estimation_iterations': 3}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:59:34,513]\u001b[0m Trial 27 finished with value: 0.6280993310535308 and parameters: {'iterations': 15709, 'od_wait': 2114, 'learning_rate': 0.015386309723468647, 'reg_lambda': 92.14650931661555, 'subsample': 0.5841653850670043, 'random_strength': 13.561051852036842, 'depth': 9, 'min_data_in_leaf': 5, 'leaf_estimation_iterations': 2}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 17:59:47,294]\u001b[0m Trial 28 finished with value: 0.6296021158425077 and parameters: {'iterations': 15787, 'od_wait': 1871, 'learning_rate': 0.2940570937374103, 'reg_lambda': 87.64796583473118, 'subsample': 0.5815626053148063, 'random_strength': 13.696015396825379, 'depth': 11, 'min_data_in_leaf': 5, 'leaf_estimation_iterations': 1}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n",
            "\u001b[32m[I 2022-08-24 18:01:29,950]\u001b[0m Trial 29 finished with value: 0.6407006696981848 and parameters: {'iterations': 19226, 'od_wait': 2140, 'learning_rate': 0.43558774891465984, 'reg_lambda': 82.10934257916828, 'subsample': 0.7677898182396943, 'random_strength': 28.885210069057653, 'depth': 15, 'min_data_in_leaf': 18, 'leaf_estimation_iterations': 2}. Best is trial 20 with value: 0.6273099377854614.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "optuna_cbrm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_cbrm.optimize(objective, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USLTEQMFFGcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7fbedd-36b4-49a2-9754-49c7498fa44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.6273099377854614,\n",
            "params {'iterations': 8426, 'od_wait': 2282, 'learning_rate': 0.01641416682919672, 'reg_lambda': 92.44968140587697, 'subsample': 0.5948931250553261, 'random_strength': 12.82043911557924, 'depth': 12, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 5}\n"
          ]
        }
      ],
      "source": [
        "cbrm_best_trial_12 = optuna_cbrm.best_trial\n",
        "cbrm_best_params_12 = cbrm_best_trial_12.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(cbrm_best_trial_12.value, cbrm_best_params_12))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbrm_best_params_12 = {'iterations': 8426, 'od_wait': 2282, 'learning_rate': 0.01641416682919672, 'reg_lambda': 92.44968140587697, 'subsample': 0.5948931250553261, 'random_strength': 12.82043911557924, 'depth': 12, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 5}"
      ],
      "metadata": {
        "id": "nEupTMp54E1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6zibicMFLM1"
      },
      "outputs": [],
      "source": [
        "y12_model = CatBoostRegressor(**cbrm_best_params_12,verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaHT-r-QFNii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9873c0b7-e09a-49d9-ace9-f9d0b7ac2e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.6297597021243172\n"
          ]
        }
      ],
      "source": [
        "y12_model.fit(X_train_scaled,y_train[:,11]) #전체 test data fit\n",
        "y12_pred = y12_model.predict(X_test_scaled)\n",
        "print(f'test loss: {rmse(y_test[:,11],y12_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###y13"
      ],
      "metadata": {
        "id": "qK9bcI2WjJVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    param = {\n",
        "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
        "        'n_estimators': 10000,\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
        "        'random_state': 42,\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_xgb = XGBRegressor(**param)\n",
        "    model_xgb = model_xgb.fit(X_drill_scaled, y_drill[:,12], eval_set=[(X_val_scaled,y_val[:,12])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,12], model_xgb.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "gepXr-atjLeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_xgb.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "id": "iLv-WU5-jTL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_trial_13 = optuna_xgb.best_trial\n",
        "xgb_best_params_13 = xgb_best_trial_13.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(xgb_best_trial_13.value, xgb_best_params_13))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWoRvCYyjYEo",
        "outputId": "81ef371f-3cd9-457e-fc75-608111f009ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.6237711129950687,\n",
            "params {'lambda': 0.1632209274580005, 'alpha': 0.009646572175508749, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 17, 'min_child_weight': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_best_params_13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aesx7ixKjX1Y",
        "outputId": "0c6b028b-efe1-4f6f-fd52-e863268416bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lambda': 0.1632209274580005,\n",
              " 'alpha': 0.009646572175508749,\n",
              " 'colsample_bytree': 0.6,\n",
              " 'subsample': 0.7,\n",
              " 'learning_rate': 0.01,\n",
              " 'max_depth': 17,\n",
              " 'min_child_weight': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y13_model_1 = XGBRegressor(**xgb_best_params_13)"
      ],
      "metadata": {
        "id": "aC7YabsKjXfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampler\n",
        "sampler = TPESampler(seed=42)\n",
        "\n",
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    lgbm_param = {\n",
        "        'random_state': 42,\n",
        "        'objective': 'regression', # 회귀\n",
        "        'verbose': -1,\n",
        "        'metric': 'rmse', \n",
        "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
        "    }\n",
        "        \n",
        "    # Generate model\n",
        "    model_lgbm = LGBMRegressor(**lgbm_param)\n",
        "    model_lgbm = model_lgbm.fit(X_drill_scaled, y_drill[:,12], eval_set=[(X_val_scaled,y_val[:,12])],early_stopping_rounds=100,verbose=False)\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,12], model_lgbm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "fPTzTJHgjW4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_lgbm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_lgbm.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "id": "q0XLnW1BjWXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_trial_13 = optuna_lgbm.best_trial\n",
        "lgbm_best_params_13 = lgbm_best_trial_13.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(lgbm_best_trial_13.value, lgbm_best_params_13))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCPWSnRKjVw5",
        "outputId": "4baf5cad-5f23-4d2e-966c-ad09078f3c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.627728715561431,\n",
            "params {'max_depth': 7, 'learning_rate': 0.005061576888752304, 'n_estimators': 2223, 'min_child_samples': 62, 'subsample': 0.46147273880126555}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params_13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m3uDYGvjTsi",
        "outputId": "98e40fbb-8885-48a0-f45c-88135a8dc0a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 7,\n",
              " 'learning_rate': 0.005061576888752304,\n",
              " 'n_estimators': 2223,\n",
              " 'min_child_samples': 62,\n",
              " 'subsample': 0.46147273880126555}"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y13_model_2 = LGBMRegressor(**lgbm_best_params_13)"
      ],
      "metadata": {
        "id": "EXlYqCUkjvX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn8pyZufFVZ6"
      },
      "source": [
        "###y14"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function\n",
        "def objective(trial):\n",
        "\n",
        "    cbrm_param = {\n",
        "            'random_state':42,\n",
        "            'iterations':trial.suggest_int(\"iterations\", 4000, 25000),\n",
        "            'od_wait':trial.suggest_int('od_wait', 500, 2300),\n",
        "            'learning_rate' : trial.suggest_uniform('learning_rate',0.01, 1),\n",
        "            'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "            'subsample': trial.suggest_uniform('subsample',0,1),\n",
        "            'random_strength': trial.suggest_uniform('random_strength',10,50),\n",
        "            'depth': trial.suggest_int('depth',1, 15),\n",
        "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "    }\n",
        "\n",
        "    # Generate model\n",
        "    model_cbrm = CatBoostRegressor(**cbrm_param, verbose=False)\n",
        "    model_cbrm = model_cbrm.fit(X_drill_scaled, y_drill[:,13], eval_set=[(X_val_scaled,y_val[:,13])],early_stopping_rounds=25)\n",
        "    #early stopping roundS를 넘어갔는데도 성능향상 없으면 중단\n",
        "                           \n",
        "\t# 평가지표 원하는 평가 지표가 있을 시 바꾸어 준다.\n",
        "    RMSE = np.sqrt(mean_squared_error(y_val[:,13], model_cbrm.predict(X_val_scaled)))\n",
        "    return RMSE"
      ],
      "metadata": {
        "id": "UAAFH_Zf9lmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna_cbrm = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "optuna_cbrm.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZPe8VIR9xgc",
        "outputId": "3cb05b04-0361-4adc-ab53-7d7ce66932d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-25 05:21:28,233]\u001b[0m A new study created in memory with name: no-name-93a88c52-3e82-4266-8a74-bb246176a1a7\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:32,093]\u001b[0m Trial 0 finished with value: 0.637983916689016 and parameters: {'iterations': 11465, 'od_wait': 1930, 'learning_rate': 0.10206073342490084, 'reg_lambda': 58.82023081281638, 'subsample': 0.48097288988612374, 'random_strength': 35.693021036209096, 'depth': 1, 'min_data_in_leaf': 18, 'leaf_estimation_iterations': 9}. Best is trial 0 with value: 0.637983916689016.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:33,723]\u001b[0m Trial 1 finished with value: 0.6346541245562606 and parameters: {'iterations': 15774, 'od_wait': 1586, 'learning_rate': 0.6797032578540986, 'reg_lambda': 80.49890191818697, 'subsample': 0.26982072012821434, 'random_strength': 43.001976407202484, 'depth': 8, 'min_data_in_leaf': 3, 'leaf_estimation_iterations': 1}. Best is trial 1 with value: 0.6346541245562606.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:34,661]\u001b[0m Trial 2 finished with value: 0.636529613899935 and parameters: {'iterations': 11019, 'od_wait': 1913, 'learning_rate': 0.7106041253935066, 'reg_lambda': 78.861498581091, 'subsample': 0.5172690564416094, 'random_strength': 27.60795991821962, 'depth': 3, 'min_data_in_leaf': 10, 'leaf_estimation_iterations': 7}. Best is trial 1 with value: 0.6346541245562606.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:38,041]\u001b[0m Trial 3 finished with value: 0.6429607543003432 and parameters: {'iterations': 5860, 'od_wait': 897, 'learning_rate': 0.6022430411231015, 'reg_lambda': 73.56631406728785, 'subsample': 0.9983475113929496, 'random_strength': 47.32453325374231, 'depth': 10, 'min_data_in_leaf': 13, 'leaf_estimation_iterations': 10}. Best is trial 1 with value: 0.6346541245562606.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:40,525]\u001b[0m Trial 4 finished with value: 0.6365525744343792 and parameters: {'iterations': 20499, 'od_wait': 713, 'learning_rate': 0.41580584079932537, 'reg_lambda': 83.98023016553887, 'subsample': 0.383832951933044, 'random_strength': 32.874890849087464, 'depth': 9, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 6}. Best is trial 1 with value: 0.6346541245562606.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:49,125]\u001b[0m Trial 5 finished with value: 0.6291121031467515 and parameters: {'iterations': 11025, 'od_wait': 547, 'learning_rate': 0.03394984625244169, 'reg_lambda': 83.1697060506069, 'subsample': 0.2730708099728124, 'random_strength': 30.72315064955262, 'depth': 5, 'min_data_in_leaf': 29, 'leaf_estimation_iterations': 4}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:50,521]\u001b[0m Trial 6 finished with value: 0.6428722838483836 and parameters: {'iterations': 13023, 'od_wait': 2071, 'learning_rate': 0.8435142311238906, 'reg_lambda': 18.61014992361355, 'subsample': 0.8026433097957104, 'random_strength': 28.327475469515704, 'depth': 8, 'min_data_in_leaf': 5, 'leaf_estimation_iterations': 2}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:53,309]\u001b[0m Trial 7 finished with value: 0.6397419711156256 and parameters: {'iterations': 19287, 'od_wait': 1394, 'learning_rate': 0.44248219558902774, 'reg_lambda': 72.95082557015739, 'subsample': 0.7655128989911097, 'random_strength': 16.35632670677414, 'depth': 10, 'min_data_in_leaf': 5, 'leaf_estimation_iterations': 12}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:56,295]\u001b[0m Trial 8 finished with value: 0.6318591414970937 and parameters: {'iterations': 17796, 'od_wait': 2222, 'learning_rate': 0.07826843619285696, 'reg_lambda': 5.70548154457822, 'subsample': 0.28218707469320015, 'random_strength': 20.46822734943624, 'depth': 4, 'min_data_in_leaf': 28, 'leaf_estimation_iterations': 4}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:21:57,782]\u001b[0m Trial 9 finished with value: 0.6392190334016876 and parameters: {'iterations': 9711, 'od_wait': 1867, 'learning_rate': 0.4552424440260346, 'reg_lambda': 77.67105792841255, 'subsample': 0.06536615756438524, 'random_strength': 29.502847746935373, 'depth': 1, 'min_data_in_leaf': 2, 'leaf_estimation_iterations': 14}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:22:15,581]\u001b[0m Trial 10 finished with value: 0.643349170898022 and parameters: {'iterations': 23877, 'od_wait': 513, 'learning_rate': 0.2673943658019119, 'reg_lambda': 35.48944719668939, 'subsample': 0.0008039799034519346, 'random_strength': 12.118279732381875, 'depth': 13, 'min_data_in_leaf': 30, 'leaf_estimation_iterations': 4}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:22:29,523]\u001b[0m Trial 11 finished with value: 0.6306938105932003 and parameters: {'iterations': 16993, 'od_wait': 1167, 'learning_rate': 0.015433026514733189, 'reg_lambda': 0.9385736544122336, 'subsample': 0.2656601955883019, 'random_strength': 21.030919173972652, 'depth': 5, 'min_data_in_leaf': 30, 'leaf_estimation_iterations': 4}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:22:41,697]\u001b[0m Trial 12 finished with value: 0.6305563110782881 and parameters: {'iterations': 6920, 'od_wait': 1171, 'learning_rate': 0.019041185484742873, 'reg_lambda': 40.4367028168547, 'subsample': 0.17024374241013218, 'random_strength': 21.20925218743306, 'depth': 5, 'min_data_in_leaf': 23, 'leaf_estimation_iterations': 4}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:22:43,833]\u001b[0m Trial 13 finished with value: 0.6322975678322487 and parameters: {'iterations': 4601, 'od_wait': 1040, 'learning_rate': 0.23737508337116298, 'reg_lambda': 99.67691977856384, 'subsample': 0.15455883297093284, 'random_strength': 37.51463949717583, 'depth': 6, 'min_data_in_leaf': 23, 'leaf_estimation_iterations': 6}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:22:46,380]\u001b[0m Trial 14 finished with value: 0.63251481189251 and parameters: {'iterations': 7621, 'od_wait': 1346, 'learning_rate': 0.22583976683468263, 'reg_lambda': 49.432407103713984, 'subsample': 0.16012871182946883, 'random_strength': 21.550818778710916, 'depth': 6, 'min_data_in_leaf': 23, 'leaf_estimation_iterations': 3}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:22:47,362]\u001b[0m Trial 15 finished with value: 0.6406120802470853 and parameters: {'iterations': 8431, 'od_wait': 538, 'learning_rate': 0.985450135369937, 'reg_lambda': 36.26967668264167, 'subsample': 0.5728041253921184, 'random_strength': 24.846975070733915, 'depth': 3, 'min_data_in_leaf': 24, 'leaf_estimation_iterations': 6}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:23:53,153]\u001b[0m Trial 16 finished with value: 0.6360468434202957 and parameters: {'iterations': 12807, 'od_wait': 794, 'learning_rate': 0.16939792513210072, 'reg_lambda': 56.058276811306385, 'subsample': 0.37678990167664544, 'random_strength': 11.084214085881989, 'depth': 14, 'min_data_in_leaf': 18, 'leaf_estimation_iterations': 8}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:23:55,002]\u001b[0m Trial 17 finished with value: 0.6332636570878251 and parameters: {'iterations': 7326, 'od_wait': 1651, 'learning_rate': 0.3358590199530851, 'reg_lambda': 98.17859686216133, 'subsample': 0.13069150726691114, 'random_strength': 38.57443496116426, 'depth': 7, 'min_data_in_leaf': 26, 'leaf_estimation_iterations': 1}. Best is trial 5 with value: 0.6291121031467515.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:28:56,780]\u001b[0m Trial 18 finished with value: 0.627244888783915 and parameters: {'iterations': 14305, 'od_wait': 1177, 'learning_rate': 0.014520689333851356, 'reg_lambda': 38.93162800143628, 'subsample': 0.3943383991877147, 'random_strength': 16.230556434079638, 'depth': 12, 'min_data_in_leaf': 19, 'leaf_estimation_iterations': 5}. Best is trial 18 with value: 0.627244888783915.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:29:20,149]\u001b[0m Trial 19 finished with value: 0.6366988647904779 and parameters: {'iterations': 14404, 'od_wait': 962, 'learning_rate': 0.14433337173203667, 'reg_lambda': 22.763775626789403, 'subsample': 0.6525327522482225, 'random_strength': 15.931767554864699, 'depth': 12, 'min_data_in_leaf': 17, 'leaf_estimation_iterations': 10}. Best is trial 18 with value: 0.627244888783915.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:29:27,309]\u001b[0m Trial 20 finished with value: 0.6365512744386871 and parameters: {'iterations': 23323, 'od_wait': 695, 'learning_rate': 0.3102893115450773, 'reg_lambda': 64.00721470416445, 'subsample': 0.41893326083464355, 'random_strength': 33.674059895754034, 'depth': 11, 'min_data_in_leaf': 14, 'leaf_estimation_iterations': 6}. Best is trial 18 with value: 0.627244888783915.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:29:35,789]\u001b[0m Trial 21 finished with value: 0.6312205593668392 and parameters: {'iterations': 10275, 'od_wait': 1155, 'learning_rate': 0.025860801479202167, 'reg_lambda': 42.26450385141087, 'subsample': 0.3103850743446006, 'random_strength': 15.988512497389479, 'depth': 4, 'min_data_in_leaf': 20, 'leaf_estimation_iterations': 3}. Best is trial 18 with value: 0.627244888783915.\u001b[0m\n",
            "\u001b[32m[I 2022-08-25 05:29:38,598]\u001b[0m Trial 22 finished with value: 0.6307398924053808 and parameters: {'iterations': 13924, 'od_wait': 1238, 'learning_rate': 0.12401542008786888, 'reg_lambda': 29.27179344881487, 'subsample': 0.20497395459941645, 'random_strength': 24.396953599788585, 'depth': 6, 'min_data_in_leaf': 21, 'leaf_estimation_iterations': 5}. Best is trial 18 with value: 0.627244888783915.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbrm_best_trial_14 = optuna_cbrm.best_trial\n",
        "cbrm_best_params_14 = cbrm_best_trial_14.params\n",
        "print('Best Trial: score {},\\nparams {}'.format(cbrm_best_trial_14.value, cbrm_best_params_14))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H4N6v_I92L7",
        "outputId": "a3f9de2c-a6b3-49a1-cc72-112af9fe2233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Trial: score 0.6260155863709848,\n",
            "params {'iterations': 10613, 'od_wait': 1747, 'learning_rate': 0.03510067863468966, 'reg_lambda': 96.94571353066611, 'subsample': 0.9953018774882569, 'random_strength': 39.258217508905865, 'depth': 10, 'min_data_in_leaf': 10, 'leaf_estimation_iterations': 15, 'bagging_temperature': 6.676577708925311, 'colsample_bylevel': 0.48223882642603205}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cv: 0.6246"
      ],
      "metadata": {
        "id": "dFqMOzl5Gqpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y14_model = CatBoostRegressor(**cbrm_best_params_14,verbose=False)"
      ],
      "metadata": {
        "id": "yHnjoUbb95qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y14_model.fit(X_train_scaled,y_train[:,13]) #전체 test data fit\n",
        "y14_pred = y14_model.predict(X_test_scaled)\n",
        "print(f'test loss: {rmse(y_test[:,13],y14_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-32Y9dR-Eu3",
        "outputId": "bfa731ff-dc66-4b4d-cf0c-ccc09b5bc35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.6339371383807458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB_u96u-WGsm"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Load"
      ],
      "metadata": {
        "id": "VDI6YXBrahwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "KVAFKDKNOUGu",
        "outputId": "ef2dde7b-9321-41f5-bd53-7965253e876e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08    X_09  \\\n",
              "0      70.544  103.320  67.47     1  101.892  74.983  29.45   62.38  245.71   \n",
              "1      69.524  103.321  65.17     1  101.944  72.943  28.73   61.23  233.61   \n",
              "2      72.583  103.320  64.07     1  103.153  72.943  28.81  105.77  272.20   \n",
              "3      71.563  103.320  67.57     1  101.971  77.022  28.92  115.21  255.36   \n",
              "4      69.524  103.320  63.57     1  101.981  70.904  29.68  103.38  241.46   \n",
              "...       ...      ...    ...   ...      ...     ...    ...     ...     ...   \n",
              "39602  66.465  103.320  62.27     1  103.150  66.825  30.20   77.83  298.05   \n",
              "39603  66.465  103.321  62.77     1  102.021  66.825  29.21  102.25  270.67   \n",
              "39604  68.504  103.320  64.67     1  103.144  68.864  29.96  102.61  198.07   \n",
              "39605  66.465  103.320  63.67     1  102.025  67.845  30.30  112.60  275.52   \n",
              "39606  66.465  103.320  65.67     1  102.004  69.884  30.16  112.90  276.06   \n",
              "\n",
              "       X_10  ...  X_48      X_49        X_50        X_51        X_52  \\\n",
              "0       0.0  ...     1   9706.03  137.043591  135.359219  147.837968   \n",
              "1       0.0  ...     1  10423.43  133.736691  135.979817  149.924692   \n",
              "2       0.0  ...     1  10948.53  132.805112  131.055355  146.814592   \n",
              "3       0.0  ...     1  15007.03  134.138760  133.239422  139.720132   \n",
              "4       0.0  ...     1  11051.03  142.728970  136.620022  134.853555   \n",
              "...     ...  ...   ...       ...         ...         ...         ...   \n",
              "39602   0.0  ...     1  60630.73  129.965741  130.807148  133.481737   \n",
              "39603   0.0  ...     1  60763.43  127.633885  120.158764  142.667802   \n",
              "39604   0.0  ...     1   8813.33  132.501286  136.893025  134.419328   \n",
              "39605   0.0  ...     1  62222.33  128.189679  121.495930  141.288011   \n",
              "39606   0.0  ...     1  62172.23  135.096272  122.988476  142.019357   \n",
              "\n",
              "             X_53        X_54        X_55        X_56    평균_SMT납량  \n",
              "0      134.313475  125.605427  136.721425  125.028256  134.558480  \n",
              "1      123.630583  127.893337  143.322659  124.877308  134.195012  \n",
              "2      128.939070  127.012195  140.395688  122.238232  132.751463  \n",
              "3      132.260824  130.723186  147.624829  134.875225  136.083197  \n",
              "4      134.760252  125.647793  139.331105  123.272762  133.887780  \n",
              "...           ...         ...         ...         ...         ...  \n",
              "39602  125.273130  121.780933  133.780110  129.029812  129.159802  \n",
              "39603  122.465490  122.987209  143.090741  122.811413  128.830758  \n",
              "39604  129.115431  130.920147  140.489232  119.166699  131.929307  \n",
              "39605  130.141676  125.518825  136.603634  124.525929  129.680526  \n",
              "39606  123.752157  130.648365  139.695370  136.714504  132.987786  \n",
              "\n",
              "[39607 rows x 57 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05a2c8b9-b7b9-4aee-9c9f-080f139d5c7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X_01</th>\n",
              "      <th>X_02</th>\n",
              "      <th>X_03</th>\n",
              "      <th>X_04</th>\n",
              "      <th>X_05</th>\n",
              "      <th>X_06</th>\n",
              "      <th>X_07</th>\n",
              "      <th>X_08</th>\n",
              "      <th>X_09</th>\n",
              "      <th>X_10</th>\n",
              "      <th>...</th>\n",
              "      <th>X_48</th>\n",
              "      <th>X_49</th>\n",
              "      <th>X_50</th>\n",
              "      <th>X_51</th>\n",
              "      <th>X_52</th>\n",
              "      <th>X_53</th>\n",
              "      <th>X_54</th>\n",
              "      <th>X_55</th>\n",
              "      <th>X_56</th>\n",
              "      <th>평균_SMT납량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70.544</td>\n",
              "      <td>103.320</td>\n",
              "      <td>67.47</td>\n",
              "      <td>1</td>\n",
              "      <td>101.892</td>\n",
              "      <td>74.983</td>\n",
              "      <td>29.45</td>\n",
              "      <td>62.38</td>\n",
              "      <td>245.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>9706.03</td>\n",
              "      <td>137.043591</td>\n",
              "      <td>135.359219</td>\n",
              "      <td>147.837968</td>\n",
              "      <td>134.313475</td>\n",
              "      <td>125.605427</td>\n",
              "      <td>136.721425</td>\n",
              "      <td>125.028256</td>\n",
              "      <td>134.558480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69.524</td>\n",
              "      <td>103.321</td>\n",
              "      <td>65.17</td>\n",
              "      <td>1</td>\n",
              "      <td>101.944</td>\n",
              "      <td>72.943</td>\n",
              "      <td>28.73</td>\n",
              "      <td>61.23</td>\n",
              "      <td>233.61</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>10423.43</td>\n",
              "      <td>133.736691</td>\n",
              "      <td>135.979817</td>\n",
              "      <td>149.924692</td>\n",
              "      <td>123.630583</td>\n",
              "      <td>127.893337</td>\n",
              "      <td>143.322659</td>\n",
              "      <td>124.877308</td>\n",
              "      <td>134.195012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72.583</td>\n",
              "      <td>103.320</td>\n",
              "      <td>64.07</td>\n",
              "      <td>1</td>\n",
              "      <td>103.153</td>\n",
              "      <td>72.943</td>\n",
              "      <td>28.81</td>\n",
              "      <td>105.77</td>\n",
              "      <td>272.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>10948.53</td>\n",
              "      <td>132.805112</td>\n",
              "      <td>131.055355</td>\n",
              "      <td>146.814592</td>\n",
              "      <td>128.939070</td>\n",
              "      <td>127.012195</td>\n",
              "      <td>140.395688</td>\n",
              "      <td>122.238232</td>\n",
              "      <td>132.751463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>71.563</td>\n",
              "      <td>103.320</td>\n",
              "      <td>67.57</td>\n",
              "      <td>1</td>\n",
              "      <td>101.971</td>\n",
              "      <td>77.022</td>\n",
              "      <td>28.92</td>\n",
              "      <td>115.21</td>\n",
              "      <td>255.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>15007.03</td>\n",
              "      <td>134.138760</td>\n",
              "      <td>133.239422</td>\n",
              "      <td>139.720132</td>\n",
              "      <td>132.260824</td>\n",
              "      <td>130.723186</td>\n",
              "      <td>147.624829</td>\n",
              "      <td>134.875225</td>\n",
              "      <td>136.083197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69.524</td>\n",
              "      <td>103.320</td>\n",
              "      <td>63.57</td>\n",
              "      <td>1</td>\n",
              "      <td>101.981</td>\n",
              "      <td>70.904</td>\n",
              "      <td>29.68</td>\n",
              "      <td>103.38</td>\n",
              "      <td>241.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>11051.03</td>\n",
              "      <td>142.728970</td>\n",
              "      <td>136.620022</td>\n",
              "      <td>134.853555</td>\n",
              "      <td>134.760252</td>\n",
              "      <td>125.647793</td>\n",
              "      <td>139.331105</td>\n",
              "      <td>123.272762</td>\n",
              "      <td>133.887780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39602</th>\n",
              "      <td>66.465</td>\n",
              "      <td>103.320</td>\n",
              "      <td>62.27</td>\n",
              "      <td>1</td>\n",
              "      <td>103.150</td>\n",
              "      <td>66.825</td>\n",
              "      <td>30.20</td>\n",
              "      <td>77.83</td>\n",
              "      <td>298.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>60630.73</td>\n",
              "      <td>129.965741</td>\n",
              "      <td>130.807148</td>\n",
              "      <td>133.481737</td>\n",
              "      <td>125.273130</td>\n",
              "      <td>121.780933</td>\n",
              "      <td>133.780110</td>\n",
              "      <td>129.029812</td>\n",
              "      <td>129.159802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39603</th>\n",
              "      <td>66.465</td>\n",
              "      <td>103.321</td>\n",
              "      <td>62.77</td>\n",
              "      <td>1</td>\n",
              "      <td>102.021</td>\n",
              "      <td>66.825</td>\n",
              "      <td>29.21</td>\n",
              "      <td>102.25</td>\n",
              "      <td>270.67</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>60763.43</td>\n",
              "      <td>127.633885</td>\n",
              "      <td>120.158764</td>\n",
              "      <td>142.667802</td>\n",
              "      <td>122.465490</td>\n",
              "      <td>122.987209</td>\n",
              "      <td>143.090741</td>\n",
              "      <td>122.811413</td>\n",
              "      <td>128.830758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39604</th>\n",
              "      <td>68.504</td>\n",
              "      <td>103.320</td>\n",
              "      <td>64.67</td>\n",
              "      <td>1</td>\n",
              "      <td>103.144</td>\n",
              "      <td>68.864</td>\n",
              "      <td>29.96</td>\n",
              "      <td>102.61</td>\n",
              "      <td>198.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>8813.33</td>\n",
              "      <td>132.501286</td>\n",
              "      <td>136.893025</td>\n",
              "      <td>134.419328</td>\n",
              "      <td>129.115431</td>\n",
              "      <td>130.920147</td>\n",
              "      <td>140.489232</td>\n",
              "      <td>119.166699</td>\n",
              "      <td>131.929307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39605</th>\n",
              "      <td>66.465</td>\n",
              "      <td>103.320</td>\n",
              "      <td>63.67</td>\n",
              "      <td>1</td>\n",
              "      <td>102.025</td>\n",
              "      <td>67.845</td>\n",
              "      <td>30.30</td>\n",
              "      <td>112.60</td>\n",
              "      <td>275.52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>62222.33</td>\n",
              "      <td>128.189679</td>\n",
              "      <td>121.495930</td>\n",
              "      <td>141.288011</td>\n",
              "      <td>130.141676</td>\n",
              "      <td>125.518825</td>\n",
              "      <td>136.603634</td>\n",
              "      <td>124.525929</td>\n",
              "      <td>129.680526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39606</th>\n",
              "      <td>66.465</td>\n",
              "      <td>103.320</td>\n",
              "      <td>65.67</td>\n",
              "      <td>1</td>\n",
              "      <td>102.004</td>\n",
              "      <td>69.884</td>\n",
              "      <td>30.16</td>\n",
              "      <td>112.90</td>\n",
              "      <td>276.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>62172.23</td>\n",
              "      <td>135.096272</td>\n",
              "      <td>122.988476</td>\n",
              "      <td>142.019357</td>\n",
              "      <td>123.752157</td>\n",
              "      <td>130.648365</td>\n",
              "      <td>139.695370</td>\n",
              "      <td>136.714504</td>\n",
              "      <td>132.987786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39607 rows × 57 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05a2c8b9-b7b9-4aee-9c9f-080f139d5c7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05a2c8b9-b7b9-4aee-9c9f-080f139d5c7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05a2c8b9-b7b9-4aee-9c9f-080f139d5c7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = np.array(train_y)"
      ],
      "metadata": {
        "id": "SRfAaV2ypcHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_1 = train_y[:,0]\n",
        "train_y_2 = train_y[:,1]\n",
        "train_y_3 = train_y[:,2]\n",
        "train_y_4 = train_y[:,3]\n",
        "train_y_5 = train_y[:,4]\n",
        "train_y_6 = train_y[:,5]\n",
        "train_y_7 = train_y[:,6]\n",
        "train_y_8 = train_y[:,7]\n",
        "train_y_9 = train_y[:,8]\n",
        "train_y_10 = train_y[:,9]\n",
        "train_y_11 = train_y[:,10]\n",
        "train_y_12 = train_y[:,11]\n",
        "train_y_13 = train_y[:,12]\n",
        "train_y_14 = train_y[:,13]"
      ],
      "metadata": {
        "id": "6r0ZSLEOntX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.shape,train_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o--EVQgcow4W",
        "outputId": "25b0ffc8-63cb-4ef3-9f57-eb0a9315f856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39607, 57) (39607, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "Uqwst1cLaYZc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79DeL4Cup9YO"
      },
      "outputs": [],
      "source": [
        "# 평균_SMT납량 추가\n",
        "train_x[\"평균_SMT납량\"] = (train_x[\"X_50\"] + train_x[\"X_51\"] + train_x[\"X_52\"] + train_x[\"X_53\"] + train_x[\"X_54\"] + train_x[\"X_55\"] + train_x[\"X_56\"]) / 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDTsfwcfqLdG"
      },
      "outputs": [],
      "source": [
        "deleted_train_x = train_x.drop(['X_04','X_23', 'X_47', 'X_48'], axis=1) # n차 검증 x 칼럼 제거"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ohe = OneHotEncoder(sparse=False)"
      ],
      "metadata": {
        "id": "wJ2frIS61Y_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDSP6zxfogLP"
      },
      "outputs": [],
      "source": [
        "p1_train=deleted_train_x.iloc[:,:10] #X 1 ~ 11\n",
        "p2_train=deleted_train_x.iloc[:,10:38] #X 12~40\n",
        "p3_train=deleted_train_x.iloc[:,38:45] #X 41~49\n",
        "p4_train=deleted_train_x.iloc[:,45:52] #X 50~56"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8cW-Qs1o1th",
        "outputId": "fe2734b8-9e4e-47e0-aaa6-5440ba99e070"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "clust_model_1 = KMeans(n_clusters = 2,random_state = 42) \n",
        "clust_model_1.fit(p1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vx4GDRQo15F",
        "outputId": "168b6229-4729-43d1-fced-8a1bbfc6b0b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "clust_model_2 = KMeans(n_clusters = 3,random_state = 42) \n",
        "clust_model_2.fit(p2_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3WqqjQnpIla",
        "outputId": "1e1c37a1-d0f3-4aed-c363-419ee3694e6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "clust_model_3 = KMeans(n_clusters = 3,random_state = 42) \n",
        "clust_model_3.fit(p3_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I6WMhKHpIpm",
        "outputId": "df258c53-500a-4af8-a28d-64d7a80cfcb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "clust_model_4 = KMeans(n_clusters = 2,random_state = 42) \n",
        "clust_model_4.fit(p4_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tvJ2sYVqhyR"
      },
      "outputs": [],
      "source": [
        "pred_1_train = np.array(clust_model_1.predict(p1_train)).reshape(-1, 1)\n",
        "pred_2_train = np.array(clust_model_2.predict(p2_train)).reshape(-1, 1)\n",
        "pred_3_train = np.array(clust_model_3.predict(p3_train)).reshape(-1, 1)\n",
        "pred_4_train = np.array(clust_model_4.predict(p4_train)).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-IID51Kqh1G"
      },
      "outputs": [],
      "source": [
        "train_cluster_1 = np.array(ohe.fit_transform(pred_1_train)) # 공정1\n",
        "train_cluster_2 = np.array(ohe.fit_transform(pred_2_train)) # 공정2\n",
        "train_cluster_3 = np.array(ohe.fit_transform(pred_3_train)) # 공정3\n",
        "train_cluster_4 = np.array(ohe.fit_transform(pred_4_train)) # 공정4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1KyttFCq06x"
      },
      "outputs": [],
      "source": [
        "deleted_train_x = np.concatenate([deleted_train_x, train_cluster_1, train_cluster_2, train_cluster_3, train_cluster_4], axis=1)\n",
        "train_y = np.array(train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxF0Ge4KrP51",
        "outputId": "3e2c48e6-b1b8-4891-8011-79296105f556"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39607, 63)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "deleted_train_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After Optuna tuning \n",
        "y1_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, y1_model_1, y1_model_2, model_cat)))\n",
        "y2_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, y2_model_1, y2_model_2, model_cat)))\n",
        "y3_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, y3_model_1, y3_model_2, model_cat)))\n",
        "y4_model = make_pipeline(StandardScaler(), CatBoostRegressor(**cbrm_best_params_4,verbose=False))\n",
        "y5_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, y5_model_1, y5_model_2, model_cat)))\n",
        "y6_model = make_pipeline(StandardScaler(), CatBoostRegressor(**cbrm_best_params_6,verbose=False))\n",
        "y7_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, y7_model_1, y7_model_2, model_cat)))\n",
        "y8_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, y8_model_1, y8_model_2, model_cat)))\n",
        "y9_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, y9_model_1, y9_model_2, model_cat)))\n",
        "y10_model = make_pipeline(StandardScaler(), CatBoostRegressor(**cbrm_best_params_10,verbose=False))\n",
        "y11_model = make_pipeline(StandardScaler(), CatBoostRegressor(**cbrm_best_params_11,verbose=False))\n",
        "y12_model = make_pipeline(StandardScaler(), CatBoostRegressor(**cbrm_best_params_12,verbose=False))\n",
        "y13_model = make_pipeline(StandardScaler(), AveragingModels(models = (Gboost, y13_model_1, y13_model_2, model_cat)))\n",
        "y14_model = make_pipeline(StandardScaler(), CatBoostRegressor(**cbrm_best_params_14,verbose=False))"
      ],
      "metadata": {
        "id": "4ZZMUCIFDKnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting"
      ],
      "metadata": {
        "id": "jq8lcvmlbVDn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ora_j2ntWINu"
      },
      "outputs": [],
      "source": [
        "# 최종 모델 훈련 \n",
        "y1_model.fit(deleted_train_x, train_y[:, 0])\n",
        "y2_model.fit(deleted_train_x, train_y[:, 1])\n",
        "y3_model.fit(deleted_train_x, train_y[:, 2])\n",
        "y4_model.fit(deleted_train_x, train_y[:, 3])\n",
        "y5_model.fit(deleted_train_x, train_y[:, 4])\n",
        "y6_model.fit(deleted_train_x, train_y[:, 5])\n",
        "y7_model.fit(deleted_train_x, train_y[:, 6])\n",
        "y8_model.fit(deleted_train_x, train_y[:, 7])\n",
        "y9_model.fit(deleted_train_x, train_y[:, 8])\n",
        "y10_model.fit(deleted_train_x, train_y[:, 9])\n",
        "y11_model.fit(deleted_train_x, train_y[:, 10])\n",
        "y12_model.fit(deleted_train_x, train_y[:, 11])\n",
        "y13_model.fit(deleted_train_x, train_y[:, 12])\n",
        "y14_model.fit(deleted_train_x, train_y[:, 13])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "v4-w0ERMEn2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Load"
      ],
      "metadata": {
        "id": "OWPS4m0EbORf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1KxwZSxXLQv"
      },
      "outputs": [],
      "source": [
        "test_x = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Enginnering"
      ],
      "metadata": {
        "id": "fT7pxoC8bP4v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HLsSd5JfpCU"
      },
      "outputs": [],
      "source": [
        "# 평균_SMT납량 추가\n",
        "test_x[\"평균_SMT납량\"] = (test_x[\"X_50\"] + test_x[\"X_51\"] + test_x[\"X_52\"] + test_x[\"X_53\"] + test_x[\"X_54\"] + test_x[\"X_55\"] + test_x[\"X_56\"]) / 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29gnBJ1ZXZcg"
      },
      "outputs": [],
      "source": [
        "deleted_test_x = test_x.drop(['ID','X_04','X_23', 'X_47', 'X_48'], axis=1) # n차 검증 x 칼럼 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xd3usLugU3b"
      },
      "outputs": [],
      "source": [
        "p1_test=deleted_test_x.iloc[:,:10] #X 1 ~ 11\n",
        "p2_test=deleted_test_x.iloc[:,10:38] #X 12~40\n",
        "p3_test=deleted_test_x.iloc[:,38:45] #X 41~49\n",
        "p4_test=deleted_test_x.iloc[:,45:52] #X 50~56"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buYSStioghje"
      },
      "outputs": [],
      "source": [
        "pred_1_test = np.array(clust_model_1.predict(p1_test)).reshape(-1, 1)\n",
        "pred_2_test = np.array(clust_model_2.predict(p2_test)).reshape(-1, 1)\n",
        "pred_3_test = np.array(clust_model_3.predict(p3_test)).reshape(-1, 1)\n",
        "pred_4_test = np.array(clust_model_4.predict(p4_test)).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6yUtqC-iAwH"
      },
      "outputs": [],
      "source": [
        "test_cluster_1 = np.array(ohe.fit_transform(pred_1_test)) # 공정1\n",
        "test_cluster_2 = np.array(ohe.fit_transform(pred_2_test)) # 공정2\n",
        "test_cluster_3 = np.array(ohe.fit_transform(pred_3_test)) # 공정3\n",
        "test_cluster_4 = np.array(ohe.fit_transform(pred_4_test)) # 공정4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A5CjAPThVbr"
      },
      "outputs": [],
      "source": [
        "deleted_test_x = np.concatenate([deleted_test_x, test_cluster_1, test_cluster_2, test_cluster_3, test_cluster_4], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h45LKbCHiu62",
        "outputId": "083ef98d-63cf-413a-e4aa-fa837df0b3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39608, 63)\n"
          ]
        }
      ],
      "source": [
        "print(deleted_test_x.shape) #행수가 변하면 안된다 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "EZ2Fw6_2cHLM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93MXijyjXZfX"
      },
      "outputs": [],
      "source": [
        "# 테스트데이터 예측\n",
        "y1_test_pred = y1_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y2_test_pred = y2_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y3_test_pred = y3_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y4_test_pred = y4_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y5_test_pred = y5_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y6_test_pred = y6_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y7_test_pred = y7_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y8_test_pred = y8_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y9_test_pred = y9_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y10_test_pred = y10_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y11_test_pred = y11_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y12_test_pred = y12_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y13_test_pred = y13_model.predict(deleted_test_x).reshape(-1, 1)\n",
        "y14_test_pred = y14_model.predict(deleted_test_x).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2W6-srYXZkA"
      },
      "outputs": [],
      "source": [
        "total_test_pred = np.concatenate([y1_test_pred,  y2_test_pred, y3_test_pred, y4_test_pred, y5_test_pred\n",
        "                                   , y6_test_pred, y7_test_pred, y8_test_pred, y9_test_pred, y10_test_pred, y11_test_pred,\n",
        "                                   y12_test_pred, y13_test_pred, y14_test_pred], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_test_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFB17x9MZZV6",
        "outputId": "5c84741c-7ee1-4212-fc54-c359bf1c8a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39608, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "DXNDIvuoavGh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tsdgb0_FYSyX",
        "outputId": "6d058451-c168-492c-bc75-5e8189441e4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ID  Y_01  Y_02  Y_03  Y_04  Y_05  Y_06  Y_07  Y_08  Y_09  Y_10  \\\n",
              "0  TEST_00001     0     0     0     0     0     0     0     0     0     0   \n",
              "1  TEST_00002     0     0     0     0     0     0     0     0     0     0   \n",
              "2  TEST_00003     0     0     0     0     0     0     0     0     0     0   \n",
              "3  TEST_00004     0     0     0     0     0     0     0     0     0     0   \n",
              "4  TEST_00005     0     0     0     0     0     0     0     0     0     0   \n",
              "\n",
              "   Y_11  Y_12  Y_13  Y_14  \n",
              "0     0     0     0     0  \n",
              "1     0     0     0     0  \n",
              "2     0     0     0     0  \n",
              "3     0     0     0     0  \n",
              "4     0     0     0     0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88883f17-98ad-4003-817c-e33a0748ae64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Y_01</th>\n",
              "      <th>Y_02</th>\n",
              "      <th>Y_03</th>\n",
              "      <th>Y_04</th>\n",
              "      <th>Y_05</th>\n",
              "      <th>Y_06</th>\n",
              "      <th>Y_07</th>\n",
              "      <th>Y_08</th>\n",
              "      <th>Y_09</th>\n",
              "      <th>Y_10</th>\n",
              "      <th>Y_11</th>\n",
              "      <th>Y_12</th>\n",
              "      <th>Y_13</th>\n",
              "      <th>Y_14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_00001</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_00002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_00003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_00004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_00005</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88883f17-98ad-4003-817c-e33a0748ae64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88883f17-98ad-4003-817c-e33a0748ae64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88883f17-98ad-4003-817c-e33a0748ae64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "submission = pd.read_csv(\"sample_submission.csv\")\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEK3_uSXYS0-"
      },
      "outputs": [],
      "source": [
        "for idx, col in enumerate(submission.columns):\n",
        "    if col=='ID':\n",
        "        continue\n",
        "    submission[col] = total_test_pred[:,idx-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "YDXzaS9EYYiI",
        "outputId": "c9e70abc-a74d-4698-9d75-3f291c6b8deb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               ID      Y_01      Y_02      Y_03       Y_04       Y_05  \\\n",
              "0      TEST_00001  1.382476  1.165750  1.077640  14.242799  29.067446   \n",
              "1      TEST_00002  1.432940  1.135604  1.069152  12.675567  28.808385   \n",
              "2      TEST_00003  1.372687  1.062685  0.995056  14.852908  29.963330   \n",
              "3      TEST_00004  1.405075  1.067151  0.981720  14.688744  29.985287   \n",
              "4      TEST_00005  1.292454  0.929520  0.897133  14.817383  29.331434   \n",
              "...           ...       ...       ...       ...        ...        ...   \n",
              "39603  TEST_39604  1.223865  0.910664  0.942522  11.880422  28.741146   \n",
              "39604  TEST_39605  1.212387  0.828151  0.897577  14.722887  29.101403   \n",
              "39605  TEST_39606  1.208577  0.902062  0.914130  12.754370  28.937510   \n",
              "39606  TEST_39607  1.193732  0.819654  0.872120  14.292118  29.051218   \n",
              "39607  TEST_39608  1.281661  0.925084  0.974334  13.516562  28.601737   \n",
              "\n",
              "            Y_06      Y_07       Y_08       Y_09       Y_10       Y_11  \\\n",
              "0      17.271439  2.873493 -23.156520 -23.161803 -21.882336  24.683375   \n",
              "1      16.158748  2.916047 -23.211755 -23.235543 -22.697519  24.104475   \n",
              "2      17.737953  2.812316 -22.979984 -23.025081 -21.846220  24.749504   \n",
              "3      17.089087  2.817694 -22.753980 -22.818175 -21.606555  25.140683   \n",
              "4      17.639713  2.860450 -22.834355 -22.836650 -21.823103  24.741888   \n",
              "...          ...       ...        ...        ...        ...        ...   \n",
              "39603  16.564753  2.930687 -23.462023 -23.413999 -22.896492  24.507706   \n",
              "39604  17.019292  2.939877 -23.376776 -23.379480 -23.126794  24.454283   \n",
              "39605  16.457702  2.914714 -23.414902 -23.429795 -22.992120  24.303242   \n",
              "39606  16.677959  2.955653 -23.440983 -23.418136 -22.800315  24.543566   \n",
              "39607  16.504202  2.923563 -23.477529 -23.493563 -23.198398  24.009662   \n",
              "\n",
              "            Y_12       Y_13       Y_14  \n",
              "0     -26.021520 -23.610571 -26.021520  \n",
              "1     -26.102922 -23.703496 -26.102922  \n",
              "2     -25.856413 -23.490794 -25.856413  \n",
              "3     -25.644454 -23.250578 -25.644454  \n",
              "4     -25.663386 -23.322193 -25.663386  \n",
              "...          ...        ...        ...  \n",
              "39603 -26.365455 -23.898099 -26.365455  \n",
              "39604 -26.199373 -23.888187 -26.199373  \n",
              "39605 -26.447246 -23.929491 -26.447246  \n",
              "39606 -26.364229 -23.914101 -26.364229  \n",
              "39607 -26.545748 -23.950562 -26.545748  \n",
              "\n",
              "[39608 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1434be9f-b58b-40f6-9420-381e288ed6c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Y_01</th>\n",
              "      <th>Y_02</th>\n",
              "      <th>Y_03</th>\n",
              "      <th>Y_04</th>\n",
              "      <th>Y_05</th>\n",
              "      <th>Y_06</th>\n",
              "      <th>Y_07</th>\n",
              "      <th>Y_08</th>\n",
              "      <th>Y_09</th>\n",
              "      <th>Y_10</th>\n",
              "      <th>Y_11</th>\n",
              "      <th>Y_12</th>\n",
              "      <th>Y_13</th>\n",
              "      <th>Y_14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_00001</td>\n",
              "      <td>1.382476</td>\n",
              "      <td>1.165750</td>\n",
              "      <td>1.077640</td>\n",
              "      <td>14.242799</td>\n",
              "      <td>29.067446</td>\n",
              "      <td>17.271439</td>\n",
              "      <td>2.873493</td>\n",
              "      <td>-23.156520</td>\n",
              "      <td>-23.161803</td>\n",
              "      <td>-21.882336</td>\n",
              "      <td>24.683375</td>\n",
              "      <td>-26.021520</td>\n",
              "      <td>-23.610571</td>\n",
              "      <td>-26.021520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_00002</td>\n",
              "      <td>1.432940</td>\n",
              "      <td>1.135604</td>\n",
              "      <td>1.069152</td>\n",
              "      <td>12.675567</td>\n",
              "      <td>28.808385</td>\n",
              "      <td>16.158748</td>\n",
              "      <td>2.916047</td>\n",
              "      <td>-23.211755</td>\n",
              "      <td>-23.235543</td>\n",
              "      <td>-22.697519</td>\n",
              "      <td>24.104475</td>\n",
              "      <td>-26.102922</td>\n",
              "      <td>-23.703496</td>\n",
              "      <td>-26.102922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_00003</td>\n",
              "      <td>1.372687</td>\n",
              "      <td>1.062685</td>\n",
              "      <td>0.995056</td>\n",
              "      <td>14.852908</td>\n",
              "      <td>29.963330</td>\n",
              "      <td>17.737953</td>\n",
              "      <td>2.812316</td>\n",
              "      <td>-22.979984</td>\n",
              "      <td>-23.025081</td>\n",
              "      <td>-21.846220</td>\n",
              "      <td>24.749504</td>\n",
              "      <td>-25.856413</td>\n",
              "      <td>-23.490794</td>\n",
              "      <td>-25.856413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_00004</td>\n",
              "      <td>1.405075</td>\n",
              "      <td>1.067151</td>\n",
              "      <td>0.981720</td>\n",
              "      <td>14.688744</td>\n",
              "      <td>29.985287</td>\n",
              "      <td>17.089087</td>\n",
              "      <td>2.817694</td>\n",
              "      <td>-22.753980</td>\n",
              "      <td>-22.818175</td>\n",
              "      <td>-21.606555</td>\n",
              "      <td>25.140683</td>\n",
              "      <td>-25.644454</td>\n",
              "      <td>-23.250578</td>\n",
              "      <td>-25.644454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_00005</td>\n",
              "      <td>1.292454</td>\n",
              "      <td>0.929520</td>\n",
              "      <td>0.897133</td>\n",
              "      <td>14.817383</td>\n",
              "      <td>29.331434</td>\n",
              "      <td>17.639713</td>\n",
              "      <td>2.860450</td>\n",
              "      <td>-22.834355</td>\n",
              "      <td>-22.836650</td>\n",
              "      <td>-21.823103</td>\n",
              "      <td>24.741888</td>\n",
              "      <td>-25.663386</td>\n",
              "      <td>-23.322193</td>\n",
              "      <td>-25.663386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39603</th>\n",
              "      <td>TEST_39604</td>\n",
              "      <td>1.223865</td>\n",
              "      <td>0.910664</td>\n",
              "      <td>0.942522</td>\n",
              "      <td>11.880422</td>\n",
              "      <td>28.741146</td>\n",
              "      <td>16.564753</td>\n",
              "      <td>2.930687</td>\n",
              "      <td>-23.462023</td>\n",
              "      <td>-23.413999</td>\n",
              "      <td>-22.896492</td>\n",
              "      <td>24.507706</td>\n",
              "      <td>-26.365455</td>\n",
              "      <td>-23.898099</td>\n",
              "      <td>-26.365455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39604</th>\n",
              "      <td>TEST_39605</td>\n",
              "      <td>1.212387</td>\n",
              "      <td>0.828151</td>\n",
              "      <td>0.897577</td>\n",
              "      <td>14.722887</td>\n",
              "      <td>29.101403</td>\n",
              "      <td>17.019292</td>\n",
              "      <td>2.939877</td>\n",
              "      <td>-23.376776</td>\n",
              "      <td>-23.379480</td>\n",
              "      <td>-23.126794</td>\n",
              "      <td>24.454283</td>\n",
              "      <td>-26.199373</td>\n",
              "      <td>-23.888187</td>\n",
              "      <td>-26.199373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39605</th>\n",
              "      <td>TEST_39606</td>\n",
              "      <td>1.208577</td>\n",
              "      <td>0.902062</td>\n",
              "      <td>0.914130</td>\n",
              "      <td>12.754370</td>\n",
              "      <td>28.937510</td>\n",
              "      <td>16.457702</td>\n",
              "      <td>2.914714</td>\n",
              "      <td>-23.414902</td>\n",
              "      <td>-23.429795</td>\n",
              "      <td>-22.992120</td>\n",
              "      <td>24.303242</td>\n",
              "      <td>-26.447246</td>\n",
              "      <td>-23.929491</td>\n",
              "      <td>-26.447246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39606</th>\n",
              "      <td>TEST_39607</td>\n",
              "      <td>1.193732</td>\n",
              "      <td>0.819654</td>\n",
              "      <td>0.872120</td>\n",
              "      <td>14.292118</td>\n",
              "      <td>29.051218</td>\n",
              "      <td>16.677959</td>\n",
              "      <td>2.955653</td>\n",
              "      <td>-23.440983</td>\n",
              "      <td>-23.418136</td>\n",
              "      <td>-22.800315</td>\n",
              "      <td>24.543566</td>\n",
              "      <td>-26.364229</td>\n",
              "      <td>-23.914101</td>\n",
              "      <td>-26.364229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39607</th>\n",
              "      <td>TEST_39608</td>\n",
              "      <td>1.281661</td>\n",
              "      <td>0.925084</td>\n",
              "      <td>0.974334</td>\n",
              "      <td>13.516562</td>\n",
              "      <td>28.601737</td>\n",
              "      <td>16.504202</td>\n",
              "      <td>2.923563</td>\n",
              "      <td>-23.477529</td>\n",
              "      <td>-23.493563</td>\n",
              "      <td>-23.198398</td>\n",
              "      <td>24.009662</td>\n",
              "      <td>-26.545748</td>\n",
              "      <td>-23.950562</td>\n",
              "      <td>-26.545748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39608 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1434be9f-b58b-40f6-9420-381e288ed6c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1434be9f-b58b-40f6-9420-381e288ed6c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1434be9f-b58b-40f6-9420-381e288ed6c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag0tm7tnYaU4"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('submit(Y변수_seperate_sota_predict)+OPTUNA(average포함).csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iFvI41LtfyXV",
        "vD6XQeantq_q",
        "toyoolGjtwJC",
        "tpTHoyr5tzrD",
        "KmAzJ0f1t1Yz",
        "9yA5mxAYt2yT"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}